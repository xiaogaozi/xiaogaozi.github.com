<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Maybe News | Freedom]]></title>
  <link href="https://blog.xiaogaozi.org/categories/maybe-news/atom.xml" rel="self"/>
  <link href="https://blog.xiaogaozi.org/"/>
  <updated>2020-06-02T10:26:24+08:00</updated>
  <id>https://blog.xiaogaozi.org/</id>
  <author>
    <name><![CDATA[xiaogaozi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Maybe News Issue #2]]></title>
    <link href="https://blog.xiaogaozi.org/2020/06/02/maybe-news-issue-2/"/>
    <updated>2020-06-02T09:25:45+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/06/02/maybe-news-issue-2</id>
    <content type="html"><![CDATA[<blockquote><p>「Maybe News」是一个定期（或许不定期）分享一些可能是新闻的知识的<a href="/categories/maybe-news/">系列文章</a>，名字来源于我非常喜欢的一个国内的音乐厂牌<a href="https://en.wikipedia.org/wiki/Maybe_Mars">「兵马司」</a>（Maybe Mars）。你也可以通过<a href="https://digest.xiaogaozi.org/maybe-news">邮件订阅</a>它。</p></blockquote>

<!-- more -->


<h2>In Search of an Understandable Consensus Algorithm (Extended Version)</h2>

<p><a href="https://raft.github.io/raft.pdf">[链接]</a></p>

<p>终于有机会仔细阅读一遍 Raft 的论文，如果你还不了解 Raft 是什么可以看看我过去的一篇介绍分布式系统基础概念的<a href="https://blog.xiaogaozi.org/2020/05/25/how-to-design-a-distributed-index-framework-part-5/">文章</a>。</p>

<p>Raft 为节点定义了三种状态：leader、follower 和 candidate（以及一个非正式状态 learner 或者叫做 non-voting member）。一个集群只会有 1 个 leader，其余节点都是 follower。Leader 负责处理所有的读写请求，如果请求 follower 会失败并告知客户端 leader 的地址。</p>

<p>每个节点都有一个自己的 log，log 中每个条目都有一个下标（index）。这个 log 基本算是 append-only 的，通常也需要持久化到可靠的存储上（例如磁盘）。当处理写请求时 leader 会首先更新自己的 log，然后通过 RPC 复制到其它节点，只要大多数（majority）节点更新成功 leader 就会认为这个请求已经 committed，此时会更新自己的状态机（state machine）并返回给客户端。如果 RPC 请求失败 leader 会不断重试直到成功。</p>

<p>如果出现异常，如 leader 宕机、网络故障等，就可能触发 leader 重新选举。选举过程是所有 follower 为 candidate 投票，只要获得多数票 candidate 就会升级为 leader。如果投票失败会继续新一轮选举，选举过程通常是毫秒级的。每一轮新的选举都会产生一个对应的 term（任期），Raft 在协议上保证了重新选举后的新 leader 一定是包含之前所有 term 已经 committed 的 log，这样就避免了新 leader 选举成功以后需要首先补上缺失的数据。</p>

<p>当集群需要伸缩时，leader 会首先将旧集群配置（configuration）和新集群配置合并到一起并通过 log 的形式复制到 follower。成功收到这个合并后配置的节点会用这个配置替代老的配置。一旦这个合并后的配置 committed，leader 就会创建一个只包含新配置的 log 继续复制到 follower。等到新的配置 committed，旧配置将不再生效，需要下线的节点也可以被安全关闭。</p>

<p>随着时间增长，log 的容量会越来越大，Raft 引入了快照（snapshot）机制，定期将 log 压缩到快照文件。这个快照文件同时也可以帮助新加入的节点快速补上缺失的数据。</p>

<p>总结一下 Raft 算法保证了以下几个属性始终成立：</p>

<ul>
<li><strong>Election Safety</strong>：在一个特定的任期最多只能有一个 leader 被选举出来</li>
<li><strong>Leader Append-Only</strong>：leader 永远不会覆盖或者删除 log 中的条目，只会追加新的条目。</li>
<li><strong>Log Matching</strong>：如果两份 log 同时包含一个具有相同任期数和下标的条目，那么这两份 log 中这个下标之前的所有条目都应该是一致的。</li>
<li><strong>Leader Completeness</strong>：如果某个任期中的一个 log 条目已经 committed，那么在之后任期中选举出的新 leader 一定包含这个条目。</li>
<li><strong>State Machine Safety</strong>：如果一个节点已经将一个给定下标的 log 条目更新到自己的状态机，那么其它节点上同样的下标一定不会是不同的条目，也就是说不会更新一个不同的条目到自己的状态机。</li>
</ul>


<p>更多有关 Raft 的信息可以查看它的<a href="https://raft.github.io">官网</a>，强烈建议初次接触一致性协议的朋友看看网站上的动画演示，非常有助于建立一个形象直观的认知。</p>

<h2>Scaling Raft</h2>

<p><a href="https://www.cockroachlabs.com/blog/scaling-raft">[链接]</a></p>

<p>作为前面介绍 Raft 的一篇衍生阅读，原始的 Raft 实现是将所有节点看作一个 group，这种设计在某些场景（例如集群规模很小）是可行的。但是当集群规模大到一定程度，或者类似 <a href="https://github.com/cockroachdb/cockroach">CockroachDB</a> 和 <a href="https://github.com/tikv/tikv">TiKV</a> 这种将数据划分为非常多的 range，多个 range 组成一个 Raft group 的场景（通常叫做 Multi-Raft），就会发现 Raft 的基础网络通信已经足以影响单节点的性能（比如过多的心跳请求）。因此社区已经针对这样的问题有了一些优化方案，比如 <a href="https://github.com/cockroachdb/cockroach/issues/357">CockroachDB 的方案</a>和 <a href="https://github.com/tikv/tikv/pull/4591">TiKV 的方案</a>。这两个方案都很类似，基本思想是暂停那些不活跃的 Raft group 的网络通信，等到需要的时候再唤醒。</p>

<h2>Why Generics?</h2>

<p><a href="https://blog.golang.org/why-generics">[链接]</a></p>

<p>这篇文章是 Ian Lance Taylor 在 GopherCon 2019 演讲的文字版（文章中也附带了视频），主要介绍了目前 Go 的核心开发者关于泛型（generics）的一些思考。总的来说 Go 核心团队的设计思想还是保持 Go 语言一贯的简洁，不希望引入过多的概念和复杂性。大部分新增的语法特性都由提供泛型接口的开发者来学习，对于使用者来说和调用普通接口几乎没有区别。早在 2016 年社区就已经有了 <a href="https://github.com/golang/go/issues/15292">#15292</a> 这个关于泛型的讨论，并且还在持续更新中，目前已经有了 710 条评论，Ian Lance Taylor 也在其中积极回复。虽然这个 issue 打上了 Go2 的标签，但泛型特性是否能在 Go 语言的 2.0 版本中出现现在还是个未知数。</p>

<h2>The Open Application Model from Alibaba’s Perspective</h2>

<p><a href="https://www.infoq.com/articles/oam-alibaba">[链接]</a></p>

<p>阿里云和微软在去年<a href="https://cloudblogs.microsoft.com/opensource/2019/10/16/announcing-open-application-model">共同宣布</a>了 Open Application Model（OAM），OAM 组织的<a href="https://github.com/orgs/oam-dev/people">核心成员</a>同时也是前 CoreOS 团队成员以及 etcd、K8s Operator 的创造者。简单理解 OAM 就是希望将传统的 K8s YAML 配置抽象成两部分：开发者和运维，开发者的配置中只包含与业务最相关的内容，而运维的配置中则包含与运行环境相关的内容。本质上是希望将开发者和运维的界线分得更清楚，让不同的角色更专注于自己的领域。在我看来 OAM 的好处当然是降低了普通开发者接入 K8s 的门槛，所谓大道至简，但这种表面上的「简」背后隐藏的复杂性也是不能忽略的。理想情况是某个云服务商能够完全包办所有跟运维有关的事情，用户只需要负责业务开发就好了。但现状还是不管多小的公司都肯定会有专人在负责运维工作。很多年前 Google App Engine 刚诞生时让所有人都眼前一亮，都认为这才是软件开发的未来啊，但即使是 Google 也没能让这个趋势持续下去。最近几年这个趋势又开始回潮，只不过换了一个名字叫做「Serverless」，希望这一次能够持续下去，虽然还有很长的路要走。</p>

<h2>Lightweight coscheduling based on back-to-back queue sorting</h2>

<p><a href="https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/kep/20200116-lightweight-coscheduling-based-on-back-to-back-queue-sorting.md">[链接]</a></p>

<p>自从 K8s 1.15 新增了 <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework">Scheduling Framework</a> 以后，原生调度器的扩展性有了很大程度的增强。这个 KEP 来自阿里云团队，提出了基于 Scheduling Framework 来实现 coscheduling（或者叫做 gang scheduling）。Coscheduling 这个特性对于机器学习任务来说是非常重要的，一个任务通常包含多个 pod，只有当多个 pod 能够同时运行时这个任务才算是正常运行，如果只有部分 pod 可以运行其实是一种资源的浪费。因此 coscheduling 保证的就是一个任务必须满足一定数量的 pod 都能够被调度时才会实际分配资源。这个特性在 K8s 社区早有讨论，也诞生了一些相关联的项目，如 <a href="https://volcano.sh">Volcano</a>（前身是 <a href="https://github.com/kubernetes-sigs/kube-batch">kube-batch</a>）。5 月初这个插件的第一版已经被 <a href="https://github.com/kubernetes-sigs/scheduler-plugins/pull/4">merge</a> 到 scheduler-plugins 项目。</p>

<h2>Scheduler Support for Elastic Quota Management</h2>

<p><a href="https://docs.google.com/document/d/1ViujTXLP1XX3WKYUTk6u5LTdJ1sX-tVIw9_t9_mLpIc/edit?usp=sharing">[链接]</a></p>

<p>同样是与 K8s 相关的一个讨论，也同样来自阿里云团队。<code>ResourceQuota</code> 是 K8s 目前提供的一种限制某个 namespace 最大资源使用量的方式，但是在实际的多租户场景中，<code>ResourceQuota</code> 往往显得不够灵活。很多时候我们是希望给每个租户一个可以保证（guarantee）的最小资源量，以及一个超卖的最大资源量。当某个租户的资源比较空闲时，就允许其它租户临时租用。但是调度器也要保障这个租户有能力在必要的时候可以拿回这些被租用的资源，这通常是通过抢占（preemption）的方式来实现。这个提案就提出了扩展 <code>ResourceQuota</code> 来实现类似功能的想法。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maybe News Issue #1]]></title>
    <link href="https://blog.xiaogaozi.org/2020/05/21/maybe-news-issue-1/"/>
    <updated>2020-05-21T17:34:22+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/05/21/maybe-news-issue-1</id>
    <content type="html"><![CDATA[<blockquote><p>「Maybe News」是一个定期（或许不定期）分享一些可能是新闻的知识的<a href="/categories/maybe-news/">系列文章</a>，名字来源于我非常喜欢的一个国内的音乐厂牌<a href="https://en.wikipedia.org/wiki/Maybe_Mars">「兵马司」</a>（Maybe Mars）。你也可以通过<a href="https://digest.xiaogaozi.org/maybe-news">邮件订阅</a>它。</p></blockquote>

<!-- more -->


<h2>CFS: A Distributed File System for Large Scale Container Platforms</h2>

<p><a href="https://dl.acm.org/doi/10.1145/3299869.3314046">[链接]</a></p>

<p>跟<a href="https://blog.xiaogaozi.org/2020/04/26/weekly-reading-list-issue-1/">上次介绍</a>的 FoundationDB Record Layer 一样，这篇来自京东团队的论文也是发表在 SIGMOD 2019，介绍了一个为大规模容器平台设计的分布式文件系统。</p>

<p>系统整体由 3 部分组成：元数据子系统（metadata subsystem）、数据子系统（data subsystem）、资源管理器（resource manager）。元数据子系统负责维护 inode 和 dentry（directory entry），数据子系统负责存储数据块，资源管理器负责处理客户端的各种文件操作请求以及维护前面两个子系统的状态。元数据子系统和数据子系统都是多 partition 的分布式系统，多个元数据和数据的 partition 逻辑上共同组成一个卷（volume），这个卷即是对客户端（容器）可见的存储单元并且可以被挂载，通过传统的 POSIX 接口访问。</p>

<p>因为上述 3 部分组件内部其实都是一个分布式系统，因此都用到了 Raft 作为一致性协议，资源管理器还用到了 RocksDB 作为本地持久化存储。稍微特殊的是数据子系统根据不同类型的写操作选择了不同的复制方案，论文里把这个叫做 Scenario-Aware Replication，具体讲就是顺序写操作（比如 append）用的是 primary-backup，而覆盖（overwrite）操作用的是 Raft。</p>

<p>系统的另一个亮点是基于资源利用率的 partition 分配策略，论文中叫做 Utilization-Based Placement。传统的 partition 分配策略通常是哈希，这种策略的优点是简单但是当扩缩容时必须进行 rebalance。CFS 的做法是元数据和数据子系统定期上报内存、磁盘使用率到资源管理器，当需要创建新的 partition 时根据资源利用率选择最低的那个节点，这样设计的好处是不再需要 rebalance。但是对于这种设计方案是否会造成数据不均衡表示存疑，论文中也没有做过多论述。</p>

<p>为了尽量减少客户端的网络交互，不让某个系统组件成为瓶颈，客户端会缓存元数据子系统、数据子系统和资源管理器的信息到本地，当执行文件操作时会优先读取本地缓存。当然某些组件（比如资源管理器）还是有可能在某一天成为瓶颈，但是基于京东的经验这件事情基本上不会发生。</p>

<p>在与 Ceph 的评测中，CFS 平均有 3 倍的 IOPS 提升，特别是多客户端和随机读写的场景。这很大程度上得益于元数据和数据节点分离的设计，且 CFS 的元数据是全内存存储，而 Ceph 并不是。</p>

<p>分布式文件系统一直都是比较重要的基础组件，在分布式数据库、大数据、机器学习领域有广泛应用。常见的分布式文件系统如 HDFS、Ceph，在如今这个全面推行容器化的时代越来越显得捉襟见肘。容器化一个很大的特点是快速扩缩容，传统的存储系统在这一点上是非常不友好的，因此才会有越来越多针对容器化场景的基础组件诞生（具体可以访问 <a href="https://www.cncf.io">CNCF</a> 查看），这里介绍的 CFS 是一个例子，另一个类似的是 <a href="https://juicefs.com">JuiceFS</a>。</p>

<p>CFS 目前属于 CNCF 下的 <a href="https://www.cncf.io/sandbox-projects">sandbox 项目</a>，且已经<a href="https://github.com/chubaofs/chubaofs">开源</a>，使用 Go 语言编写。</p>

<h2>tensorflow/community #237: RFC: Sparse Domain Isolation for Supporting large-scale Sparse Weights Training</h2>

<p><a href="https://github.com/tensorflow/community/pull/237">[链接]</a></p>

<p>推荐系统大规模稀疏特征分布式训练一直是工业界一件有挑战的事情，大公司内部自研的训练框架大多已经解决了这个问题，但是在开源社区问题仍然存在。TensorFlow 作为也许目前最流行的深度学习训练框架，社区里也早有相关的讨论（比如 <a href="https://github.com/tensorflow/tensorflow/issues/19324">#19324</a>、<a href="https://github.com/tensorflow/tensorflow/issues/24539">#24539</a>、<a href="https://github.com/tensorflow/tensorflow/pull/24915">#24915</a>），但基本都以烂尾告终。最新的 RFC #237 来自腾讯，区别于现有的一些开源实现（比如阿里巴巴的 <a href="https://github.com/alibaba/x-deeplearning">XDL</a>、字节跳动的 <a href="https://github.com/bytedance/byteps">BytePS</a>、蚂蚁金服的 <a href="https://github.com/sql-machine-learning/elasticdl">ElasticDL</a>）完全自己重新造了一个 parameter server，腾讯的方案最大限度复用了 TensorFlow 现有的组件，对用户的代码侵入也最小。目前这个 RFC 还在讨论中，有兴趣可以订阅 PR。</p>

<h2>深入云原生 AI：基于 Alluxio 数据缓存的大规模深度学习训练性能优化</h2>

<p><a href="https://mp.weixin.qq.com/s/2Pj8erPbYuMo7mBJvweJgQ">[链接]</a></p>

<p>机器学习模型训练由于依赖大量的数据作为输入，因此数据 I/O 的性能会直接影响模型训练的效率。有时间会发现计算设备的算力升级了，但是数据 I/O 跟不上了，反而拖慢了整个训练流程。阿里云团队分享的这篇文章便是他们在使用 Alluxio（试图）加速数据 I/O 的过程中的经验，虽然最后的优化结果性能指标其实也只是基本跟本地读取持平。</p>

<h2>Rob Pike interview: “Go has indeed become the language of cloud infrastructure”</h2>

<p><a href="https://evrone.com/rob-pike-interview">[链接]</a></p>

<p>没啥好介绍的了，值得一读的一篇采访。文中有两个有趣的问题：</p>

<ul>
<li><strong>对于 Rust 宣称的「没有 GC」的设计有什么看法</strong>：Rob Pike 只是表示了他对 Rust 很感兴趣，其它意见不便发表。</li>
<li><strong>如果可以时间旅行到最初设计 Go 的时候想给自己一个什么忠告</strong>：无视那些仇恨者（haters），只需要聆听那些理解以及和你有共同目标的人的声音。不可能每一个人都认同你正在做的事情，但是那些鼓励你前进的人会是提供给你非常棒（fantastic）的想法、能量和灵感的源泉。</li>
</ul>


<h2>孤芳「自赏」：盯鞋音乐的前世与今生</h2>

<p><a href="https://www.gcores.com/articles/121368">[上]</a> <a href="https://www.gcores.com/articles/123770">[下]</a></p>

<p>这两篇文章来自「竟然还能聊游戏」的机核，相对系统地介绍了「盯鞋（shoegaze）」这种音乐风格，作为目前可能是除了后朋克以外我最喜欢的音乐风格非常高兴能够有人科普，稍微欠缺的是文中没有提到任何中国的乐队。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maybe News Issue #0]]></title>
    <link href="https://blog.xiaogaozi.org/2020/05/11/maybe-news-issue-0/"/>
    <updated>2020-05-11T14:44:52+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/05/11/maybe-news-issue-0</id>
    <content type="html"><![CDATA[<blockquote><p>前言：从这一期开始这个系列将会有一个正式的名字「Maybe News」，名字来源于我非常喜欢的一个国内的音乐厂牌<a href="https://en.wikipedia.org/wiki/Maybe_Mars">「兵马司」</a>（Maybe Mars）。本身我分享的内容也很有可能是一些旧闻，只不过对于我来说是还未了解的知识罢了。<a href="/2020/04/26/weekly-reading-list-issue-1/">上一期</a>的名字还是维持原样就不做修改。你也可以通过<a href="https://digest.xiaogaozi.org/maybe-news">邮件订阅</a>这个系列的文章。</p></blockquote>

<!-- more -->


<h2>LightRec: a Memory and Search-Efficient Recommender System</h2>

<p><a href="http://staff.ustc.edu.cn/~liandefu/paper/lightrec.pdf">[链接]</a></p>

<p>这篇论文由微软亚洲研究院与中科大共同发表在 <a href="https://www2020.thewebconf.org">WWW 2020</a> 会议上，提出了一种新的表示物品向量的方法，大幅降低存储向量所需空间的同时还显著提升了召回效果。一个直观的数据：LightRec 将 1 千亿 256 维双精度向量的内存占用从 9.5 GB 降到了 337 MB，这是非常惊人的！现在工业界常用的 <a href="https://github.com/nmslib/nmslib">nmslib</a> 和 <a href="https://github.com/facebookresearch/faiss">Faiss</a> 都无法实现如此高的压缩比，因此很多时候都需要借助分布式存储来满足业务场景，如果真的如论文中所描述的一样那单机存储在未来很长一段时间来说都是完全足够的。</p>

<p>这里简单解释一下为什么向量召回对于当下的推荐系统如此重要，传统的召回是基于倒排索引的方式，正如我在<a href="/2020/04/21/how-to-design-a-distributed-index-framework-part-1/">之前的一篇文章</a>中介绍的那样，召回与模型优化目标之间的差异较大导致召回效果始终较差。自从 <a href="https://www.microsoft.com/en-us/research/publication/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data">Learning Deep Structured Semantic Models for Web Search using Clickthrough Data</a> 这篇论文（同样也是由微软研究院发表）提出 DSSM（Deep Structured Semantic Models）以后，将召回与 DNN 进行结合，显著提升了召回的效果，在很多公司的实践中也的确论证了 DSSM 是一个非常有效的召回方式。DSSM 的核心是分别为物品和用户生成向量，再通过 ANN（Approximate Nearest Neighbors）查询相似向量从而实现召回。因此向量的存储和查询效率决定了在线请求的效果和性能，如何平衡向量索引的空间占用和召回效果是非常重要的。</p>

<p>微软研究院的微信公众号有一篇简短的针对这篇论文的<a href="https://mp.weixin.qq.com/s/E43gc16A3OVWgxyfdUxr7g">中文版介绍</a>，有兴趣也可以先看这篇文章。</p>

<h2>TFRT: A new TensorFlow runtime</h2>

<p><a href="https://blog.tensorflow.org/2020/04/tfrt-new-tensorflow-runtime.html">[链接]</a></p>

<p>Google 近期开源了新的 TensorFlow 运行时 TFRT（TensorFlow Runtime），这是一个介于上层用户代码和底层设备之间的执行环境。项目的愿景是实现一个统一的、可扩展的、性能首屈一指（best-in-class）的，同时可跨越多种领域硬件（domain specific hardware）的运行时。未来 TFRT 会成为 TensorFlow 默认的运行时，目前还在集成中。从 ResNet-50 的 inference 测试结果上看平均提升了 28% 的性能。</p>

<h2>Why We Need DevOps for ML Data</h2>

<p><a href="https://tecton.ai/blog/devops-ml-data">[链接]</a></p>

<p>虽然这是一篇产品推广软文（在文章最后一节），但是文章中普及的关于 DevOps 与机器学习之间的关系还是非常有价值的。很多人可能以为机器学习就只是模型算法而已，诚然这是学术研究的基石，但是要真正把机器学习应用到工业界光有算法是远远不够的。Google 著名的 <a href="https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf.">Hidden Technical Debt in Machine Learning Systems</a> 论文已经论述了那些隐藏在模型背后的往往被人忽略的技术，模型规模越大需要付出的工程努力也是越大的（所以很多时候大公司才需要自己造轮子）。作为衍生阅读也可以同时看看 <a href="https://towardsdatascience.com/how-linkedin-uber-lyft-airbnb-and-netflix-are-solving-data-management-and-discovery-for-machine-9b79ee9184bb">How LinkedIn, Uber, Lyft, Airbnb and Netflix are Solving Data Management and Discovery for Machine Learning Solutions</a> 这篇文章。</p>

<h2>Mid-stack inlining in Go</h2>

<p><a href="https://dave.cheney.net/2020/05/02/mid-stack-inlining-in-go">[链接]</a></p>

<p>Dave Cheney 继续科普 Go 的一些实现细节，这次的主题是编译器如何实现 mid-stack inlining。所谓 mid-stack inlining 就是将那些调用了其它函数的函数变成 inline，相对的还有 leaf inlining，即不调用任何其它函数。有兴趣了解 leaf inlining 的可以看 Dave Cheney 的<a href="https://dave.cheney.net/2020/04/25/inlining-optimisations-in-go">上一篇文章</a>。</p>

<h2>Why We Leverage Multi-tenancy in Uber’s Microservice Architecture</h2>

<p><a href="https://eng.uber.com/multitenancy-microservice-architecture">[链接]</a></p>

<p>Uber 介绍了他们在微服务领域实践的一个经验「多租户」，简单讲就是让请求链路上的所有组件和系统都能够感知「租户」这个概念，比如租户可以分为生产环境和测试环境。Uber 列举了两个应用场景：集成测试和 Canary 部署，这两个场景都依赖生产环境的请求，有了租户的概念就可以自动进行请求路由和数据隔离。愿景其实挺美好，但「代价」也是不容忽视，前面讲了要让所有组件和系统都感知就非常依赖基础组件的统一，要解决这个问题很多时候并不单纯是一个技术问题。如何做好不同环境的数据隔离也是一个难题，关于这一点文章并没有做特别详细的介绍。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Weekly Reading List Issue #1]]></title>
    <link href="https://blog.xiaogaozi.org/2020/04/26/weekly-reading-list-issue-1/"/>
    <updated>2020-04-26T12:22:08+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/04/26/weekly-reading-list-issue-1</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>FoundationDB Record Layer: A Multi-Tenant Structured Datastore</h2>

<p><a href="https://arxiv.org/abs/1901.04452">[链接]</a></p>

<p>FoundationDB 2015 年被 Apple <a href="https://techcrunch.com/2015/03/24/apple-acquires-durable-database-company-foundationdb">收购</a>并于 2018 年<a href="https://www.foundationdb.org/blog/foundationdb-is-open-source">开源</a>，作为 Apple 为数不多的开源项目受到广泛关注。简单介绍 FoundationDB 是一个基于 Paxos 的分布式 KV 存储，底层存储结构是 B-tree（是的，并不是 LSM tree），定位上跟 Google 的 Spanner 非常相似。这篇论文发表在 <a href="https://sigmod2019.org/sigmod_industry_list">SIGMOD 2019</a>，介绍的是基于 FoundationDB 的 record-oriented 结构化存储框架（也已经<a href="https://github.com/FoundationDB/fdb-record-layer">开源</a>）。<a href="https://apple.github.io/foundationdb/layer-concept.html">Layer</a> 是 FoundationDB 一个很有特色的概念，在最基本的 KV 上无限扩展更加复杂的数据模型。这个框架整体上有几个亮点：</p>

<ul>
<li>基于 Protocol Buffers 的数据模型定义</li>
<li>丰富的索引类型支持（单字段索引、嵌套字段索引、列表字段索引、聚合索引、rank 索引、全文索引、多字段联合索引等），并且索引是可以跨表的（这里简单将 record type 理解为表）。</li>
<li>基于 Java 的查询 API（并不是 SQL）</li>
</ul>


<p>目前已经被应用在 <a href="https://developer.apple.com/icloud/cloudkit">CloudKit</a>，替代旧的 Cassandra + Solr 架构（旧架构也有<a href="https://dl.acm.org/doi/10.1145/3164135.3164138">一篇论文</a>介绍）。CloudKit 作为一个庞大的存储服务供所有 Apple 生态的应用和用户使用，这也就是论文标题中 Multi-Tenant 的含义。</p>

<h2>Introducing Dispatch</h2>

<p><a href="https://netflixtechblog.com/introducing-dispatch-da4b8a2a8072">[链接]</a></p>

<p>Incident 管理一直是 DevOps 领域比较热门的话题，Netflix 开源了他们自己的 incident 管理工具 <a href="https://github.com/Netflix/dispatch">Dispatch</a>，更早之前 LinkedIn 也<a href="https://engineering.linkedin.com/blog/2017/06/open-sourcing-iris-and-oncall">开源</a>过类似的东西。</p>

<h2>Agent57: Outperforming the human Atari benchmark</h2>

<p><a href="https://deepmind.com/blog/article/Agent57-Outperforming-the-human-Atari-benchmark">[链接]</a></p>

<p>大众对于 DeepMind 的认知恐怕就是<a href="https://en.wikipedia.org/wiki/AlphaGo">下下围棋</a>、<a href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii">打打星际</a>，最近又搞起了雅达利的游戏，可以说是把强化学习玩儿出花儿了。最新一代的 Agent57 已经可以在全部 57 个游戏里战胜人类玩家。</p>

<h2>An Illustrated Guide to Graph Neural Networks</h2>

<p><a href="https://medium.com/dair-ai/an-illustrated-guide-to-graph-neural-networks-d5564a551783">[链接]</a></p>

<p>Graph Neural Networks（GNN）最近几年已经火得不行，Amazon 也开源了相关的框架 <a href="https://www.dgl.ai/">DGL</a>。这篇文章以一种简单的示意图的形式介绍什么是 GNN，帮助不了解 GNN 的人建立一个简单的认知。</p>

<h2>Debugging with Delve</h2>

<p><a href="https://tpaschalis.github.io/delve-debugging">[链接]</a></p>

<p><a href="https://github.com/go-delve/delve">Delve</a> 是一个 Go 语言的 debugger，Go 官方也<a href="https://golang.org/doc/gdb">推荐</a>优先考虑使用它而不是 GDB。这篇文章简单介绍了 Delve 的基本功能，其实跟 GDB 的使用方式很类似，但是 Delve 的亮点在于可以理解 Go 语言的语义以及调试 goroutine。</p>

<h2>gofiber/fiber</h2>

<p><a href="https://github.com/gofiber/fiber">[链接]</a></p>

<p>Fiber 是（又）一个 Go 语言的 HTTP 框架，设计上很大程度受了 Node.js 中非常流行的 <a href="https://expressjs.com">Express</a> 启发（API 非常相似）。得益于底层使用的 <a href="https://github.com/valyala/fasthttp">fasthttp</a> 库，在 Fiber 自己的<a href="https://docs.gofiber.io/benchmarks">评测</a>中超越了很多市面上现有的框架。</p>
]]></content>
  </entry>
  
</feed>
