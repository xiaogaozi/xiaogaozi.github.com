<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Recommendation | Freedom]]></title>
  <link href="http://blog.xiaogaozi.org/categories/recommendation/atom.xml" rel="self"/>
  <link href="http://blog.xiaogaozi.org/"/>
  <updated>2020-04-27T15:18:43+08:00</updated>
  <id>http://blog.xiaogaozi.org/</id>
  <author>
    <name><![CDATA[xiaogaozi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[如何设计与实现一个分布式索引框架（三）：正排索引]]></title>
    <link href="http://blog.xiaogaozi.org/2020/04/24/how-to-design-a-distributed-index-framework-part-3/"/>
    <updated>2020-04-24T16:29:40+08:00</updated>
    <id>http://blog.xiaogaozi.org/2020/04/24/how-to-design-a-distributed-index-framework-part-3</id>
    <content type="html"><![CDATA[<blockquote><p>这是一个<a href="/categories/htdadif/">系列文章</a>，大部分内容都来自我过去在小红书发现 Feed 团队工作期间的实践和经验。在介绍的过程中我会尽量不掺杂过多的业务细节，而专注于这背后我个人一些浅薄的设计思想，希望你在阅读完这些文章以后能够直接或者间接地拓展到不同的场景。</p></blockquote>

<p><a href="/2020/04/22/how-to-design-a-distributed-index-framework-part-2/">上一篇文章</a>介绍了如何定义 schema、查询 API 以及怎样实现倒排索引，本篇将会着重介绍另一种重要的索引类型「正排索引」，以及跟正排索引密切相关的「二级索引」。</p>

<!-- more -->


<h2>正排索引</h2>

<p>正排索引是主键（primary key）到条目的一一映射，在推荐系统中使用正排索引的场景是获取模型计算所需的原始特征（raw feature）。为什么说是原始特征呢？因为这些数据还需要经过特征提取（feature extraction）以后才能作为最终输入给模型的参数，特征提取不在本系列文章的讨论范畴。</p>

<p>这里先简单讲讲什么是<a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">特征</a>。最早我们提到机器学习的时候讲过模型是首先经过离线训练产生，然后用于在线预测去预估用户的喜好。在离线训练阶段算法工程师需要先从训练数据<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>人工筛选出一批对于当前想要训练的模型有意义、有价值的、可衡量的属性，这个过程叫做<a href="https://en.wikipedia.org/wiki/Feature_engineering">「特征工程（feature engineering）」</a>。特征工程考验的是一个算法工程师对于业务数据的理解、经验、数据敏感度以及统计分析能力，很多时候还需要结合大量的 A/B 实验才行。近年来深度学习的兴起已经将特征工程的复杂度降低不少，但特征工程依然是一个非常重要的步骤。这些被筛选出来的属性就是特征，举个直观的例子下面这些都可以作为模型特征使用：用户的地理位置、用户性别、用户看过的内容总曝光/点击/赞/评论的次数等。</p>

<p>正排索引中的条目存储的就是大量的原始特征，这些特征也是在 schema 中定义，基本上 schema 中除了跟倒排索引有关的字段其它都属于特征。因此可以看到正排索引条目的大小是远大于倒排索引条目的。为了保证查询的性能我们依然选择了将正排索引存储在内存中，但是这会带来一个问题，因为正排索引占用的空间可能会很大，我们也是明确知道这些数据是需要常驻在内存中的，对于类似 Java 这种带有 GC 的语言来说这部分数据反而会增加垃圾回收器的压力。这些数据会长期存储在 old generation 中，不仅浪费空间也降低了 GC 的性能。那么我们的目标便是尽量不要让这部分数据对 GC 造成太大的影响，最好是对 GC 不可见的，毕竟「眼不见心不烦」。</p>

<p>一种比较常见的解决方案是「堆外内存（off-heap）」<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。所谓堆外内存就是通过某些特殊的 API 分配独立的内存空间，且这个内存空间对于 GC 是不可见的，当然也就不会影响 GC。听起来这个方法似乎很简单直接，但凡事有好也有坏，绕开 GC 的副作用是你需要自己管理这块儿内存，如何高效地使用堆外内存是一个比较关键的问题。HBase 的 <code>BucketCache</code><sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>是一个值得参考的实现，我们在调研阶段也仔细研究过 <code>BucketCache</code> 的设计，但最终没有直接照搬，有一个非常重要的原因：<code>BucketCache</code> 是为了解决之前 <code>BlockCache</code> 这种 on-heap 缓存方案造成的 GC 性能问题而诞生，本质上也还是一个缓存，既然是缓存就必定要考虑缓存数据的驱逐，因此 <code>BucketCache</code> 的设计方案中包含如何释放内存以及合并 bucket 的逻辑。但是正排索引不是缓存，也就不存在驱逐数据的问题<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>，<code>BucketCache</code> 中的这部分设计对于我们的场景来说其实是多余的，如果完全照搬反而是在系统中引入了一个不必要的复杂组件，增加维护成本<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>。因此我们最终借鉴了一部分 <code>BucketCache</code> 的设计思想同时再结合推荐系统的业务特点实现了一个只读版本的堆外内存，下图是具体的实现方案。</p>

<p><img src="/images/posts/off_heap_design.png" alt="off-heap design" /></p>

<p>上图中最左边蓝色的部分是一个 hash map，key 是正排索引的主键，value 是一个包含与堆外内存地址有关的元信息对象。这个元信息对象中主要有 3 个成员变量：</p>

<ol>
<li>BB Index：BB 是 <a href="https://docs.oracle.com/javase/8/docs/api/java/nio/ByteBuffer.html"><code>java.nio.ByteBuffer</code></a> 的缩写，是 Java 中创建堆外内存的底层 API。在应用的初始化阶段我们会提前申请一块儿大的物理内存空间作为堆外内存，假设这块儿内存的大小是 10GB，在其中会按照一个固定的大小（默认是 10MB）再分割成多个小的 bucket。BB Index 即是某个 bucket 的索引。</li>
<li>Offset：每个 bucket 中存储了很多正排索引条目，offset 是某个条目在当前 bucket 中的偏移。</li>
<li>Length：这个很好理解，就是索引条目的长度。</li>
</ol>


<p>上图中蓝色和黄色的部分还是存储在堆内，只有绿色部分属于堆外。写入数据的流程就是根据索引条目的长度找到空闲的 bucket，然后通过 <code>ByteBuffer.put()</code> 方法将数据存放到堆外内存，并在 hash map 中新增相应的元信息。读取数据的流程是首先查找元信息，然后通过 HBase 中封装的 <a href="https://github.com/apache/hbase/blob/master/hbase-common/src/main/java/org/apache/hadoop/hbase/util/UnsafeAccess.java"><code>UnsafeAccess.copy()</code></a> 方法将数据从堆外拷贝到堆内。当然数据拷贝出来以后并不能直接使用，因为这还只是序列化后的字节流，还需要经过反序列化步骤<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>。</p>

<h2>二级索引</h2>

<p>二级索引的概念在很多数据库系统中也存在，特别是分布式数据库，通常主键用来查询分片的位置，而二级索引用来在某个具体的分片中查询特定的字段。</p>

<p>在推荐系统场景中二级索引的功能类似，只不过不是因为这是一个分布式系统，而是为了查询某些特殊的特征。在传统的机器学习模型中有一类特征是非常重要的，那便是内容在不同维度的统计值。举个例子，我们不仅会统计一篇笔记的总曝光数，还会统计这篇笔记在不同城市、不同性别、不同类型设备的曝光数，这里的城市、性别、设备类型就是维度。并且这些维度是允许交叉的，也就会产生非常多的维度组合。所有这些维度组合起来的统计值是一个大的集合，每次查询时并不需要这个集合中的所有值，而是根据当前用户的画像选取与这个用户相符的值。</p>

<p>如果每次查询时都把所有值从堆外内存中拷贝出来显然是很浪费的，因此我们需要一种方法直接从堆外内存中查询部分值，这就是二级索引的作用。二级索引的字段在 schema 中会标记 <code>secondary_key</code> 属性，上一篇文章中示例的字段类型是 <code>[BreakdownStats]</code>，那这个 <code>BreakdownStats</code> 的定义是什么呢？如下所示：</p>

<p><code>
table BreakdownStats {
  key:SecondaryKey (id: 0);
  value:NoteEngagementStats (id: 1);
}
</code></p>

<p>上面 <code>key</code> 字段的数据类型是 <code>SecondaryKey</code>，这是一个由框架预定义的类型，具体定义如下：</p>

<p><code>
table SecondaryKey {
  type:int (id: 0);
  value:string (id: 1);
}
</code></p>

<p>因此我们可以知道一个二级索引 key 由两部分组成：<code>type</code> 和 <code>value</code>，<code>type</code> 是 key 的类型（通常是可枚举的），<code>value</code> 是具体的值（不可枚举）。继续拿前面的例子举例，「城市」是一种 key 的类型，「上海」是具体的值。于是查询流程相比前面介绍的区别之处在于，通过主键查找以后还需要通过二级索引 key 才能获取到元信息对象，相当于增加了一次 hash map 的查找。一个优化的细节点是在框架内部我们还将二级索引 key 映射到了一个整数，这样便可以将这个整数作为 hash map 的 key 来使用。于是通过刚才的流程便实现了直接获取某个维度（或者维度组合）的统计值的需求。</p>

<p>以上就是本篇要介绍的全部内容，简单回顾一下：</p>

<ul>
<li>基于堆外内存的正排索引</li>
<li>通过二级索引实现查询部分特征</li>
</ul>


<p>至此两种索引已经全部介绍完毕，下一篇文章将会围绕一个更加上层的问题「索引如何快速更新」进行讨论。数据不可能是一成不变的，更新的效率也会直接影响产品体验和业务指标。</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>训练数据往往是用户的历史行为数据，例如用户看过、点过、赞过、评论过的所有内容。<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>除了堆外内存这种方案还有一些其它可参考的解决方案，例如阿里巴巴曾经<a href="https://blog.csdn.net/alitech2017/article/details/80133021">分享</a>过的一些经验（文章中提到的 AliGC 多租户功能近期已经在 <a href="https://github.com/alibaba/dragonwell8/wiki/Alibaba-Dragonwell8-Release-Notes">Alibaba Dragonwell 8.3.3-GA</a> 中开源）；Netflix 的开源框架 <a href="https://hollow.how/advanced-topics/#in-memory-data-layout">Hollow</a>。<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p><code>BucketCache</code> 的详细设计可以参考 <a href="https://issues.apache.org/jira/browse/HBASE-7404">HBASE-7404</a> 这个 issue<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>本质上索引是只读的<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>也许有人会问索引数据难道是不更新的吗？答案是需要更新，有关如何更新索引数据会在下一篇文章中介绍。<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
<li id="fn:6">
<p>频繁从堆外拷贝大量数据并反序列化可能会是一个比较耗时的过程，因此我们在实际使用时还在正排索引上增加了一层堆内的缓存。<a href="#fnref:6" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何设计与实现一个分布式索引框架（二）：Schema、API 及倒排索引]]></title>
    <link href="http://blog.xiaogaozi.org/2020/04/22/how-to-design-a-distributed-index-framework-part-2/"/>
    <updated>2020-04-22T18:16:55+08:00</updated>
    <id>http://blog.xiaogaozi.org/2020/04/22/how-to-design-a-distributed-index-framework-part-2</id>
    <content type="html"><![CDATA[<blockquote><p>这是一个<a href="/categories/htdadif/">系列文章</a>，大部分内容都来自我过去在小红书发现 Feed 团队工作期间的实践和经验。在介绍的过程中我会尽量不掺杂过多的业务细节，而专注于这背后我个人一些浅薄的设计思想，希望你在阅读完这些文章以后能够直接或者间接地拓展到不同的场景。</p></blockquote>

<p>在<a href="/2020/04/21/how-to-design-a-distributed-index-framework-part-1/">上一篇文章</a>中简单介绍了什么是推荐系统以及实现一个推荐系统的核心组件有哪些，文章最后引入了一个非常重要的概念「索引」，本篇将会首先从框架使用者的角度介绍如何定义索引，框架有哪些 API 可以使用以及从设计者的角度介绍如何实现一个简单的倒排索引。</p>

<!-- more -->


<h2>Schema</h2>

<p>在传统的数据库系统中，当我们提到 schema 时通常是指表（table）的逻辑定义，这个定义中会包含这些信息：表名、有哪些列（column）、列名、列的数据类型、主键（primary key）、索引名、索引的列等。非常类似的，在推荐系统中我们也需要这样的信息。框架的使用者需要首先定义好存储的数据实体，如实体名（表名）、实体有哪些字段（列）、字段的名称和数据类型、哪个字段是主键、哪些字段需要创建倒排索引。正如传统数据库系统中通过 SQL 来定义 shcema，我们也需要一种类似的 DDL<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>。经过一番调研和比较以后，我们选用了 <a href="https://google.github.io/flatbuffers">FlatBuffers</a> 作为定义 schema 的语言。同 <a href="https://developers.google.com/protocol-buffers">Protocol Buffers</a>（以下简称 PB）一样，FlatBuffers 也是 Google 开源的一种序列化协议，支持多种主流语言。为什么要选用 FlatBuffers 呢？FlatBuffers 的主页上列举了几个特点，我选取了几个最重要的翻译过来<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>，如果你熟悉 PB、Thrift 这一类 IDL 应该能很明显看出区别。</p>

<ul>
<li><strong>无需反序列化即可访问序列化后的数据</strong>：将 FlatBuffers 同其它协议区分开来的一个重要原因是 FlatBuffers 通过平展的二进制缓冲区（flat binary buffer）表示层级数据（hierarchical data），因此无需反序列化（parsing/unpacking）即可直接访问数据。同时依然支持数据结构的演变（evolution），保持向前和向后兼容性。</li>
<li><strong>高效的内存空间和访问性能</strong>：当访问数据时唯一需要分配的内存就只有数据本身的缓冲区（buffer），不需要任何额外的内存空间（C++ 语言支持，其它语言可能有变化）。FlatBuffers 也非常适合用于 mmap（或者流式处理），允许只有部分缓冲区在内存中。访问序列化后的数据基本等价于访问原始的结构体（struct），只会增加一次额外的跳转（一种虚表）来实现数据格式的演变（evolution）和可选字段。FlatBuffers 旨在应用于那些不接受耗费大量时间和空间访问或者构建序列化数据的项目，例如游戏或者任何其它对性能敏感的应用。点击查看<a href="https://google.github.io/flatbuffers/flatbuffers_benchmarks.html">性能测试</a>了解更详细的信息。</li>
</ul>


<p>有兴趣进一步了解设计细节的朋友可以看看官网的 <a href="https://google.github.io/flatbuffers/flatbuffers_internals.html">FlatBuffers Internals</a> 文档，简单总结就是 FlatBuffers 通过一种特殊的序列化格式（针对更小的内存开销和访问性能设计）相比传统 IDL 更加高性能，同时又兼具传统 IDL 的大部分特性（语言无关、强类型、schema evolution）。当然 FlatBuffers 也不是没有缺点，最明显的一个问题就是为了实现高性能，FlatBuffers 的原始 API 对开发者及其不友好，手动编写序列化或者读取数据<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>的代码非常容易出错。不过好在这些问题都可以通过自动生成的代码和框架隐藏起来，不需要直接暴露给用户<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>。前面列举的几个特点为什么对于索引框架如此重要呢？笼统讲当然是为了高性能，不过后面介绍倒排索引的设计时会详细说明一些细节点。</p>

<p>说了这么多还是不知道具体的 schema 长什么样子，下面以一个实际的例子来说明。</p>

<p><code>
table NoteInfo {
  note_id:string (id: 0, primary_key);
  ...
  note_gender:NoteGender (id: 29, index_attribute);
  taxonomies:[KeyValueEntry] (id: 30, index_key);
  ...
  breakdown_stats:[BreakdownStats] (id: 47, secondary_key);
}
</code></p>

<p>上面是一个完整的索引实体定义，也就是小红书里用户创建的笔记（note）。每一行定义了实体中的字段名称、数据类型以及可选的属性标记。例如 <code>note_id</code> 这个字段是笔记的 ID，数据类型是 <code>string</code>，<code>id: 0</code> 是字段在 FlatBuffers 中的唯一 ID，<code>primary_key</code> 表示这个字段是主键。类似的后面列举的几个字段也具有某些特殊含义，例如 <code>NoteGender</code> 是一个枚举值，<code>index_attribute</code> 表示这是一个索引属性；<code>[KeyValueEntry]</code> 是一个 <code>KeyValueEntry</code> 类型的数组，<code>index_key</code> 表示这是一个倒排索引；<code>secondary_key</code> 表示这是一个二级索引。可以看到语法上 FlatBuffers 跟传统 IDL 类似，某种意义上可能还略微简洁一些。定义里有些是 FlatBuffers 官方的语法（如 <code>id: 0</code>），还有一些是我们扩展的（如 <code>primary_key</code>）<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>。这里扩展性是非常有必要的，否则这个 IDL 就只能用于序列化而没法作为一种数据的逻辑定义语言来使用了。这些扩展的语法具体是什么意思之后的几篇文章会逐渐展开。</p>

<h2>API</h2>

<p>有了 schema 框架就可以理解索引的数据结构了，但是对于使用者来说其实更加关心的是如何「查询」数据。推荐系统的业务特点是一个读远大于写的场景，且在线请求中只会涉及读数据而不涉及写数据，即请求都是只读的。结合上一篇文章的介绍，使用者真正需要用到的 API 基本就是下面几种：</p>

<ol>
<li>查询正排索引</li>
<li>查询倒排索引</li>
<li>查询二级索引</li>
</ol>


<p>以 Java 语言为例，实际的 API 大概长这样：</p>

<p><code>java
QueryApi.queryByPrimaryKey(Object primaryKey)
QueryApi.queryByIndexKey(String indexKeyName, Object indexKey, long limit, Function&lt;IndexPayload&lt;?&gt;, Boolean&gt; filter)
QueryApi.queryBySecondaryKey(Object primaryKey, String secondaryKeyName, List&lt;SecondaryKey&gt; secondaryKeys)
</code></p>

<p>第 1 个 API 通过主键查询正排索引；第 2 个 API 通过倒排索引的字段 key 来查询倒排索引，同时还限定了查询的索引条目数以及一个用户自定义的过滤器；第 3 个 API 通过主键和二级索引 key 查询二级索引。</p>

<p>当然除了以上列举的最基本的 API 以外我们还提供了一些额外的接口，例如为了优化批量查询性能的批量查询接口，为了监控和可视化的索引统计信息查询接口。</p>

<h2>倒排索引</h2>

<p>假设给你一份序列化好的索引数据，要怎么创建倒排索引呢？这里有几个关键的问题需要思考：</p>

<ol>
<li>如何解析序列化的数据？</li>
<li>如何知道哪些字段需要创建倒排索引？</li>
<li>如何在运行时读取需要创建倒排的字段的值？</li>
<li>倒排索引在内存中的数据结构是什么？</li>
<li>倒排索引的条目列表如何排序？</li>
<li>如何实现在查询倒排索引的同时对条目进行过滤？</li>
</ol>


<p>第 1 个和第 2 个问题结合前面介绍 schema 时的知识应该很容易解答，只要框架能够提前获取到数据的 schema<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>，就能对索引数据有一个全局的了解，并能够事先知道哪些字段需要创建倒排索引。</p>

<p>第 3 个问题需要通过 FlatBuffers 提供的<a href="https://github.com/google/flatbuffers/blob/master/reflection/reflection.fbs">反射 API</a> 来解决<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup>，配合 shcema 就能够从实际的数据中获取某个字段的值。还记得前面没有细讲的一个问题吗？为什么我们选用了 FlatBuffers 作为序列化协议，一个非常重要的原因就是<strong>无需反序列化即可访问序列化后的数据</strong>。在创建倒排索引时这个需求尤其强烈，一个完整的定义有可能包含几十甚至上百个字段，每个字段的大小都是不同的，但是这其中可能只有个位数的字段需要创建倒排索引，如果使用传统的 IDL 反序列化整个对象的时间和空间开销将会非常大，特别是对于有 GC 的语言来说<sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup>。因此在这一点上 FlatBuffers 基本完美解决了这个问题。</p>

<p>第 4 个问题思考的角度需要从查询性能出发，既然是索引那必然追求的是查询时间复杂度最小，那就没有比 O(1) 更小的复杂度了。能够实现 O(1) 查找的数据结构最常见的就是 hash map<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup>，在不同语言中这都是非常基础的数据结构，基本不用操心是否需要自己从头开始实现。Hash map 的 key 就是倒排索引 key，value 就是索引的条目列表。而 value 应该用什么数据结构呢？倒排索引的 value 一定是有序的，且通常是倒序排列，最简单的场景用 array 其实就够了，如果需要动态增删那你可能会想到类似 <a href="https://en.wikipedia.org/wiki/Skip_list">skip list</a> 这样的数据结构。这里有一个细节点需要注意，同一个条目是有可能同时出现在不同的倒排索引中的，因此做好对象复用是节省内存非常关键的点。</p>

<p>回答第 5 个问题前可以先回到介绍 schema 时举的例子，倒排索引的字段是一个特殊的数据结构 <code>[KeyValueEntry]</code>，那么这个 <code>KeyValueEntry</code> 具体是什么呢？</p>

<p><code>
table KeyValueEntry {
  key:string (key);
  value:double;
}
</code></p>

<p>这是一个由用户自定义的数据结构，只有两个字段 <code>key</code> 和 <code>value</code>，前者即是倒排索引 key，而后者即是倒排索引条目的 score，同一个倒排索引 key 下的条目列表将会根据这个 score 从大到小逆序排序。这个特殊的数据结构是框架约定俗成的，只要符合一定条件就可以作为倒排索引的字段类型。</p>

<p>最后一个问题是在推荐系统的业务场景中相当常见的需求，通常查询时会限定查询 top N 的条目，但是对于不同用户这个 top N 可能是不一样的。例如需要过滤掉每个用户历史上曾经有过曝光（impression）的条目，需要根据某些用户画像属性过滤条目等。出于节省内存的原因我们不可能将一个完整定义中的所有字段都直接存放在内存中<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup>，因此限定了只有某些标记了特殊属性的字段才会存储在索引条目中，这也是前面示例中 <code>index_attribute</code> 这个标记的作用。因此一个完整的索引条目数据结构大概是这样（以 Java 语言为例）：</p>

<p>```java
public class IndexPayload<T extends Comparable<T>> implements Cloneable {</p>

<pre><code>private final T primaryKey;
private final Object indexKey;
private final double score;
private final Map&lt;String, Object&gt; attributes;

public Object getAttribute(String attrName) {
    return attributes.get(attrName);
}
</code></pre>

<p>}
```</p>

<p>上面的 <code>attributes</code> 成员变量即是索引属性，key 是标记了索引属性的字段名，value 是对应的值，可以通过 <code>getAttribute()</code> 方法查询这个值。前面介绍的 <code>QueryApi.queryByIndexKey()</code> 接口中有一个 <code>filter</code> 参数，数据类型是 <code>Function&lt;IndexPayload&lt;?&gt;, Boolean&gt;</code>，也就是说这个参数是一个函数，输入参数的数据类型是 <code>IndexPayload</code>，返回值的数据类型是 <code>Boolean</code>。用户需要自己实现过滤器的逻辑，通过 <code>IndexPayload</code> 提供的接口来判断是否需要过滤当前条目。</p>

<p>以上就是本篇要介绍的全部内容，简单回顾一下：</p>

<ul>
<li>基于 FlatBuffers 的 schema 定义</li>
<li>根据不同索引类型提供不同的查询 API</li>
<li>如何在运行时创建倒排索引</li>
</ul>


<p>下一篇文章依然是围绕索引来介绍，不过重点将会是正排索引，看似一个 hash map 即可解决的问题其实有很多玄机。</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>为什么不直接用 SQL 呢？首先 SQL 的语法很复杂，很多原语是多余的，这对于使用者来说是不必要的负担。其次我们是实现一个推荐系统而不是一个完备的 DBMS，没必要硬套。最后这个 DDL 需要足够的扩展性来满足针对推荐系统的一些定制需求，关于这一点后面会提到。<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>需要查看原文和所有特点的朋友请转到 FlatBuffers 的官网<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>这里我刻意没有用「反序列化」这个词，理论上 FlatBuffers 是没有反序列化这个概念的，buffer is data（缓冲区即数据）。<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>框架使用者甚至不需要知道底层用的是 FlatBuffers<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>同样的设计思想在 <a href="https://github.com/FoundationDB/fdb-record-layer/blob/master/docs/Overview.md">FoundationDB Record Layer</a> 里也有所体现，只不过它使用的是 PB 作为 DDL，相比之下 FlatBuffers 的语法会更加简洁。<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
<li id="fn:6">
<p>实际在实现时是通过框架暴露的注册 schema 的 API 由用户来提供这些信息<a href="#fnref:6" rev="footnote">&#8617;</a></p></li>
<li id="fn:7">
<p>截止 2020 年 4 月 FlatBuffers 官方依然没有提供 Java 语言的反射 API，有需要的朋友可以参考 <a href="https://github.com/google/flatbuffers/pull/4019">#4019</a> 这个 PR，虽然这个 PR 也烂尾了。<a href="#fnref:7" rev="footnote">&#8617;</a></p></li>
<li id="fn:8">
<p>如果你使用的是 Java 语言，即使用对象池这个问题也是没法优化的，类似 PB 这样的协议对于对象池的支持可以说是相当不友好。<a href="#fnref:8" rev="footnote">&#8617;</a></p></li>
<li id="fn:9">
<p>这里暂时忽略掉哈希碰撞<a href="#fnref:9" rev="footnote">&#8617;</a></p></li>
<li id="fn:10">
<p>至于完整的数据存放在哪里后续的文章中会介绍<a href="#fnref:10" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何设计与实现一个分布式索引框架（一）：概览]]></title>
    <link href="http://blog.xiaogaozi.org/2020/04/21/how-to-design-a-distributed-index-framework-part-1/"/>
    <updated>2020-04-21T17:08:24+08:00</updated>
    <id>http://blog.xiaogaozi.org/2020/04/21/how-to-design-a-distributed-index-framework-part-1</id>
    <content type="html"><![CDATA[<blockquote><p>这是一个<a href="/categories/htdadif/">系列文章</a>，大部分内容都来自我过去在小红书发现 Feed 团队工作期间的实践和经验。在介绍的过程中我会尽量不掺杂过多的业务细节<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>，而专注于这背后我个人一些浅薄的设计思想，希望你在阅读完这些文章以后能够直接或者间接地拓展到不同的场景。</p></blockquote>

<p>在介绍什么是索引框架之前先了解一下我们当时面临的业务场景<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>，业界现在的 <a href="https://en.wikipedia.org/wiki/Activity_stream">feed 流</a>产品已经逐步从非个性化全面过渡到个性化，所谓的个性化 feed 其实就是<strong>基于机器学习的推荐系统</strong>。</p>

<!-- more -->


<p>先讲讲什么是推荐系统，用一个词概括就是「投其所好」。当你遇到一个跟你志趣相投的人时，那这个人感兴趣的东西很有可能也是你感兴趣的，这是「基于人」的维度进行推荐，微信的「朋友圈」就是这么一个简单的思路<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>。也有可能一个人他从来没见过你，你们也不互相认识，但是如果他能够知道你过去看过、喜欢过的东西，那他也很有可能可以推断出你未来感兴趣的东西，这是「基于历史行为」的维度进行推荐。我们可以通过制定一些人工的规则来实现推荐，但是用户的喜好是千奇百怪的<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>，有大量长尾的需求是人工规则无法覆盖的<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>。因此我们需要让计算机学习如何制定这些规则，这是对「机器学习」这个概念非常浅显的解释。一个完整的机器学习流程简单概括包含「离线」和「在线」两部分，离线部分是通过大量的用户数据来让计算机找寻其中的规律和共性，最终产出「模型」；在线部分是通过输入当前用户的数据给模型，让模型计算出一个预测值，这个预测值用来衡量我们想要推荐的内容是否符合这个用户的兴趣。这个系列的文章将会主要围绕在线部分，离线部分如果有机会会在以后的文章中介绍。</p>

<p>前面提到在线部分的核心逻辑是模型计算<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>，但在计算之前还有一个非常重要的工作是筛选候选集，通常叫做「召回（recall）」。所谓召回就是从一个很大的集合中通过一定的条件选取一个子集，为什么要有召回这一步呢？本质上是因为模型计算是一个非常耗费时间及资源的过程，如果每次用户请求都对整个集合中的条目进行计算，不仅浪费资源，所需的时间对于用户来说也是无法接受的<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup>。大部分情况<sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup>下我们对于推荐系统一次请求的时间要求是控制在 100~200ms 左右，如果超过这个时间对业务指标一定会有负面影响。因此有针对性地进行召回就非常关键了，召回需要尽量确保筛选出来的候选集是符合当前用户兴趣的，但同时耗时又是非常短的<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup>。总结一下一次推荐请求的流程如下图所示。</p>

<p><img src="/images/posts/recommendation_system_arch.png" alt="recommendation system architecture" /></p>

<p>实现快速召回的关键是「索引（index）」，正如大部分数据库系统一样，索引是为了实现快速查找的重要组件。在推荐系统中主要有两类索引：正排索引（forward index）和倒排索引（inverted index）<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup>。正排索引通常是用来通过一个主键（primary key）查询一个条目，是「一对一的映射」；倒排索引是用来通过跟条目关联的某些属性查询多个条目，是「一对多的映射」。举个实际的例子，小红书上用户发布的内容叫做「笔记」，每一篇笔记都会生成一个唯一的 ID，这个 ID 就是这篇笔记的主键，正排索引即是一个从笔记 ID 到笔记的映射。而每篇笔记都会有一些同笔记本身相关的属性，比如分类（category），一些常见的分类有：旅行、美妆、摄影、美食等。倒排索引即是一个从多个属性到多篇笔记的映射，如「旅行」分类可以映射到所有属于这个类别的笔记列表。对于召回来说主要依赖倒排索引，而正排索引将会在模型计算的前置步骤特征提取中用到<sup id="fnref:11"><a href="#fn:11" rel="footnote">11</a></sup>。</p>

<p><img src="/images/posts/rec_sys_index.png" alt="recommendation system index" /></p>

<p>讲到这里也基本上把索引框架需要实现的功能介绍得差不多了，其实需求很简单：给定一个集合然后在这个集合上创建正排和倒排索引，并暴露相应的查询接口。下一篇将会详细介绍如何定义索引、框架的 API 应该有哪些以及如何实现一个简单的倒排索引。</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>但其实能真正应用到业务中才是检验设计的唯一标准<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p><del>刚说完不聊业务就打脸</del><a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>当然前提是你的好友数得像<a href="https://baike.baidu.com/item/%E5%BD%AD%E7%A3%8A/6238051">彭磊</a>一样少<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>这几年有一个很恶心的词叫「千人千面」也是同样的意思<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>满足好长尾需求也是推荐系统面临的一大挑战<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
<li id="fn:6">
<p>你可能看到的表示模型计算的术语有：推理（inference）、预测（prediction）<a href="#fnref:6" rev="footnote">&#8617;</a></p></li>
<li id="fn:7">
<p>想象一下你打开某个 app 的首页需要等待数分钟才能显示出来<a href="#fnref:7" rev="footnote">&#8617;</a></p></li>
<li id="fn:8">
<p>大部分情况 = P95/P99<a href="#fnref:8" rev="footnote">&#8617;</a></p></li>
<li id="fn:9">
<p>召回的耗时通常比模型计算小一到两个数量级<a href="#fnref:9" rev="footnote">&#8617;</a></p></li>
<li id="fn:10">
<p>如果你接触过搜索引擎，对于这两类索引也不会感到陌生。<a href="#fnref:10" rev="footnote">&#8617;</a></p></li>
<li id="fn:11">
<p>特征提取（feature extraction）是一个非常重要的步骤，这里暂时不会过多介绍。<a href="#fnref:11" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
</feed>
