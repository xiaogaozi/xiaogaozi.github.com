<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Freedom]]></title>
  <link href="https://blog.xiaogaozi.org/atom.xml" rel="self"/>
  <link href="https://blog.xiaogaozi.org/"/>
  <updated>2020-06-17T14:24:05+08:00</updated>
  <id>https://blog.xiaogaozi.org/</id>
  <author>
    <name><![CDATA[xiaogaozi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Maybe News Issue #4]]></title>
    <link href="https://blog.xiaogaozi.org/2020/06/17/maybe-news-issue-4/"/>
    <updated>2020-06-17T14:07:52+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/06/17/maybe-news-issue-4</id>
    <content type="html"><![CDATA[<blockquote><p>「Maybe News」是一个定期（或许不定期）分享一些可能是新闻的知识的<a href="https://blog.xiaogaozi.org/categories/maybe-news/">系列文章</a>，名字来源于我非常喜欢的一个国内的音乐厂牌<a href="https://en.wikipedia.org/wiki/Maybe_Mars">「兵马司」</a>（Maybe Mars）。你也可以通过<a href="https://digest.xiaogaozi.org/maybe-news">邮件订阅</a>它。</p></blockquote>

<!-- more -->


<h2>AliGraph: A Comprehensive Graph Neural Network Platform</h2>

<p><a href="https://dl.acm.org/doi/10.1145/3292500.3340404">[链接]</a></p>

<p>AliGraph 是阿里巴巴团队研发的 GNN（Graph Neural Network）分布式训练框架（虽然标题里是「平台」但感觉还算不上），论文发表在 KDD 2019 和 PVLDB 2019。</p>

<p>论文开篇便提出了当下 GNN 模型训练的 4 个挑战：</p>

<ol>
<li>如何提高大规模图模型的训练效率及优化空间占用？</li>
<li>怎样优雅地将异构（heterogeneous）信息组合到一个统一的 embedding 结果中？</li>
<li>如何将结构化的拓扑（topological）信息与非结构化的属性（attribute）信息统一来共同定义那些需要保留的信息？</li>
<li>如何设计一个高效的增量更新动态图的 GNN 方法？</li>
</ol>


<p>后面的篇章便是详细介绍 AliGraph 如何解决以上这 4 个问题。框架从上至下整体分为 3 层：算子（operator）、采样（sampling）、存储（storage）。算子层包含常见的 GNN 运算操作，采样层包含几种预设的采样算法，存储层主要关注如何高效对大规模图进行分布式存储。在这 3 层基础之上可以实现任意的 GNN 算法以及应用。</p>

<p>存储层因为是要解决一个图的分布式存储问题，因此首先要将图进行分割（partition）。AliGraph 内置了 4 种图分割算法：<a href="https://dm.kaist.ac.kr/kse625/resources/metis.pdf">METIS</a>、<a href="https://www.usenix.org/conference/osdi12/technical-sessions/presentation/gonzalez">顶点切割和边切割</a>、<a href="https://dl.acm.org/doi/10.1145/2503210.2503293">2D 分割</a>、<a href="https://dl.acm.org/doi/10.1145/2339530.2339722">流式分割</a>。这 4 种算法分别适用于不同的场景，METIS 适合处理稀疏（sparse）的图，顶点切割和边切割适合密集（dense）的图，2D 分割适合 worker 数量固定的场景，流式分割通常应用在边（edge）频繁更新的图。用户需要根据自己的需求选择恰当的分割算法，当然也可以通过插件的形式自己实现。</p>

<p>另一个存储层关心的问题是如何将图结构和属性（attribute）共同存储。这里讲的图结构即顶点和边的信息，这是最主要的图数据。同时每个顶点也会附加一些独特的属性，例如某个顶点表示一个用户，那附加在这个用户上面的属性就是类似性别、年龄、地理位置这样的信息。如果直接将属性信息和图结构一起存储会造成非常大的空间浪费，因为从全局角度看同一种类型的顶点的属性是高度重合的。并且属性与图结构的大小差异也非常明显，一个顶点 ID 通常占用 8 字节，但是属性信息的大小从 0.1KB 到 1KB 都有可能 。因此 AliGraph 选择将属性信息单独存储，通过两个单独的索引分别存储顶点和边的属性，而图结构中只存储属性索引的 ID。这样设计的好处自然是显著降低了存储所需的空间，但代价就是降低了查询性能，因为需要频繁访问索引来获取属性信息。AliGraph 选择增加一层 LRU 缓存的方式对查询性能进行优化。</p>

<p>存储层关心的最后一个问题也是跟查询性能有关。在图算法中一个顶点的邻居（neighbor）是非常重要的信息，邻居可以是直接（1 跳）的也可以是间接（多跳）的，由于图被分割以后本地只会存储直接的邻居，当需要访问间接邻居的时候就必须通过网络通信与其它存储节点进行交互，这里的网络通信代价在大规模图计算中是不容忽视的。解决思路也很直接，即在每个节点本地缓存顶点的间接邻居，但要缓存哪些顶点的邻居，要缓存几个邻居是需要仔细考量的问题。AliGraph 没有使用目前常见的一些缓存算法（如 LRU），而是提出了一种新的基于顶点重要性（importance）的算法来对间接邻居进行缓存。在有向图中计算一个顶点重要性的公式是 <code>入邻居的个数 / 出邻居的个数</code>，注意这里的邻居个数同样可以是直接的或者间接的。当这个公式的计算结果大于某个用户自定义的阈值时即认为这是一个「重要」的顶点。从实际测试中得出的经验值是通常只需要计算两跳（hop）的邻居个数就够了，而阈值本身不是一个特别敏感的数值，设置在 0.2 左右是对于缓存成本和效果一个比较好的平衡。选出所有重要的顶点以后，最终会在所有包含这些顶点的节点上缓存 <em>k</em> 跳的出邻居（out-neighbor）。</p>

<p>GNN 算法通常可以总结为 3 个步骤：采样（sample）某个顶点的邻居，聚合（aggregate）这些采样后的顶点的 embedding，将聚合后的 embedding 与顶点自己的进行合并（combine）得到新的 embedding。这里可以看到采样是整个流程中的第一步，采样的效果也会直接影响后续计算的 embedding 结果。AliGraph 抽象了 3 类采样方法：遍历采样（traverse）、近邻采样（neighborhood）和负采样（negative）。遍历采样是从本地子图中获取数据；近邻采样对于 1 跳的邻居可以从本地存储中获取，多跳的邻居如果在缓存中就从缓存中获取否则就请求其它节点；负采样通常也是从本地挑选顶点，在某些特殊情况下有可能需要从其它节点挑选。</p>

<p>在采样完邻居顶点以后就是聚合这些顶点的 embedding，常用的聚合方法有：element-wise mean、max-pooling 和 LSTM。最后是将聚合后的 embedding 与顶点自己的进行合并，通常就是将这两个 embedding 进行求和。为了加速聚合和合并这两个算子的计算，AliGraph 应用了一个物化（materialization）中间向量的策略，即每个 mini-batch 中的所有顶点共享采样的顶点，同样的聚合和合并操作的中间结果也共享，这个策略会大幅降低计算成本。</p>

<p>在最后的评估环节用了两个来自淘宝的数据集，两个数据集之间只有大小的区别，大数据集是小数据集的 6 倍左右。大数据集的基础数据是：4.8 亿个用户顶点，968 万个商品顶点，65.8 亿条用户到商品的边，2.3 亿条商品到商品的边，用户平均有 27 个属性，商品平均有 32 个属性。当使用 200 个 worker（节点配置论文中没有说明）时大数据集只需要 5 分钟即可将整个图构建完毕，相比之下以往的一些方案可能需要耗费数小时。基于顶点重要性的缓存算法相比 LRU 这些传统算法也是明显更优。3 类采样方法的性能评估结果从几毫秒到几十毫秒不等，但最长也不超过 60 毫秒，并且采样性能与数据集大小不太相关。聚合和合并算子相比传统的实现也有一个数量级的性能提升，这主要得益于前面提到的物化策略。</p>

<p>AliGraph 目前已经开源（一部分？）但是换了一个名字叫做 <a href="https://github.com/alibaba/graph-learn">graph-learn</a>，跟大多数深度学习框架一样，底层使用 C++ 语言实现并提供 Python 语言的 API，目前支持 TensorFlow，未来会支持 PyTorch。有意思的是刚刚开源不久就有人提了一个 <a href="https://github.com/alibaba/graph-learn/issues/16">issue</a> 希望能够跟另外几个流行的 GNN 框架进行比较，但是项目成员的回答比较含糊。</p>

<h2>Building Uber’s Go Monorepo with Bazel</h2>

<p><a href="https://eng.uber.com/go-monorepo-bazel">[链接]</a></p>

<p>Uber 应该是除了 Google 以外很早选择在后端服务中大规模使用 Go 语言的公司之一，并贡献了很多著名的 Go 语言项目（如 <a href="https://github.com/uber-go/zap">zap</a>、<a href="https://github.com/jaegertracing/jaeger">Jaeger</a>）。早在 2017 年，Uber 的 Android 和 iOS 团队就已经只使用一个代码仓库进行开发，俗称 monorepo。实践 monorepo 最著名的公司应该还是 Google，有兴趣可以看看 <a href="https://research.google/pubs/pub45424">Why Google Stores Billions of Lines of Code in a Single Repository</a> 这篇文章。现在后端团队也开始采用 monorepo 来管理 Go 语言项目，但是和客户端团队的不同之处在于没有用 <a href="https://buck.build">Buck</a> 而是用 <a href="https://bazel.build">Bazel</a>（前者是 Facebook 开源，后者是 Google 开源）。这篇文章介绍了在 monorepo 中将 Go 语言和 Bazel 结合遇到的一些问题。</p>

<h2>Optimising Docker Layers for Better Caching with Nix</h2>

<p><a href="https://grahamc.com/blog/nix-and-layered-docker-images">[链接]</a></p>

<p>恐怕大多数时候接触容器是从构建一个 Docker 镜像开始的，这一步往往也是最容易被忽视的。为什么我的镜像这么大？为什么每次拉取镜像都要从头开始？这些问题可能会随着使用时间越来越长逐渐浮现出来，要回答它们需要了解 Docker 镜像的一个核心概念「layer」，本质上你在 <code>Dockerfile</code> 里写的每一行命令都会生成一个 layer，一个镜像便是由很多 layer 构成。Layer 之间是有层级关系的，当拉取镜像时如果本地已经存在某个 layer 就不会重复拉取。在传统的 Linux 发行版中安装依赖时 Docker 是不知道具体有哪些文件被修改的，而 <a href="https://github.com/NixOS/nix">Nix</a> 这个特殊的包管理器采用了不一样的设计思路使得安装依赖这件事情对于 Docker layer 缓存非常友好。衍生阅读推荐 Jérôme Petazzoni 写的关于如何减少镜像大小的<a href="https://www.ardanlabs.com/blog/2020/02/docker-images-part1-reducing-image-size.html">系列文章</a>。</p>

<h2>Proposal: Permit embedding of interfaces with overlapping method sets</h2>

<p><a href="https://github.com/golang/proposal/blob/master/design/6977-overlapping-interfaces.md">[链接]</a></p>

<p>Interface 是 Go 语言一个重要的特性，类似很多其它语言中的概念，接口定义好以后是需要通过 struct 来实现的。但不同之处又在于 struct 不需要显式声明实现了什么 interface，只要满足 interface 中定义的接口就行，这个关键设计使得 Go 语言的 interface 使用场景可以非常灵活。跟 struct 一样 interface 也允许嵌套，也就是可以在一个 interface 定义中嵌套另一个 interface。如果同时嵌套了多个 interface，并且这些 interface 之间有重复的接口在编译时是会报错的。实际开发过程中为了规避这个限制可能需要修改 interface 的定义，这对于开发者来说不太友好。上面这个提案允许开发者在不修改代码的情况下避开这个限制，目前这个功能已经在 <a href="https://golang.org/doc/go1.14#language">Go 1.14</a> 中发布。</p>

<h2>VexTab</h2>

<p><a href="https://github.com/0xfe/vextab">[链接]</a></p>

<p>不管是音乐创作还是音乐演奏，乐谱都是一个必不可少的东西。还记得刚学吉他那会儿非常热衷的一件事情就是去网上搜集各种歌曲的六线谱，这些乐谱的格式从最朴素的纯文本到高级的 <a href="https://www.guitar-pro.com">Guitar Pro</a> 格式都有。再后来开始学习扒歌，也面临把扒下来的谱子纪录下来的需求。虽然 Guitar Pro 很好但毕竟是一个收费软件，文件格式也是私有的。就像我更喜欢 Markdown 而不是直接用 Word 一样，一直希望能有一个类似的标记语言用于编写乐谱。VexTab 即是这样一个专门用于编写五线谱和六线谱的语言，也提供一个 JavaScript 库方便嵌入到网页中。有意思的是 VexTab 的作者同时也是 Google 的一名员工。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maybe News Issue #3]]></title>
    <link href="https://blog.xiaogaozi.org/2020/06/10/maybe-news-issue-3/"/>
    <updated>2020-06-10T17:37:27+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/06/10/maybe-news-issue-3</id>
    <content type="html"><![CDATA[<blockquote><p>「Maybe News」是一个定期（或许不定期）分享一些可能是新闻的知识的<a href="https://blog.xiaogaozi.org/categories/maybe-news/">系列文章</a>，名字来源于我非常喜欢的一个国内的音乐厂牌<a href="https://en.wikipedia.org/wiki/Maybe_Mars">「兵马司」</a>（Maybe Mars）。你也可以通过<a href="https://digest.xiaogaozi.org/maybe-news">邮件订阅</a>它。</p></blockquote>

<!-- more -->


<h2>Kudu: Storage for Fast Analytics on Fast Data</h2>

<p><a href="https://kudu.apache.org/kudu.pdf">[链接]</a></p>

<p><a href="https://en.wikipedia.org/wiki/Online_analytical_processing">OLAP</a>（Online Analytical Processing）一直是大数据领域非常重要的应用场景，光有数据也不行，你得「分析」啊。自从有了 Hadoop，OLAP 的工具就一直在演变，从最早的裸写 MapReduce 任务，到 <a href="https://pig.apache.org">Pig</a>、<a href="https://hive.apache.org">Hive</a>、<a href="https://prestosql.io">Presto</a>、<a href="https://impala.apache.org">Impala</a>、<a href="https://druid.apache.org">Druid</a>、<a href="https://clickhouse.tech">ClickHouse</a>，以及今天要介绍的 <a href="https://kudu.apache.org">Kudu</a>。一个明显的趋势是 OLAP 引擎在逐步朝着「去 Hadoop 化」和「实时化」发展，当然这些项目里最新的也已经是 2016 年发布的了，接下来会怎么变化还是个未知数。</p>

<p>先讲讲为什么会有类似 Kudu 这样的项目诞生。传统的 OLAP 引擎因为是构建在 HDFS 上的，要想分析数据首先得将数据存储到 HDFS 上，而这个过程（通常叫做 ETL）往往是比较耗时以及复杂的。同时由于 HDFS 天生不支持随机读写，为了弥补这个「缺陷」，有了 HBase 这样的项目。但 HBase 对于 OLAP 场景是不够友好的，因此往往需要把数据从 HBase 再导入到 HDFS 中，这个过程也可能比较耗时，维护成本也比较高。因此 Kudu 的目标是实现一个即支持随机读写（主要是写），又针对大批量查询进行优化的存储引擎。这种时候 HDFS 就显得很累赘了，这也是为什么越来越多引擎选择不依赖 HDFS 的缘故（Kudu 官网也在 FAQ 中专门<a href="https://kudu.apache.org/faq.html#why-doesnt-kudu-store-its-data-in-hdfs">解释</a>了为什么不用 HDFS）。当然并不是说 HDFS 就没用了，有很多数据还是非常静态的，对于实时性要求也不高，此时用 HDFS 是一种简单经济的选择。</p>

<p>这篇论文虽然介绍的是 Kudu 早期的一些设计思想，但基本上属于最核心的功能。跟很多分布式数据库一样，Kudu 也是受 <a href="https://research.google/pubs/pub39966">Spanner</a> 启发。系统架构上分为一个 Master 服务和若干 Tablet 服务。Master 负责维护元信息，包括 Tablet 节点和数据的。Tablet 服务则负责数据存储，每台节点上会有几十至数百个 tablet，每个 tablet 中包含了若干数据，最大可以达到几十 GB 的规模（这里你可以把 tablet 类比为很多别的系统中的 region 概念）。</p>

<p>跟很多关系数据库一样，Kudu 是有 table 的概念的。但跟很多 NoSQL 数据库不一样的地方是，强制用户必须显式定义 schema。Kudu 一个有意思的设计在于同时支持了 hash 和 range 这两种数据 partition 方法，而不像别的系统只支持其中一种（有关这两种 partition 的介绍可以看我之前的<a href="https://blog.xiaogaozi.org/2020/05/25/how-to-design-a-distributed-index-framework-part-5/">一篇文章</a>）。这样设计的好处是即保留了 hash 的数据均匀分配特点，可以在一定程度上防止读写热点，又保留了 range 对于范围扫描的友好性。</p>

<p>Tablet 服务之间是通过 Raft 来进行数据复制，因此可以认为 Kudu 是一个保证强一致性的存储系统。值得注意的是 Kudu 的默认设置是 500 毫秒的心跳间隔以及 1.5 秒的选举超时，这个跟 Raft 论文推荐的时间相比长了不少（推荐的选举超时是 150~300 毫秒）。当集群扩容时，新节点将会首先进入 <code>PRE_VOTER</code> 状态，等到 log 追上以后再变成 <code>VOTER</code> 状态，这个设计也是 Raft 论文中建议的，不过论文中叫做 learner 或者 non-voting member。Master 服务虽然是单点设计（即状态不是分布式存储），但为了保障高可用也可以通过 Raft 实现多节点状态复制，只不过任意时间只能有一个节点工作。</p>

<p>Kudu 的数据存储引擎是完全自己设计的，没有直接用任何现有的引擎，虽然也能多少看出一些别的引擎的影子。关于这一点可以理解，OLAP 系统区别于 <a href="https://en.wikipedia.org/wiki/Online_transaction_processing">OLTP</a> （Online Transactional Processing）系统的最大不同即在于数据存储的形式，简单理解后者是行式（row-oriented）存储，而前者是列式（column-oriented）存储。著名的 <a href="https://parquet.apache.org">Parquet</a> 就是广泛被用于 OLAP 场景的列式存储格式，Kudu 在实现上也复用了很多 Parquet 的代码。</p>

<p>每个 table 在存储级别会被分割为多个 RowSets，顾名思义每个 RowSets 是由很多行（row）组成，RowSets 之间不会有重复的数据，但主键的范围可能会交叉。</p>

<p>当有新的数据时会首先存储到内存中的 MemRowSets，底层实现是一个使用乐观锁（optimistic locking）的并发（concurrent）B 树。比较特别的一点是数据并不是一开始就按照列式进行存储，MemRowSets 中还是用的行式存储。当数据累积到一定程度 MemRowSets 就会持久化到磁盘上，称之为 DiskRowSets，每个 DiskRowSet 大小上限是 32MB。DiskRowSet 由两部分组成：基础数据（base data）和增量数据（delta stores）。</p>

<p>基础数据是列式格式，即每一列都单独连续存储，每一列内部又划分成了多个小的页（page），有一个 B 树根据行号索引了这些页。每一列可以由用户指定不同的编码（encoding）方法（如 dictionary encoding、bitshuffle、front coding），同时也可以使用通用的压缩算法对数据进行压缩（如 LZ4、gzip、bzip2），基于列的编码及数据压缩是列式存储非常大的一个特点。</p>

<p>增量数据也分为内存和磁盘两种形式。内存中的叫做 DeltaMemStores，这个跟 MemRowSets 的实现一样。磁盘中的叫做 DeltaFiles，是一个二进制类型的列块（column block）。不管是内存还是磁盘上的数据都会有一个额外的从 <code>(row_offset, timestamp)</code> 到 RowChangeList 的映射，<code>row_offset</code> 是某一行在一个 RowSet 中的偏移，RowChangList 是二进制编码以后的增量操作（如更新某一列、删除某一行）列表。同样的，DeltaMemStores 也会持久化到磁盘上变成 DeltaFiles。</p>

<p>这些增量数据会定期跟基础数据进行合并（compation），以防止过多的增量文件。同时 DiskRowSets 之间也会进行合并，目的是清理已经被删除的行以及减少 DiskRowSets 之间的主键交叉范围。</p>

<p>前面提到的将内存中的数据持久化到磁盘及对数据进行合并操作，都是由一组单独的后台任务来完成，但是什么时候执行什么操作是由一个调度器来控制的。有趣的是 Kudu 将调度器的逻辑抽象成了一个<a href="https://en.wikipedia.org/wiki/Knapsack_problem">背包问题</a>，只不过需要权衡的不是背包容量，而是 I/O 带宽。</p>

<p>Kudu 本身只提供编程语言级别的 API（如 Java、C++），而 OLAP 系统中常用的 SQL 需要配合其它项目来实现。Kudu 原生已经跟 Spark 和 Impala 集成，也就是说你可以在这两个系统中通过 SQL 来查询。</p>

<p>最后是性能评测。在 <a href="http://www.tpc.org/tpch">TPC-H</a> 数据集上与 Parquet 进行对比测试，Kudu 平均有 31% 的性能提升，尽管如此 Kudu 团队认为随着 Parquet 的迭代这个差距可能会逐渐缩小。在与 <a href="http://phoenix.apache.org">Phoenix</a> 的对比测试中也有 16~187 倍的性能提升。最后与 HBase 进行的 <a href="https://github.com/brianfrankcooper/YCSB">YCSB</a> 测试是为了看看 Kudu 在 OLTP 场景的性能，虽然它本身并不是为 OLTP 场景而设计，结果上的确也是 HBase 表现更好，但 Kudu P99 6 毫秒的响应时间在某些时候也许可以代替 OLTP 系统。</p>

<p>Kudu 由 Cloudera 公司开发并于 2016 年正式发布，现已捐献给 Apache 基金会，整个系统使用 C++ 语言编写。</p>

<p>顺带说个题外话这两年炒得比较火的 <a href="https://en.wikipedia.org/wiki/Hybrid_transactional/analytical_processing">HTAP</a>（Hybrid Transactional/Analytical Processing），本质上是希望在一个引擎中同时适配 OLTP 和 OLAP 这两个场景。但在我看来就目前的技术现状这个愿景实现起来还是比较困难，软件工程界的名言<a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">「没有银弹」</a>告诉我们不存在一个可以通吃的、完美的方案，因此 HTAP 目前更多还只是一个营销概念吧。</p>

<h2>字节跳动自研强一致在线 KV &amp; 表格存储实践</h2>

<p><a href="https://mp.weixin.qq.com/s/jdPE9WClBuimIHVxJnwwUw">[上篇]</a> <a href="https://mp.weixin.qq.com/s/DvUBnWBqb0XGnicKUb-iqg">[下篇]</a></p>

<p><a href="https://github.com/cockroachdb/cockroach">又</a><a href="https://github.com/pingcap/tidb">又</a><a href="https://github.com/dgraph-io/dgraph">又</a><a href="https://kudu.apache.org">又</a><a href="https://github.com/vesoft-inc/nebula">又</a>一个受 Spanner 启发的分布式存储（Google 功德无量！Jeff Dean 万寿无疆！），这次的项目来自字节跳动。关键词：range 分割、Raft、RocksDB、MVCC、分布式事务、SQL 层，看看这些也基本能对整体设计猜个八九不离十了，比较有价值的信息是学习学习字节跳动在他们的实践中的一些经验。项目使用 C++ 语言编写，目前没有开源。</p>

<h2>Challenges Supporting MIG in Kubernetes</h2>

<p><a href="https://docs.google.com/document/d/1Dxx5MwG_GiBeKOuMNwv4QbO8OqA7XFdzn7fzzI7AQDg">[链接]</a></p>

<p>随着深度学习的蓬勃发展，GPU 共享逐渐成为了 K8s 社区的一个<a href="https://github.com/kubernetes/kubernetes/issues/52757">热门话题</a>。目前 NVIDIA 官方提供的<a href="https://github.com/NVIDIA/k8s-device-plugin">设备插件</a>可以申请的最小资源粒度还是 1 个 GPU，但很多时候资源是浪费的。为了提升 GPU 的资源利用率，社区已经出现了多种解决方案，例如分别来自<a href="https://github.com/AliyunContainerService/gpushare-scheduler-extender">阿里云</a>、<a href="https://github.com/tkestack/gpu-manager">腾讯云</a>以及 <a href="https://github.com/awslabs/aws-virtual-gpu-device-plugin">AWS</a> 的实现。现在 NVIDIA 官方终于在新一代的 Ampere 架构硬件上原生支持了共享，也就是标题中的 MIG（Multi-Instance GPUs）。这篇文档来自 NVIDIA 团队，首先介绍了当前是如何在 K8s 中管理 GPU 资源的，然后介绍了 MIG 的一些概念，最后提议了 4 个支持 MIG 的可能的解决方案。整体感觉 GPU 共享还是没有 CPU 灵活，不少地方设置了限制，但毕竟这是 NVIDIA 官方迈出的第一步。</p>

<h2>How to read deep learning papers?</h2>

<p><a href="https://www.reddit.com/r/MachineLearning/comments/gi3ihe/d_how_to_read_deep_learning_papers">[链接]</a></p>

<p>Reddit 上一个有趣的讨论：如何阅读深度学习的论文？我们常常调侃机器学习就是在「炼丹」，没有人能解释为什么结果就是有效的，反正<a href="https://www.youtube.com/watch?v=YPN0qhSyWy8">「it just works」</a>。最高票的评论说你不需要接受论文中的每一个观点，只要把注意力集中在作者提供的证据并有选择性地调整你的想法就好了。正好前段时间前微软执行副总裁沈向洋博士做了一个主题名为<a href="https://www.bilibili.com/video/BV1df4y1m74k">「You are how you read」</a>的演讲，主要内容就是一些阅读论文的经验（有趣的是沈博士在几年前还写过一篇叫做<a href="https://www.linkedin.com/pulse/you-what-write-harry-shum">「You are what you write」</a>的博客）。</p>

<h2>Farewell, TensorFlow</h2>

<p><a href="https://mrry.github.io/2020/05/10/farewell-tensorflow.html">[链接]</a></p>

<p>TensorFlow 核心开发者、Google Brain 团队的 Derek Murray 宣布离开，这位大哥在 GitHub 和 Stack Overflow 上都很活跃，如果你经常浏览社区应该对他的头像不陌生。在这篇告别文中 Murray 提到了很多 Google 内部帮助工程师解决问题的工具，并详细介绍了近期对 TensorFlow 底层运行时进行的一项性能优化的过程，在部分评测中可以提升 10% 的推理性能。这个优化目前已经合入 master，并将在 TensorFlow 2.3 发布。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maybe News Issue #2]]></title>
    <link href="https://blog.xiaogaozi.org/2020/06/02/maybe-news-issue-2/"/>
    <updated>2020-06-02T09:25:45+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/06/02/maybe-news-issue-2</id>
    <content type="html"><![CDATA[<blockquote><p>「Maybe News」是一个定期（或许不定期）分享一些可能是新闻的知识的<a href="https://blog.xiaogaozi.org/categories/maybe-news/">系列文章</a>，名字来源于我非常喜欢的一个国内的音乐厂牌<a href="https://en.wikipedia.org/wiki/Maybe_Mars">「兵马司」</a>（Maybe Mars）。你也可以通过<a href="https://digest.xiaogaozi.org/maybe-news">邮件订阅</a>它。</p></blockquote>

<!-- more -->


<h2>In Search of an Understandable Consensus Algorithm (Extended Version)</h2>

<p><a href="https://raft.github.io/raft.pdf">[链接]</a></p>

<p>终于有机会仔细阅读一遍 Raft 的论文，如果你还不了解 Raft 是什么可以看看我过去的一篇介绍分布式系统基础概念的<a href="https://blog.xiaogaozi.org/2020/05/25/how-to-design-a-distributed-index-framework-part-5/">文章</a>。</p>

<p>Raft 为节点定义了三种状态：leader、follower 和 candidate（以及一个非正式状态 learner 或者叫做 non-voting member）。一个集群只会有 1 个 leader，其余节点都是 follower。Leader 负责处理所有的读写请求，如果请求 follower 会失败并告知客户端 leader 的地址。</p>

<p>每个节点都有一个自己的 log，log 中每个条目都有一个下标（index）。这个 log 基本算是 append-only 的，通常也需要持久化到可靠的存储上（例如磁盘）。当处理写请求时 leader 会首先更新自己的 log，然后通过 RPC 复制到其它节点，只要大多数（majority）节点更新成功 leader 就会认为这个请求已经 committed，此时会更新自己的状态机（state machine）并返回给客户端。如果 RPC 请求失败 leader 会不断重试直到成功。</p>

<p>如果出现异常，如 leader 宕机、网络故障等，就可能触发 leader 重新选举。选举过程是所有 follower 为 candidate 投票，只要获得多数票 candidate 就会升级为 leader。如果投票失败会继续新一轮选举，选举过程通常是毫秒级的。每一轮新的选举都会产生一个对应的 term（任期），Raft 在协议上保证了重新选举后的新 leader 一定是包含之前所有 term 已经 committed 的 log，这样就避免了新 leader 选举成功以后需要首先补上缺失的数据。</p>

<p>当集群需要伸缩时，leader 会首先将旧集群配置（configuration）和新集群配置合并到一起并通过 log 的形式复制到 follower。成功收到这个合并后配置的节点会用这个配置替代老的配置。一旦这个合并后的配置 committed，leader 就会创建一个只包含新配置的 log 继续复制到 follower。等到新的配置 committed，旧配置将不再生效，需要下线的节点也可以被安全关闭。</p>

<p>随着时间增长，log 的容量会越来越大，Raft 引入了快照（snapshot）机制，定期将 log 压缩到快照文件。这个快照文件同时也可以帮助新加入的节点快速补上缺失的数据。</p>

<p>总结一下 Raft 算法保证了以下几个属性始终成立：</p>

<ul>
<li><strong>Election Safety</strong>：在一个特定的任期最多只能有一个 leader 被选举出来</li>
<li><strong>Leader Append-Only</strong>：leader 永远不会覆盖或者删除 log 中的条目，只会追加新的条目。</li>
<li><strong>Log Matching</strong>：如果两份 log 同时包含一个具有相同任期数和下标的条目，那么这两份 log 中这个下标之前的所有条目都应该是一致的。</li>
<li><strong>Leader Completeness</strong>：如果某个任期中的一个 log 条目已经 committed，那么在之后任期中选举出的新 leader 一定包含这个条目。</li>
<li><strong>State Machine Safety</strong>：如果一个节点已经将一个给定下标的 log 条目更新到自己的状态机，那么其它节点上同样的下标一定不会是不同的条目，也就是说不会更新一个不同的条目到自己的状态机。</li>
</ul>


<p>更多有关 Raft 的信息可以查看它的<a href="https://raft.github.io">官网</a>，强烈建议初次接触一致性协议的朋友看看网站上的动画演示，非常有助于建立一个形象直观的认知。</p>

<h2>Scaling Raft</h2>

<p><a href="https://www.cockroachlabs.com/blog/scaling-raft">[链接]</a></p>

<p>作为前面介绍 Raft 的一篇衍生阅读，原始的 Raft 实现是将所有节点看作一个 group，这种设计在某些场景（例如集群规模很小）是可行的。但是当集群规模大到一定程度，或者类似 <a href="https://github.com/cockroachdb/cockroach">CockroachDB</a> 和 <a href="https://github.com/tikv/tikv">TiKV</a> 这种将数据划分为非常多的 range，多个 range 组成一个 Raft group 的场景（通常叫做 Multi-Raft），就会发现 Raft 的基础网络通信已经足以影响单节点的性能（比如过多的心跳请求）。因此社区已经针对这样的问题有了一些优化方案，比如 <a href="https://github.com/cockroachdb/cockroach/issues/357">CockroachDB 的方案</a>和 <a href="https://github.com/tikv/tikv/pull/4591">TiKV 的方案</a>。这两个方案都很类似，基本思想是暂停那些不活跃的 Raft group 的网络通信，等到需要的时候再唤醒。</p>

<h2>Why Generics?</h2>

<p><a href="https://blog.golang.org/why-generics">[链接]</a></p>

<p>这篇文章是 Ian Lance Taylor 在 GopherCon 2019 演讲的文字版（文章中也附带了视频），主要介绍了目前 Go 的核心开发者关于泛型（generics）的一些思考。总的来说 Go 核心团队的设计思想还是保持 Go 语言一贯的简洁，不希望引入过多的概念和复杂性。大部分新增的语法特性都由提供泛型接口的开发者来学习，对于使用者来说和调用普通接口几乎没有区别。早在 2016 年社区就已经有了 <a href="https://github.com/golang/go/issues/15292">#15292</a> 这个关于泛型的讨论，并且还在持续更新中，目前已经有了 710 条评论，Ian Lance Taylor 也在其中积极回复。虽然这个 issue 打上了 Go2 的标签，但泛型特性是否能在 Go 语言的 2.0 版本中出现现在还是个未知数。</p>

<h2>The Open Application Model from Alibaba’s Perspective</h2>

<p><a href="https://www.infoq.com/articles/oam-alibaba">[链接]</a></p>

<p>阿里云和微软在去年<a href="https://cloudblogs.microsoft.com/opensource/2019/10/16/announcing-open-application-model">共同宣布</a>了 Open Application Model（OAM），OAM 组织的<a href="https://github.com/orgs/oam-dev/people">核心成员</a>同时也是前 CoreOS 团队成员以及 etcd、K8s Operator 的创造者。简单理解 OAM 就是希望将传统的 K8s YAML 配置抽象成两部分：开发者和运维，开发者的配置中只包含与业务最相关的内容，而运维的配置中则包含与运行环境相关的内容。本质上是希望将开发者和运维的界线分得更清楚，让不同的角色更专注于自己的领域。在我看来 OAM 的好处当然是降低了普通开发者接入 K8s 的门槛，所谓大道至简，但这种表面上的「简」背后隐藏的复杂性也是不能忽略的。理想情况是某个云服务商能够完全包办所有跟运维有关的事情，用户只需要负责业务开发就好了。但现状还是不管多小的公司都肯定会有专人在负责运维工作。很多年前 Google App Engine 刚诞生时让所有人都眼前一亮，都认为这才是软件开发的未来啊，但即使是 Google 也没能让这个趋势持续下去。最近几年这个趋势又开始回潮，只不过换了一个名字叫做「Serverless」，希望这一次能够持续下去，虽然还有很长的路要走。</p>

<h2>Lightweight coscheduling based on back-to-back queue sorting</h2>

<p><a href="https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/kep/20200116-lightweight-coscheduling-based-on-back-to-back-queue-sorting.md">[链接]</a></p>

<p>自从 K8s 1.15 新增了 <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework">Scheduling Framework</a> 以后，原生调度器的扩展性有了很大程度的增强。这个 KEP 来自阿里云团队，提出了基于 Scheduling Framework 来实现 coscheduling（或者叫做 gang scheduling）。Coscheduling 这个特性对于机器学习任务来说是非常重要的，一个任务通常包含多个 pod，只有当多个 pod 能够同时运行时这个任务才算是正常运行，如果只有部分 pod 可以运行其实是一种资源的浪费。因此 coscheduling 保证的就是一个任务必须满足一定数量的 pod 都能够被调度时才会实际分配资源。这个特性在 K8s 社区早有讨论，也诞生了一些相关联的项目，如 <a href="https://volcano.sh">Volcano</a>（前身是 <a href="https://github.com/kubernetes-sigs/kube-batch">kube-batch</a>）。5 月初这个插件的第一版已经被 <a href="https://github.com/kubernetes-sigs/scheduler-plugins/pull/4">merge</a> 到 scheduler-plugins 项目。</p>

<h2>Scheduler Support for Elastic Quota Management</h2>

<p><a href="https://docs.google.com/document/d/1ViujTXLP1XX3WKYUTk6u5LTdJ1sX-tVIw9_t9_mLpIc/edit?usp=sharing">[链接]</a></p>

<p>同样是与 K8s 相关的一个讨论，也同样来自阿里云团队。<code>ResourceQuota</code> 是 K8s 目前提供的一种限制某个 namespace 最大资源使用量的方式，但是在实际的多租户场景中，<code>ResourceQuota</code> 往往显得不够灵活。很多时候我们是希望给每个租户一个可以保证（guarantee）的最小资源量，以及一个超卖的最大资源量。当某个租户的资源比较空闲时，就允许其它租户临时租用。但是调度器也要保障这个租户有能力在必要的时候可以拿回这些被租用的资源，这通常是通过抢占（preemption）的方式来实现。这个提案就提出了扩展 <code>ResourceQuota</code> 来实现类似功能的想法。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何设计与实现一个分布式索引框架（五）：分布式]]></title>
    <link href="https://blog.xiaogaozi.org/2020/05/25/how-to-design-a-distributed-index-framework-part-5/"/>
    <updated>2020-05-25T11:21:49+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/05/25/how-to-design-a-distributed-index-framework-part-5</id>
    <content type="html"><![CDATA[<blockquote><p>这是一个<a href="https://blog.xiaogaozi.org/categories/htdadif/">系列文章</a>，大部分内容都来自我过去在小红书发现 Feed 团队工作期间的实践和经验。在介绍的过程中我会尽量不掺杂过多的业务细节，而专注于这背后我个人一些浅薄的设计思想，希望你在阅读完这些文章以后能够直接或者间接地拓展到不同的场景。</p></blockquote>

<p>前面几篇文章介绍的技术都是在单机上实现的，但如果做不到分布式那整个系统的扩展性将会受到非常大的限制。本篇文章将会围绕分布式这个话题讨论。</p>

<!-- more -->


<h2>数据分割（Partition）</h2>

<p>分布式存储很大一个目的是为了将数据分布到多个节点上，以突破单机的存储限制，实现水平扩展（horizontal scaling）。因此这就涉及到一个很重要的问题：要如何将数据分布到不同的节点上？可能的几种做法有：</p>

<ol>
<li>随机：每一条数据都随机分配到某个节点上</li>
<li>轮询（round-robin）：通过轮询的方式将数据分配到节点上，例如第 1 条数据分配到节点 1，第 2 条数据就分配到节点 2，以此类推。</li>
<li>哈希（hash）：通过某种哈希算法将数据中的某个 key 映射到一个固定的值，根据这个值来分配节点。</li>
<li>范围（range）：划定一些范围，并将这些范围与节点进行映射，当数据中的某个 key 属于某个范围时就分配到对应的节点上。</li>
</ol>


<p>方案 1 显然是最简单的，但也是最不可行的。这个方案有两个大问题：因为数据是随机分配的，因此在查询某一条数据时必须请求所有节点；同样因为随机分配的关系，不同节点之间的数据量可能是非常不均衡的。</p>

<p>方案 2 相比方案 1 稍微改进了一点，轮询的方式可以基本保证数据分布是均衡的，但是在查询时还是必须请求所有节点。</p>

<p>方案 3 基本解决了前面提到的两个问题，哈希算法通常是稳定的，也就是说通过某个 key 得到的哈希值是固定的。比如最简单的哈希算法取模运算，将 key 模上集群的节点数 <code>key mod N</code>，就可以算出这个 key 应该分配的节点。不过取模运算虽然简单但也存在一些问题，最明显的就是当添加新节点或者删除老节点的时候会造成大量的数据重新分配（rebalance）。因此比较常见的改进方案是采用<a href="https://en.wikipedia.org/wiki/Consistent_hashing">一致性哈希</a>（consistent hashing），一致性哈希可以显著降低数据重新分配这个过程需要迁移的数据量。Amazon 的 <a href="https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">Dynamo</a> 便是采用一致性哈希进行数据分割的一个很好的例子，Cassandra 的<a href="https://cassandra.apache.org/doc/latest/architecture/dynamo.html">官方文档</a>里也介绍了类似的内容。但是一致性哈希也不是没有缺点，当集群节点数较少时还是有可能造成数据分布不均衡，因此 Dynamo 提出了通过增加虚拟节点（virtual node）的方法来解决这个问题，细节可以参考论文或者 Cassandra 的文档。</p>

<p>方案 4 也能实现稳定查询，例如将数据 key 的首字母限定在 a-z 这 26 个字母中，再将 a-z 等分为几个范围（range），那么就能根据 key 的首字母确定属于哪个范围。同时每个节点会包含 1 个或多个范围，便能将 key 分配到某个节点上。HBase 便是采用范围分割数据的一个案例，但是由于 HBase 不会预先为所有节点绑定范围，因此在实践中通常还要结合 <a href="https://hbase.apache.org/book.html#tricks.pre-split">pre-split</a> 来避免数据都集中在少数节点中。因为每个范围都是连续的，所以方案 4 相比方案 3 的一个优势是对于范围扫描（range scan）的支持更好。</p>

<p>综合来看方案 3 和方案 4 都是可行的方案，它们也都有各自的一些优缺点，如何选择还得看具体的使用场景。</p>

<h2>数据复制（Replication）</h2>

<p>数据分布到多个节点上以后，虽然扩展性（scalability）得到了满足，但是随着节点数的增多，可用性（availability）的重要性会逐渐凸显出来。节点因为各种原因下线是非常普遍的，一旦节点下线那这台节点上的数据将无法访问。因此为了保障可用性，通常会通过冗余存储的方式来解决，也就是为每一份数据新增多个副本（replica），然后将副本分散到不同的节点上，只要还有至少 1 个副本存在那即使部分节点下线也能继续访问数据。为了实现多副本也有几种可能的方案：</p>

<ol>
<li>节点组（node group）：为每个节点创建多个副本节点，这些节点共同组成一个节点组。一个节点组内部的数据是完全相同的，不同节点组之间的数据是不同的。</li>
<li>混合（hybrid）：每个节点不仅有属于自己的数据，同时还存储了其它节点数据的副本。</li>
</ol>


<p>方案 1 中节点组之间的数据因为是相互独立的，因此实现和维护相对来说都会比较简单，新增副本就只需要在每个节点组中新增节点即可。我们在数据库系统中经常见到主（master）从（slave）节点的概念，这里可以把 1 个主节点和多个从节点看作是一个节点组。</p>

<p>方案 2 是目前主流分布式存储的实现方案，在存储数据时通过某种算法选择多个副本节点，并时刻检查当前数据的副本数是否符合用户设定的值。这种方案因为在一个节点上同时包含了原始数据和副本，相比方案 1 节点的资源利用率会更高，但代价就是维护成本会有所提升。</p>

<p>不论是选择前面介绍的哪种方案都会涉及到一个问题：如何将原始数据同步到副本上？这里就必须提及在分布式系统中非常重要的一个概念「一致性（consistency）」<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>，所谓一致性就是用于描述分布式系统中不同实体间状态（state）一致程度的概念。一致性从强到弱大致可以分为以下 4 种类别：</p>

<ol>
<li>线性一致性（Linearizability）或者强一致性（Strong consistency）</li>
<li>顺序一致性（Sequential consistency）</li>
<li>因果一致性（Causal consistency）</li>
<li>最终一致性（Eventual consistency）</li>
</ol>


<p>一致性越强的算法对数据的一致要求也越高，当然实现成本也越高。线性一致性的代表有 <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a> 和 <a href="https://raft.github.io">Raft</a>，最终一致性的代表有 Dynamo<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。为什么一致性如此重要呢？因为分布式系统天然存在的并发和延迟，要如何把一个集群的状态更新最终实现得看起来就像一台单机一样，这是一致性算法要解决的问题。</p>

<p>具体细分状态复制的实现方式有两种：一种是传统的 replicated state machine（或者叫做 active replication），另一种是 primary-backup（或者叫做 primary-copy、passive replication）。前者的代表有 Paxos 和 Raft，后者的代表有 <a href="http://www.cs.princeton.edu/courses/archive/fall09/cos518/papers/viewstamped.pdf">Viewstamped Replication</a> 和 <a href="https://marcoserafini.github.io/papers/zab.pdf">Zab（ZooKeeper Atomic Broadcast）</a>。有关这两种状态复制方案的区别可以看看 Raft 作者的<a href="https://web.stanford.edu/~ouster/cgi-bin/papers/OngaroPhD.pdf">博士毕业论文</a><sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>和 <a href="https://arxiv.org/abs/1309.5671">Vive la Différence: Paxos vs. Viewstamped Replication vs. Zab</a> 这篇论文。</p>

<p>因此回到最开始的那个问题「要如何将原始数据同步到副本」，这取决于你需要哪种程度的一致性，你甚至可以说我不需要一致性<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>。对于推荐系统的场景，线性一致性属于杀鸡用牛刀<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>，所以我们只要追求最终一致性就够了。</p>

<h2>集群成员管理</h2>

<p>一个分布式系统必然是由多个节点构成的，那这些节点之间要如何互相感知呢？关于这个问题可以分为两类方案：中心化和去中心化。</p>

<p>所谓中心化就是存在一个（或一组）集中管理的服务，这个中心服务负责接收并存储集群所有节点上报的信息，以及反向分发这些信息，相当于一个集群的信息枢纽。在微服务领域有另外一个词用于表示类似的功能：服务注册与发现。常见的可以实现这种中心服务的开源组件有 <a href="https://zookeeper.apache.org/">ZooKeeper</a>、<a href="https://etcd.io">etcd</a> 和 <a href="https://www.consul.io">Consul</a>。</p>

<p>而去中心化顾名思义就是不存在一个中心服务，完全依靠集群内各个节点之间的通信来实现拓扑发现。最著名的去中心化协议恐怕就是 <a href="https://en.wikipedia.org/wiki/Gossip_protocol">gossip 协议</a>，这是一个可以实现点对点（P2P）通信的协议，很多开源系统里也使用到了 gossip，比如 <a href="https://cassandra.apache.org/doc/latest/architecture/dynamo.html#distributed-cluster-membership-and-failure-detection">Cassandra</a> 和 <a href="https://www.consul.io/docs/internals/gossip.html">Consul</a>。</p>

<p>至于是中心化还是去中心化好那只能是见仁见智了，没有哪个方案是绝对完美的。</p>

<h2>数据重新分配（Rebalance）</h2>

<p>前面的「数据分割」小节已经介绍了如何将数据分布到不同的节点上，如果一个集群的节点数永远不变那这不会带来任何问题，但是如果存在新增或者删除节点的情况呢？不论是哈希还是范围分割的方法，都必须要重新分配数据，以保持集群节点间的数据均衡。为了不影响已有的节点，数据重新分配通常的实现都是在一个后台线程中执行，同时也要控制数据同步的带宽和速率。当数据重新分配这个过程完成以后就可以上线或者下线对应的节点。</p>

<p>当然数据重新分配也不一定就只是由集群节点伸缩触发的，某些系统也会实时地根据当前每个节点的负载而动态调整数据的分布，目的是为了避免出现热点导致整体系统的稳定性受影响。</p>

<h2>整体设计</h2>

<p>综合前面介绍的所有内容，现在如果让你来设计分布式索引你会如何设计？这里提供一个我们的实现方案，但是请记住一定不存在一个完美的方案，任何架构设计都是权衡（trade-off）的结果。</p>

<p><img src="https://blog.xiaogaozi.org/images/posts/rec_sys_distributed_design.png" alt="recommendation system distributed design" /></p>

<p>简单总结上面这个方案的一些特点：</p>

<ul>
<li>通过哈希来进行数据分割</li>
<li>通过节点组的方式进行数据复制，一致性的要求是最终一致性<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>。</li>
<li>通过 Consul 来进行服务注册和发现，并封装一个库供客户端使用。</li>
</ul>


<p>以上就是关于分布式的介绍，下一篇文章的内容会相对轻松一些，聊一聊所谓的端到端（end-to-end）用户体验。</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>如果想系统了解一致性，推荐阅读 Jepsen 的<a href="https://jepsen.io/consistency">系列文档</a>、普林斯顿大学的 <a href="https://www.cs.princeton.edu/courses/archive/fall19/cos418">COS 418</a> 课程以及 The Morning Paper 的<a href="https://blog.acolyer.org/2015/03/01/cant-we-all-just-agree">系列解读</a>。<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>Amazon 的 CTO 也写过<a href="https://www.allthingsdistributed.com/2008/12/eventually_consistent.html">一篇博客</a>讲解最终一致性<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>具体位置在「11.6 Replicated state machines vs. primary copy approach」章节<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>那你爱咋同步咋同步<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>用户根本不关心（或者说根本察觉不出）不同推荐结果之间有什么一致性问题<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
<li id="fn:6">
<p>实践中我们是通过 HDFS 作为索引数据源，每个节点自行拉取（pull）的方式实现。<a href="#fnref:6" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maybe News Issue #1]]></title>
    <link href="https://blog.xiaogaozi.org/2020/05/21/maybe-news-issue-1/"/>
    <updated>2020-05-21T17:34:22+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/05/21/maybe-news-issue-1</id>
    <content type="html"><![CDATA[<blockquote><p>「Maybe News」是一个定期（或许不定期）分享一些可能是新闻的知识的<a href="https://blog.xiaogaozi.org/categories/maybe-news/">系列文章</a>，名字来源于我非常喜欢的一个国内的音乐厂牌<a href="https://en.wikipedia.org/wiki/Maybe_Mars">「兵马司」</a>（Maybe Mars）。你也可以通过<a href="https://digest.xiaogaozi.org/maybe-news">邮件订阅</a>它。</p></blockquote>

<!-- more -->


<h2>CFS: A Distributed File System for Large Scale Container Platforms</h2>

<p><a href="https://dl.acm.org/doi/10.1145/3299869.3314046">[链接]</a></p>

<p>跟<a href="https://blog.xiaogaozi.org/2020/04/26/weekly-reading-list-issue-1/">上次介绍</a>的 FoundationDB Record Layer 一样，这篇来自京东团队的论文也是发表在 SIGMOD 2019，介绍了一个为大规模容器平台设计的分布式文件系统。</p>

<p>系统整体由 3 部分组成：元数据子系统（metadata subsystem）、数据子系统（data subsystem）、资源管理器（resource manager）。元数据子系统负责维护 inode 和 dentry（directory entry），数据子系统负责存储数据块，资源管理器负责处理客户端的各种文件操作请求以及维护前面两个子系统的状态。元数据子系统和数据子系统都是多 partition 的分布式系统，多个元数据和数据的 partition 逻辑上共同组成一个卷（volume），这个卷即是对客户端（容器）可见的存储单元并且可以被挂载，通过传统的 POSIX 接口访问。</p>

<p>因为上述 3 部分组件内部其实都是一个分布式系统，因此都用到了 Raft 作为一致性协议，资源管理器还用到了 RocksDB 作为本地持久化存储。稍微特殊的是数据子系统根据不同类型的写操作选择了不同的复制方案，论文里把这个叫做 Scenario-Aware Replication，具体讲就是顺序写操作（比如 append）用的是 primary-backup，而覆盖（overwrite）操作用的是 Raft。</p>

<p>系统的另一个亮点是基于资源利用率的 partition 分配策略，论文中叫做 Utilization-Based Placement。传统的 partition 分配策略通常是哈希，这种策略的优点是简单但是当扩缩容时必须进行 rebalance。CFS 的做法是元数据和数据子系统定期上报内存、磁盘使用率到资源管理器，当需要创建新的 partition 时根据资源利用率选择最低的那个节点，这样设计的好处是不再需要 rebalance。但是对于这种设计方案是否会造成数据不均衡表示存疑，论文中也没有做过多论述。</p>

<p>为了尽量减少客户端的网络交互，不让某个系统组件成为瓶颈，客户端会缓存元数据子系统、数据子系统和资源管理器的信息到本地，当执行文件操作时会优先读取本地缓存。当然某些组件（比如资源管理器）还是有可能在某一天成为瓶颈，但是基于京东的经验这件事情基本上不会发生。</p>

<p>在与 Ceph 的评测中，CFS 平均有 3 倍的 IOPS 提升，特别是多客户端和随机读写的场景。这很大程度上得益于元数据和数据节点分离的设计，且 CFS 的元数据是全内存存储，而 Ceph 并不是。</p>

<p>分布式文件系统一直都是比较重要的基础组件，在分布式数据库、大数据、机器学习领域有广泛应用。常见的分布式文件系统如 HDFS、Ceph，在如今这个全面推行容器化的时代越来越显得捉襟见肘。容器化一个很大的特点是快速扩缩容，传统的存储系统在这一点上是非常不友好的，因此才会有越来越多针对容器化场景的基础组件诞生（具体可以访问 <a href="https://www.cncf.io">CNCF</a> 查看），这里介绍的 CFS 是一个例子，另一个类似的是 <a href="https://juicefs.com">JuiceFS</a>。</p>

<p>CFS 目前属于 CNCF 下的 <a href="https://www.cncf.io/sandbox-projects">sandbox 项目</a>，且已经<a href="https://github.com/chubaofs/chubaofs">开源</a>，使用 Go 语言编写。</p>

<h2>tensorflow/community #237: RFC: Sparse Domain Isolation for Supporting large-scale Sparse Weights Training</h2>

<p><a href="https://github.com/tensorflow/community/pull/237">[链接]</a></p>

<p>推荐系统大规模稀疏特征分布式训练一直是工业界一件有挑战的事情，大公司内部自研的训练框架大多已经解决了这个问题，但是在开源社区问题仍然存在。TensorFlow 作为也许目前最流行的深度学习训练框架，社区里也早有相关的讨论（比如 <a href="https://github.com/tensorflow/tensorflow/issues/19324">#19324</a>、<a href="https://github.com/tensorflow/tensorflow/issues/24539">#24539</a>、<a href="https://github.com/tensorflow/tensorflow/pull/24915">#24915</a>），但基本都以烂尾告终。最新的 RFC #237 来自腾讯，区别于现有的一些开源实现（比如阿里巴巴的 <a href="https://github.com/alibaba/x-deeplearning">XDL</a>、字节跳动的 <a href="https://github.com/bytedance/byteps">BytePS</a>、蚂蚁金服的 <a href="https://github.com/sql-machine-learning/elasticdl">ElasticDL</a>）完全自己重新造了一个 parameter server，腾讯的方案最大限度复用了 TensorFlow 现有的组件，对用户的代码侵入也最小。目前这个 RFC 还在讨论中，有兴趣可以订阅 PR。</p>

<h2>深入云原生 AI：基于 Alluxio 数据缓存的大规模深度学习训练性能优化</h2>

<p><a href="https://mp.weixin.qq.com/s/2Pj8erPbYuMo7mBJvweJgQ">[链接]</a></p>

<p>机器学习模型训练由于依赖大量的数据作为输入，因此数据 I/O 的性能会直接影响模型训练的效率。有时间会发现计算设备的算力升级了，但是数据 I/O 跟不上了，反而拖慢了整个训练流程。阿里云团队分享的这篇文章便是他们在使用 Alluxio（试图）加速数据 I/O 的过程中的经验，虽然最后的优化结果性能指标其实也只是基本跟本地读取持平。</p>

<h2>Rob Pike interview: “Go has indeed become the language of cloud infrastructure”</h2>

<p><a href="https://evrone.com/rob-pike-interview">[链接]</a></p>

<p>没啥好介绍的了，值得一读的一篇采访。文中有两个有趣的问题：</p>

<ul>
<li><strong>对于 Rust 宣称的「没有 GC」的设计有什么看法</strong>：Rob Pike 只是表示了他对 Rust 很感兴趣，其它意见不便发表。</li>
<li><strong>如果可以时间旅行到最初设计 Go 的时候想给自己一个什么忠告</strong>：无视那些仇恨者（haters），只需要聆听那些理解以及和你有共同目标的人的声音。不可能每一个人都认同你正在做的事情，但是那些鼓励你前进的人会是提供给你非常棒（fantastic）的想法、能量和灵感的源泉。</li>
</ul>


<h2>孤芳「自赏」：盯鞋音乐的前世与今生</h2>

<p><a href="https://www.gcores.com/articles/121368">[上]</a> <a href="https://www.gcores.com/articles/123770">[下]</a></p>

<p>这两篇文章来自「竟然还能聊游戏」的机核，相对系统地介绍了「盯鞋（shoegaze）」这种音乐风格，作为目前可能是除了后朋克以外我最喜欢的音乐风格非常高兴能够有人科普，稍微欠缺的是文中没有提到任何中国的乐队。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何设计与实现一个分布式索引框架（四）：索引更新]]></title>
    <link href="https://blog.xiaogaozi.org/2020/05/13/how-to-design-a-distributed-index-framework-part-4/"/>
    <updated>2020-05-13T14:55:43+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/05/13/how-to-design-a-distributed-index-framework-part-4</id>
    <content type="html"><![CDATA[<blockquote><p>这是一个<a href="https://blog.xiaogaozi.org/categories/htdadif/">系列文章</a>，大部分内容都来自我过去在小红书发现 Feed 团队工作期间的实践和经验。在介绍的过程中我会尽量不掺杂过多的业务细节，而专注于这背后我个人一些浅薄的设计思想，希望你在阅读完这些文章以后能够直接或者间接地拓展到不同的场景。</p></blockquote>

<p><a href="https://blog.xiaogaozi.org/2020/04/24/how-to-design-a-distributed-index-framework-part-3/">上一篇文章</a>介绍了如何实现正排索引和二级索引，但要创建索引也得先有数据才行，本篇将会介绍数据是如何更新的。</p>

<!-- more -->


<h2>全量索引</h2>

<p>所谓「全量索引（full index）」就是指需要索引的数据的全集，通常全量索引的数据量都是一个比较大的量级<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>，离线构建一次全量索引的时间成本也比较高，因此更新频率不会特别频繁<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。全量索引的更新很简单，一般就是覆盖线上已经存在的那份旧的全量索引，当然这个更新流程不会是直接替换，而是先把新的数据加载好再进行替换，也就是说在更新的过程中需要保证内存中能够同时存放两份数据。</p>

<p>全量索引有几个比较严重的问题：</p>

<ul>
<li>索引的数据量决定了它的更新频率不会很快，而且有变化的数据在这个全集中必定是少数，每次都更新全部数据有点浪费。</li>
<li>索引更新过程中需要临时存储双份数据，会有大量新对象产生，对 GC 的压力也会很大。很多时候我们选择不频繁更新全量索引也是这个原因，这就进一步加剧了上一个问题的影响。</li>
</ul>


<p>解决思路其实也很直接，既然需要更新的数据是少数，那每次索引更新就只更新这部分数据好了，这也就是下一章节要着重介绍的内容。</p>

<h2>增量索引</h2>

<p>与「全量索引」一起经常被提及的另一个词就是「增量索引（incremental index）」，顾名思义增量索引是只针对增量数据构建的集合，因此索引的数据量也会小非常多，自然更新频率就可以很快了。构建增量索引并不是一件特别复杂的事情，只需要有办法获取到最近一段时间有变化的内容就行<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>。但是构建好的增量索引要如何更新到线上是一个值得认真思考的问题，有两种方案可以选择：</p>

<ol>
<li>直接修改全量数据的倒排索引和正排索引</li>
<li>单独为增量数据创建倒排索引和正排索引</li>
</ol>


<p>第 1 种方案如果是新增的内容比较简单，在倒排索引和正排索引中插入新的条目即可。但如果是旧的内容被更新或者删除，那就需要在这两种索引中找到对应的条目并全部更新或者删除。直接原地更新或者删除对于倒排索引来说因为需要扫描整个索引条目列表，时间复杂度会随着列表长度以及增量更新的数据量线性增长；对于正排索引来说堆外内存不可避免会产生空间碎片，必须定期清理碎片以免造成空间浪费。</p>

<p>第 2 种方案创建索引的逻辑跟全量索引是一样的，只不过是针对增量数据。但是此时相当于就存在了多个倒排索引和正排索引，查询逻辑应该怎样实现呢？由于正排索引是一一映射，因此如果有多个相同 primary key 的索引，那在查询时选择最新的那个索引即可。查询倒排索引稍微复杂一点，同一个倒排索引 key 可能在多个索引中都存在，查询时需要同时从这些索引中遍历，最终选取出 top N 的条目<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>。遍历时除了用户提供的过滤器以外，还需要过滤那些已经被删除的条目，这可以通过一个全局的已删除条目集合来实现。随着增量索引数量的增多，不同索引间冗余的数据会变得越来越多，浪费存储空间的同时也会增加查询的时间复杂度。因此我们需要不定期合并这些索引，去除那些重复或者被删除的条目。</p>

<p>我们最终选择了方案 2，因为整体上更倾向于把存储的数据结构设计成 append-only 的模式，简化底层存储的实现<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>。熟悉数据库系统设计的朋友可能已经发现方案 2 同现在流行的 <a href="https://github.com/google/leveldb">LevelDB</a>、<a href="https://rocksdb.org">RocksDB</a> 有一些相似的地方，事实上我们在设计时也的确借鉴了它们的部分思想。这两者底层都是 <a href="https://en.wikipedia.org/wiki/Log-structured_merge-tree">LSM tree</a> 的数据结构，简单介绍 LSM tree 就是将数据分为多个 level，每个 level 的数据都是只读的且可能存在冗余，不同 level 之间会通过压缩（compaction）来去掉这些冗余。下图是增量索引的设计示意图。</p>

<p><img src="https://blog.xiaogaozi.org/images/posts/incremental_index_design.png" alt="incremental index design" /></p>

<p>我们限定最大的 level 数（即增量索引数），如果超过这个限定值就会触发合并。大部分情况下都会是增量索引之间进行合并，但如果合并之后的大小已经超过全量索引大小的某个比例，就会触发 1 次同全量索引的合并。</p>

<p>有了增量索引之后索引的更新频率最快可以控制在分钟级，相比全量索引动辄小时级甚至天级的频率已经快了不少。索引更新更快也意味着内容可以更快地被用户消费，促进了整个社区的信息流动。</p>

<p>以上就是本篇要介绍的全部内容，简单回顾一下：</p>

<ul>
<li>全量索引虽然构建成本很高但也是不可或缺的，它有着最全的业务数据。</li>
<li>增量索引的目的是为了加快索引更新频率，设计上借鉴了部分 LSM tree 的思想。</li>
</ul>


<p>注意过这个系列文章标题的朋友可能很好奇讲了这么久为啥感觉跟分布式一点儿关系都没有，的确前面几篇文章都是在重点介绍索引相关的技术，下一篇文章将会开始聊聊分布式这个话题，敬请期待。</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>当然数据量有多大取决于你的业务数据有多少<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>小时级、天级、周级都有可能<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>如何获取有非常多的方案，比如 MySQL 的 binlog，MongoDB 的 oplog。基础服务做得比较好的公司还会将不同存储的更新消息聚合到类似消息队列的系统中，方便下游业务消费。<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>假设现在有 3 个倒排索引，那是不是得从这 3 个倒排索引中都选出 top N 以后才能得到最终的结果呢（即总共需要查询 3 x N 个条目）？答案是不用，一种优化的实现方案是同时比较 3 个倒排索引的头部，挑选最大的那个条目，然后一直重复这个步骤直到满足选出 N 个条目，这样总共需要查询的条目数仍然是 N。<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>比如堆外内存从设计上就不用考虑更新和删除操作<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maybe News Issue #0]]></title>
    <link href="https://blog.xiaogaozi.org/2020/05/11/maybe-news-issue-0/"/>
    <updated>2020-05-11T14:44:52+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/05/11/maybe-news-issue-0</id>
    <content type="html"><![CDATA[<blockquote><p>前言：从这一期开始这个系列将会有一个正式的名字「Maybe News」，名字来源于我非常喜欢的一个国内的音乐厂牌<a href="https://en.wikipedia.org/wiki/Maybe_Mars">「兵马司」</a>（Maybe Mars）。本身我分享的内容也很有可能是一些旧闻，只不过对于我来说是还未了解的知识罢了。<a href="https://blog.xiaogaozi.org/2020/04/26/weekly-reading-list-issue-1/">上一期</a>的名字还是维持原样就不做修改。你也可以通过<a href="https://digest.xiaogaozi.org/maybe-news">邮件订阅</a>这个系列的文章。</p></blockquote>

<!-- more -->


<h2>LightRec: a Memory and Search-Efficient Recommender System</h2>

<p><a href="http://staff.ustc.edu.cn/~liandefu/paper/lightrec.pdf">[链接]</a></p>

<p>这篇论文由微软亚洲研究院与中科大共同发表在 <a href="https://www2020.thewebconf.org">WWW 2020</a> 会议上，提出了一种新的表示物品向量的方法，大幅降低存储向量所需空间的同时还显著提升了召回效果。一个直观的数据：LightRec 将 1 千亿 256 维双精度向量的内存占用从 9.5 GB 降到了 337 MB，这是非常惊人的！现在工业界常用的 <a href="https://github.com/nmslib/nmslib">nmslib</a> 和 <a href="https://github.com/facebookresearch/faiss">Faiss</a> 都无法实现如此高的压缩比，因此很多时候都需要借助分布式存储来满足业务场景，如果真的如论文中所描述的一样那单机存储在未来很长一段时间来说都是完全足够的。</p>

<p>这里简单解释一下为什么向量召回对于当下的推荐系统如此重要，传统的召回是基于倒排索引的方式，正如我在<a href="https://blog.xiaogaozi.org/2020/04/21/how-to-design-a-distributed-index-framework-part-1/">之前的一篇文章</a>中介绍的那样，召回与模型优化目标之间的差异较大导致召回效果始终较差。自从 <a href="https://www.microsoft.com/en-us/research/publication/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data">Learning Deep Structured Semantic Models for Web Search using Clickthrough Data</a> 这篇论文（同样也是由微软研究院发表）提出 DSSM（Deep Structured Semantic Models）以后，将召回与 DNN 进行结合，显著提升了召回的效果，在很多公司的实践中也的确论证了 DSSM 是一个非常有效的召回方式。DSSM 的核心是分别为物品和用户生成向量，再通过 ANN（Approximate Nearest Neighbors）查询相似向量从而实现召回。因此向量的存储和查询效率决定了在线请求的效果和性能，如何平衡向量索引的空间占用和召回效果是非常重要的。</p>

<p>微软研究院的微信公众号有一篇简短的针对这篇论文的<a href="https://mp.weixin.qq.com/s/E43gc16A3OVWgxyfdUxr7g">中文版介绍</a>，有兴趣也可以先看这篇文章。</p>

<h2>TFRT: A new TensorFlow runtime</h2>

<p><a href="https://blog.tensorflow.org/2020/04/tfrt-new-tensorflow-runtime.html">[链接]</a></p>

<p>Google 近期开源了新的 TensorFlow 运行时 TFRT（TensorFlow Runtime），这是一个介于上层用户代码和底层设备之间的执行环境。项目的愿景是实现一个统一的、可扩展的、性能首屈一指（best-in-class）的，同时可跨越多种领域硬件（domain specific hardware）的运行时。未来 TFRT 会成为 TensorFlow 默认的运行时，目前还在集成中。从 ResNet-50 的 inference 测试结果上看平均提升了 28% 的性能。</p>

<h2>Why We Need DevOps for ML Data</h2>

<p><a href="https://tecton.ai/blog/devops-ml-data">[链接]</a></p>

<p>虽然这是一篇产品推广软文（在文章最后一节），但是文章中普及的关于 DevOps 与机器学习之间的关系还是非常有价值的。很多人可能以为机器学习就只是模型算法而已，诚然这是学术研究的基石，但是要真正把机器学习应用到工业界光有算法是远远不够的。Google 著名的 <a href="https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf.">Hidden Technical Debt in Machine Learning Systems</a> 论文已经论述了那些隐藏在模型背后的往往被人忽略的技术，模型规模越大需要付出的工程努力也是越大的（所以很多时候大公司才需要自己造轮子）。作为衍生阅读也可以同时看看 <a href="https://towardsdatascience.com/how-linkedin-uber-lyft-airbnb-and-netflix-are-solving-data-management-and-discovery-for-machine-9b79ee9184bb">How LinkedIn, Uber, Lyft, Airbnb and Netflix are Solving Data Management and Discovery for Machine Learning Solutions</a> 这篇文章。</p>

<h2>Mid-stack inlining in Go</h2>

<p><a href="https://dave.cheney.net/2020/05/02/mid-stack-inlining-in-go">[链接]</a></p>

<p>Dave Cheney 继续科普 Go 的一些实现细节，这次的主题是编译器如何实现 mid-stack inlining。所谓 mid-stack inlining 就是将那些调用了其它函数的函数变成 inline，相对的还有 leaf inlining，即不调用任何其它函数。有兴趣了解 leaf inlining 的可以看 Dave Cheney 的<a href="https://dave.cheney.net/2020/04/25/inlining-optimisations-in-go">上一篇文章</a>。</p>

<h2>Why We Leverage Multi-tenancy in Uber’s Microservice Architecture</h2>

<p><a href="https://eng.uber.com/multitenancy-microservice-architecture">[链接]</a></p>

<p>Uber 介绍了他们在微服务领域实践的一个经验「多租户」，简单讲就是让请求链路上的所有组件和系统都能够感知「租户」这个概念，比如租户可以分为生产环境和测试环境。Uber 列举了两个应用场景：集成测试和 Canary 部署，这两个场景都依赖生产环境的请求，有了租户的概念就可以自动进行请求路由和数据隔离。愿景其实挺美好，但「代价」也是不容忽视，前面讲了要让所有组件和系统都感知就非常依赖基础组件的统一，要解决这个问题很多时候并不单纯是一个技术问题。如何做好不同环境的数据隔离也是一个难题，关于这一点文章并没有做特别详细的介绍。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Weekly Reading List Issue #1]]></title>
    <link href="https://blog.xiaogaozi.org/2020/04/26/weekly-reading-list-issue-1/"/>
    <updated>2020-04-26T12:22:08+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/04/26/weekly-reading-list-issue-1</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>FoundationDB Record Layer: A Multi-Tenant Structured Datastore</h2>

<p><a href="https://arxiv.org/abs/1901.04452">[链接]</a></p>

<p>FoundationDB 2015 年被 Apple <a href="https://techcrunch.com/2015/03/24/apple-acquires-durable-database-company-foundationdb">收购</a>并于 2018 年<a href="https://www.foundationdb.org/blog/foundationdb-is-open-source">开源</a>，作为 Apple 为数不多的开源项目受到广泛关注。简单介绍 FoundationDB 是一个基于 Paxos 的分布式 KV 存储，底层存储结构是 B-tree（是的，并不是 LSM tree），定位上跟 Google 的 Spanner 非常相似。这篇论文发表在 <a href="https://sigmod2019.org/sigmod_industry_list">SIGMOD 2019</a>，介绍的是基于 FoundationDB 的 record-oriented 结构化存储框架（也已经<a href="https://github.com/FoundationDB/fdb-record-layer">开源</a>）。<a href="https://apple.github.io/foundationdb/layer-concept.html">Layer</a> 是 FoundationDB 一个很有特色的概念，在最基本的 KV 上无限扩展更加复杂的数据模型。这个框架整体上有几个亮点：</p>

<ul>
<li>基于 Protocol Buffers 的数据模型定义</li>
<li>丰富的索引类型支持（单字段索引、嵌套字段索引、列表字段索引、聚合索引、rank 索引、全文索引、多字段联合索引等），并且索引是可以跨表的（这里简单将 record type 理解为表）。</li>
<li>基于 Java 的查询 API（并不是 SQL）</li>
</ul>


<p>目前已经被应用在 <a href="https://developer.apple.com/icloud/cloudkit">CloudKit</a>，替代旧的 Cassandra + Solr 架构（旧架构也有<a href="https://dl.acm.org/doi/10.1145/3164135.3164138">一篇论文</a>介绍）。CloudKit 作为一个庞大的存储服务供所有 Apple 生态的应用和用户使用，这也就是论文标题中 Multi-Tenant 的含义。</p>

<h2>Introducing Dispatch</h2>

<p><a href="https://netflixtechblog.com/introducing-dispatch-da4b8a2a8072">[链接]</a></p>

<p>Incident 管理一直是 DevOps 领域比较热门的话题，Netflix 开源了他们自己的 incident 管理工具 <a href="https://github.com/Netflix/dispatch">Dispatch</a>，更早之前 LinkedIn 也<a href="https://engineering.linkedin.com/blog/2017/06/open-sourcing-iris-and-oncall">开源</a>过类似的东西。</p>

<h2>Agent57: Outperforming the human Atari benchmark</h2>

<p><a href="https://deepmind.com/blog/article/Agent57-Outperforming-the-human-Atari-benchmark">[链接]</a></p>

<p>大众对于 DeepMind 的认知恐怕就是<a href="https://en.wikipedia.org/wiki/AlphaGo">下下围棋</a>、<a href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii">打打星际</a>，最近又搞起了雅达利的游戏，可以说是把强化学习玩儿出花儿了。最新一代的 Agent57 已经可以在全部 57 个游戏里战胜人类玩家。</p>

<h2>An Illustrated Guide to Graph Neural Networks</h2>

<p><a href="https://medium.com/dair-ai/an-illustrated-guide-to-graph-neural-networks-d5564a551783">[链接]</a></p>

<p>Graph Neural Networks（GNN）最近几年已经火得不行，Amazon 也开源了相关的框架 <a href="https://www.dgl.ai/">DGL</a>。这篇文章以一种简单的示意图的形式介绍什么是 GNN，帮助不了解 GNN 的人建立一个简单的认知。</p>

<h2>Debugging with Delve</h2>

<p><a href="https://tpaschalis.github.io/delve-debugging">[链接]</a></p>

<p><a href="https://github.com/go-delve/delve">Delve</a> 是一个 Go 语言的 debugger，Go 官方也<a href="https://golang.org/doc/gdb">推荐</a>优先考虑使用它而不是 GDB。这篇文章简单介绍了 Delve 的基本功能，其实跟 GDB 的使用方式很类似，但是 Delve 的亮点在于可以理解 Go 语言的语义以及调试 goroutine。</p>

<h2>gofiber/fiber</h2>

<p><a href="https://github.com/gofiber/fiber">[链接]</a></p>

<p>Fiber 是（又）一个 Go 语言的 HTTP 框架，设计上很大程度受了 Node.js 中非常流行的 <a href="https://expressjs.com">Express</a> 启发（API 非常相似）。得益于底层使用的 <a href="https://github.com/valyala/fasthttp">fasthttp</a> 库，在 Fiber 自己的<a href="https://docs.gofiber.io/benchmarks">评测</a>中超越了很多市面上现有的框架。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何设计与实现一个分布式索引框架（三）：正排索引]]></title>
    <link href="https://blog.xiaogaozi.org/2020/04/24/how-to-design-a-distributed-index-framework-part-3/"/>
    <updated>2020-04-24T16:29:40+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/04/24/how-to-design-a-distributed-index-framework-part-3</id>
    <content type="html"><![CDATA[<blockquote><p>这是一个<a href="https://blog.xiaogaozi.org/categories/htdadif/">系列文章</a>，大部分内容都来自我过去在小红书发现 Feed 团队工作期间的实践和经验。在介绍的过程中我会尽量不掺杂过多的业务细节，而专注于这背后我个人一些浅薄的设计思想，希望你在阅读完这些文章以后能够直接或者间接地拓展到不同的场景。</p></blockquote>

<p><a href="https://blog.xiaogaozi.org/2020/04/22/how-to-design-a-distributed-index-framework-part-2/">上一篇文章</a>介绍了如何定义 schema、查询 API 以及怎样实现倒排索引，本篇将会着重介绍另一种重要的索引类型「正排索引」，以及跟正排索引密切相关的「二级索引」。</p>

<!-- more -->


<h2>正排索引</h2>

<p>正排索引是主键（primary key）到条目的一一映射，在推荐系统中使用正排索引的场景是获取模型计算所需的原始特征（raw feature）。为什么说是原始特征呢？因为这些数据还需要经过特征提取（feature extraction）以后才能作为最终输入给模型的参数，特征提取不在本系列文章的讨论范畴。</p>

<p>这里先简单讲讲什么是<a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">特征</a>。最早我们提到机器学习的时候讲过模型是首先经过离线训练产生，然后用于在线预测去预估用户的喜好。在离线训练阶段算法工程师需要先从训练数据<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>人工筛选出一批对于当前想要训练的模型有意义、有价值的、可衡量的属性，这个过程叫做<a href="https://en.wikipedia.org/wiki/Feature_engineering">「特征工程（feature engineering）」</a>。特征工程考验的是一个算法工程师对于业务数据的理解、经验、数据敏感度以及统计分析能力，很多时候还需要结合大量的 A/B 实验才行。近年来深度学习的兴起已经将特征工程的复杂度降低不少，但特征工程依然是一个非常重要的步骤。这些被筛选出来的属性就是特征，举个直观的例子下面这些都可以作为模型特征使用：用户的地理位置、用户性别、用户看过的内容总曝光/点击/赞/评论的次数等。</p>

<p>正排索引中的条目存储的就是大量的原始特征，这些特征也是在 schema 中定义，基本上 schema 中除了跟倒排索引有关的字段其它都属于特征。因此可以看到正排索引条目的大小是远大于倒排索引条目的。为了保证查询的性能我们依然选择了将正排索引存储在内存中，但是这会带来一个问题，因为正排索引占用的空间可能会很大，我们也是明确知道这些数据是需要常驻在内存中的，对于类似 Java 这种带有 GC 的语言来说这部分数据反而会增加垃圾回收器的压力。这些数据会长期存储在 old generation 中，不仅浪费空间也降低了 GC 的性能。那么我们的目标便是尽量不要让这部分数据对 GC 造成太大的影响，最好是对 GC 不可见的，毕竟「眼不见心不烦」。</p>

<p>一种比较常见的解决方案是「堆外内存（off-heap）」<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。所谓堆外内存就是通过某些特殊的 API 分配独立的内存空间，且这个内存空间对于 GC 是不可见的，当然也就不会影响 GC。听起来这个方法似乎很简单直接，但凡事有好也有坏，绕开 GC 的副作用是你需要自己管理这块儿内存，如何高效地使用堆外内存是一个比较关键的问题。HBase 的 <code>BucketCache</code><sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>是一个值得参考的实现，我们在调研阶段也仔细研究过 <code>BucketCache</code> 的设计，但最终没有直接照搬，有一个非常重要的原因：<code>BucketCache</code> 是为了解决之前 <code>BlockCache</code> 这种 on-heap 缓存方案造成的 GC 性能问题而诞生，本质上也还是一个缓存，既然是缓存就必定要考虑缓存数据的驱逐，因此 <code>BucketCache</code> 的设计方案中包含如何释放内存以及合并 bucket 的逻辑。但是正排索引不是缓存，也就不存在驱逐数据的问题<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>，<code>BucketCache</code> 中的这部分设计对于我们的场景来说其实是多余的，如果完全照搬反而是在系统中引入了一个不必要的复杂组件，增加维护成本<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>。因此我们最终借鉴了一部分 <code>BucketCache</code> 的设计思想同时再结合推荐系统的业务特点实现了一个只读版本的堆外内存，下图是具体的实现方案。</p>

<p><img src="https://blog.xiaogaozi.org/images/posts/off_heap_design.png" alt="off-heap design" /></p>

<p>上图中最左边蓝色的部分是一个 hash map，key 是正排索引的主键，value 是一个包含与堆外内存地址有关的元信息对象。这个元信息对象中主要有 3 个成员变量：</p>

<ol>
<li>BB Index：BB 是 <a href="https://docs.oracle.com/javase/8/docs/api/java/nio/ByteBuffer.html"><code>java.nio.ByteBuffer</code></a> 的缩写，是 Java 中创建堆外内存的底层 API。在应用的初始化阶段我们会提前申请一块儿大的物理内存空间作为堆外内存，假设这块儿内存的大小是 10GB，在其中会按照一个固定的大小（默认是 10MB）再分割成多个小的 bucket。BB Index 即是某个 bucket 的索引。</li>
<li>Offset：每个 bucket 中存储了很多正排索引条目，offset 是某个条目在当前 bucket 中的偏移。</li>
<li>Length：这个很好理解，就是索引条目的长度。</li>
</ol>


<p>上图中蓝色和黄色的部分还是存储在堆内，只有绿色部分属于堆外。写入数据的流程就是根据索引条目的长度找到空闲的 bucket，然后通过 <code>ByteBuffer.put()</code> 方法将数据存放到堆外内存，并在 hash map 中新增相应的元信息。读取数据的流程是首先查找元信息，然后通过 HBase 中封装的 <a href="https://github.com/apache/hbase/blob/master/hbase-common/src/main/java/org/apache/hadoop/hbase/util/UnsafeAccess.java"><code>UnsafeAccess.copy()</code></a> 方法将数据从堆外拷贝到堆内。当然数据拷贝出来以后并不能直接使用，因为这还只是序列化后的字节流，还需要经过反序列化步骤<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>。</p>

<h2>二级索引</h2>

<p>二级索引的概念在很多数据库系统中也存在，特别是分布式数据库，通常主键用来查询分片的位置，而二级索引用来在某个具体的分片中查询特定的字段。</p>

<p>在推荐系统场景中二级索引的功能类似，只不过不是因为这是一个分布式系统，而是为了查询某些特殊的特征。在传统的机器学习模型中有一类特征是非常重要的，那便是内容在不同维度的统计值。举个例子，我们不仅会统计一篇笔记的总曝光数，还会统计这篇笔记在不同城市、不同性别、不同类型设备的曝光数，这里的城市、性别、设备类型就是维度。并且这些维度是允许交叉的，也就会产生非常多的维度组合。所有这些维度组合起来的统计值是一个大的集合，每次查询时并不需要这个集合中的所有值，而是根据当前用户的画像选取与这个用户相符的值。</p>

<p>如果每次查询时都把所有值从堆外内存中拷贝出来显然是很浪费的，因此我们需要一种方法直接从堆外内存中查询部分值，这就是二级索引的作用。二级索引的字段在 schema 中会标记 <code>secondary_key</code> 属性，上一篇文章中示例的字段类型是 <code>[BreakdownStats]</code>，那这个 <code>BreakdownStats</code> 的定义是什么呢？如下所示：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>table BreakdownStats {
</span><span class='line'>  key:SecondaryKey (id: 0);
</span><span class='line'>  value:NoteEngagementStats (id: 1);
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>上面 <code>key</code> 字段的数据类型是 <code>SecondaryKey</code>，这是一个由框架预定义的类型，具体定义如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>table SecondaryKey {
</span><span class='line'>  type:int (id: 0);
</span><span class='line'>  value:string (id: 1);
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>因此我们可以知道一个二级索引 key 由两部分组成：<code>type</code> 和 <code>value</code>，<code>type</code> 是 key 的类型（通常是可枚举的），<code>value</code> 是具体的值（不可枚举）。继续拿前面的例子举例，「城市」是一种 key 的类型，「上海」是具体的值。于是查询流程相比前面介绍的区别之处在于，通过主键查找以后还需要通过二级索引 key 才能获取到元信息对象，相当于增加了一次 hash map 的查找。一个优化的细节点是在框架内部我们还将二级索引 key 映射到了一个整数，这样便可以将这个整数作为 hash map 的 key 来使用。于是通过刚才的流程便实现了直接获取某个维度（或者维度组合）的统计值的需求。</p>

<p>以上就是本篇要介绍的全部内容，简单回顾一下：</p>

<ul>
<li>基于堆外内存的正排索引</li>
<li>通过二级索引实现查询部分特征</li>
</ul>


<p>至此两种索引已经全部介绍完毕，下一篇文章将会围绕一个更加上层的问题「索引如何快速更新」进行讨论。数据不可能是一成不变的，更新的效率也会直接影响产品体验和业务指标。</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>训练数据往往是用户的历史行为数据，例如用户看过、点过、赞过、评论过的所有内容。<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>除了堆外内存这种方案还有一些其它可参考的解决方案，例如阿里巴巴曾经<a href="https://blog.csdn.net/alitech2017/article/details/80133021">分享</a>过的一些经验（文章中提到的 AliGC 多租户功能近期已经在 <a href="https://github.com/alibaba/dragonwell8/wiki/Alibaba-Dragonwell8-Release-Notes">Alibaba Dragonwell 8.3.3-GA</a> 中开源）；Netflix 的开源框架 <a href="https://hollow.how/advanced-topics/#in-memory-data-layout">Hollow</a>。<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p><code>BucketCache</code> 的详细设计可以参考 <a href="https://issues.apache.org/jira/browse/HBASE-7404">HBASE-7404</a> 这个 issue<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>本质上索引是只读的<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>也许有人会问索引数据难道是不更新的吗？答案是需要更新，有关如何更新索引数据会在下一篇文章中介绍。<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
<li id="fn:6">
<p>频繁从堆外拷贝大量数据并反序列化可能会是一个比较耗时的过程，因此我们在实际使用时还在正排索引上增加了一层堆内的缓存。<a href="#fnref:6" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何设计与实现一个分布式索引框架（二）：Schema、API 及倒排索引]]></title>
    <link href="https://blog.xiaogaozi.org/2020/04/22/how-to-design-a-distributed-index-framework-part-2/"/>
    <updated>2020-04-22T18:16:55+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/04/22/how-to-design-a-distributed-index-framework-part-2</id>
    <content type="html"><![CDATA[<blockquote><p>这是一个<a href="https://blog.xiaogaozi.org/categories/htdadif/">系列文章</a>，大部分内容都来自我过去在小红书发现 Feed 团队工作期间的实践和经验。在介绍的过程中我会尽量不掺杂过多的业务细节，而专注于这背后我个人一些浅薄的设计思想，希望你在阅读完这些文章以后能够直接或者间接地拓展到不同的场景。</p></blockquote>

<p>在<a href="https://blog.xiaogaozi.org/2020/04/21/how-to-design-a-distributed-index-framework-part-1/">上一篇文章</a>中简单介绍了什么是推荐系统以及实现一个推荐系统的核心组件有哪些，文章最后引入了一个非常重要的概念「索引」，本篇将会首先从框架使用者的角度介绍如何定义索引，框架有哪些 API 可以使用以及从设计者的角度介绍如何实现一个简单的倒排索引。</p>

<!-- more -->


<h2>Schema</h2>

<p>在传统的数据库系统中，当我们提到 schema 时通常是指表（table）的逻辑定义，这个定义中会包含这些信息：表名、有哪些列（column）、列名、列的数据类型、主键（primary key）、索引名、索引的列等。非常类似的，在推荐系统中我们也需要这样的信息。框架的使用者需要首先定义好存储的数据实体，如实体名（表名）、实体有哪些字段（列）、字段的名称和数据类型、哪个字段是主键、哪些字段需要创建倒排索引。正如传统数据库系统中通过 SQL 来定义 shcema，我们也需要一种类似的 DDL<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>。经过一番调研和比较以后，我们选用了 <a href="https://google.github.io/flatbuffers">FlatBuffers</a> 作为定义 schema 的语言。同 <a href="https://developers.google.com/protocol-buffers">Protocol Buffers</a>（以下简称 PB）一样，FlatBuffers 也是 Google 开源的一种序列化协议，支持多种主流语言。为什么要选用 FlatBuffers 呢？FlatBuffers 的主页上列举了几个特点，我选取了几个最重要的翻译过来<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>，如果你熟悉 PB、Thrift 这一类 IDL 应该能很明显看出区别。</p>

<ul>
<li><strong>无需反序列化即可访问序列化后的数据</strong>：将 FlatBuffers 同其它协议区分开来的一个重要原因是 FlatBuffers 通过平展的二进制缓冲区（flat binary buffer）表示层级数据（hierarchical data），因此无需反序列化（parsing/unpacking）即可直接访问数据。同时依然支持数据结构的演变（evolution），保持向前和向后兼容性。</li>
<li><strong>高效的内存空间和访问性能</strong>：当访问数据时唯一需要分配的内存就只有数据本身的缓冲区（buffer），不需要任何额外的内存空间（C++ 语言支持，其它语言可能有变化）。FlatBuffers 也非常适合用于 mmap（或者流式处理），允许只有部分缓冲区在内存中。访问序列化后的数据基本等价于访问原始的结构体（struct），只会增加一次额外的跳转（一种虚表）来实现数据格式的演变（evolution）和可选字段。FlatBuffers 旨在应用于那些不接受耗费大量时间和空间访问或者构建序列化数据的项目，例如游戏或者任何其它对性能敏感的应用。点击查看<a href="https://google.github.io/flatbuffers/flatbuffers_benchmarks.html">性能测试</a>了解更详细的信息。</li>
</ul>


<p>有兴趣进一步了解设计细节的朋友可以看看官网的 <a href="https://google.github.io/flatbuffers/flatbuffers_internals.html">FlatBuffers Internals</a> 文档，简单总结就是 FlatBuffers 通过一种特殊的序列化格式（针对更小的内存开销和访问性能设计）相比传统 IDL 更加高性能，同时又兼具传统 IDL 的大部分特性（语言无关、强类型、schema evolution）。当然 FlatBuffers 也不是没有缺点，最明显的一个问题就是为了实现高性能，FlatBuffers 的原始 API 对开发者及其不友好，手动编写序列化或者读取数据<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>的代码非常容易出错。不过好在这些问题都可以通过自动生成的代码和框架隐藏起来，不需要直接暴露给用户<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>。前面列举的几个特点为什么对于索引框架如此重要呢？笼统讲当然是为了高性能，不过后面介绍倒排索引的设计时会详细说明一些细节点。</p>

<p>说了这么多还是不知道具体的 schema 长什么样子，下面以一个实际的例子来说明。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>table NoteInfo {
</span><span class='line'>  note_id:string (id: 0, primary_key);
</span><span class='line'>  ...
</span><span class='line'>  note_gender:NoteGender (id: 29, index_attribute);
</span><span class='line'>  taxonomies:[KeyValueEntry] (id: 30, index_key);
</span><span class='line'>  ...
</span><span class='line'>  breakdown_stats:[BreakdownStats] (id: 47, secondary_key);
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>上面是一个完整的索引实体定义，也就是小红书里用户创建的笔记（note）。每一行定义了实体中的字段名称、数据类型以及可选的属性标记。例如 <code>note_id</code> 这个字段是笔记的 ID，数据类型是 <code>string</code>，<code>id: 0</code> 是字段在 FlatBuffers 中的唯一 ID，<code>primary_key</code> 表示这个字段是主键。类似的后面列举的几个字段也具有某些特殊含义，例如 <code>NoteGender</code> 是一个枚举值，<code>index_attribute</code> 表示这是一个索引属性；<code>[KeyValueEntry]</code> 是一个 <code>KeyValueEntry</code> 类型的数组，<code>index_key</code> 表示这是一个倒排索引；<code>secondary_key</code> 表示这是一个二级索引。可以看到语法上 FlatBuffers 跟传统 IDL 类似，某种意义上可能还略微简洁一些。定义里有些是 FlatBuffers 官方的语法（如 <code>id: 0</code>），还有一些是我们扩展的（如 <code>primary_key</code>）<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>。这里扩展性是非常有必要的，否则这个 IDL 就只能用于序列化而没法作为一种数据的逻辑定义语言来使用了。这些扩展的语法具体是什么意思之后的几篇文章会逐渐展开。</p>

<h2>API</h2>

<p>有了 schema 框架就可以理解索引的数据结构了，但是对于使用者来说其实更加关心的是如何「查询」数据。推荐系统的业务特点是一个读远大于写的场景，且在线请求中只会涉及读数据而不涉及写数据，即请求都是只读的。结合上一篇文章的介绍，使用者真正需要用到的 API 基本就是下面几种：</p>

<ol>
<li>查询正排索引</li>
<li>查询倒排索引</li>
<li>查询二级索引</li>
</ol>


<p>以 Java 语言为例，实际的 API 大概长这样：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">QueryApi</span><span class="o">.</span><span class="na">queryByPrimaryKey</span><span class="o">(</span><span class="n">Object</span> <span class="n">primaryKey</span><span class="o">)</span>
</span><span class='line'><span class="n">QueryApi</span><span class="o">.</span><span class="na">queryByIndexKey</span><span class="o">(</span><span class="n">String</span> <span class="n">indexKeyName</span><span class="o">,</span> <span class="n">Object</span> <span class="n">indexKey</span><span class="o">,</span> <span class="kt">long</span> <span class="n">limit</span><span class="o">,</span> <span class="n">Function</span><span class="o">&lt;</span><span class="n">IndexPayload</span><span class="o">&lt;?&gt;,</span> <span class="n">Boolean</span><span class="o">&gt;</span> <span class="n">filter</span><span class="o">)</span>
</span><span class='line'><span class="n">QueryApi</span><span class="o">.</span><span class="na">queryBySecondaryKey</span><span class="o">(</span><span class="n">Object</span> <span class="n">primaryKey</span><span class="o">,</span> <span class="n">String</span> <span class="n">secondaryKeyName</span><span class="o">,</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">SecondaryKey</span><span class="o">&gt;</span> <span class="n">secondaryKeys</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>第 1 个 API 通过主键查询正排索引；第 2 个 API 通过倒排索引的字段 key 来查询倒排索引，同时还限定了查询的索引条目数以及一个用户自定义的过滤器；第 3 个 API 通过主键和二级索引 key 查询二级索引。</p>

<p>当然除了以上列举的最基本的 API 以外我们还提供了一些额外的接口，例如为了优化批量查询性能的批量查询接口，为了监控和可视化的索引统计信息查询接口。</p>

<h2>倒排索引</h2>

<p>假设给你一份序列化好的索引数据，要怎么创建倒排索引呢？这里有几个关键的问题需要思考：</p>

<ol>
<li>如何解析序列化的数据？</li>
<li>如何知道哪些字段需要创建倒排索引？</li>
<li>如何在运行时读取需要创建倒排的字段的值？</li>
<li>倒排索引在内存中的数据结构是什么？</li>
<li>倒排索引的条目列表如何排序？</li>
<li>如何实现在查询倒排索引的同时对条目进行过滤？</li>
</ol>


<p>第 1 个和第 2 个问题结合前面介绍 schema 时的知识应该很容易解答，只要框架能够提前获取到数据的 schema<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>，就能对索引数据有一个全局的了解，并能够事先知道哪些字段需要创建倒排索引。</p>

<p>第 3 个问题需要通过 FlatBuffers 提供的<a href="https://github.com/google/flatbuffers/blob/master/reflection/reflection.fbs">反射 API</a> 来解决<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup>，配合 shcema 就能够从实际的数据中获取某个字段的值。还记得前面没有细讲的一个问题吗？为什么我们选用了 FlatBuffers 作为序列化协议，一个非常重要的原因就是<strong>无需反序列化即可访问序列化后的数据</strong>。在创建倒排索引时这个需求尤其强烈，一个完整的定义有可能包含几十甚至上百个字段，每个字段的大小都是不同的，但是这其中可能只有个位数的字段需要创建倒排索引，如果使用传统的 IDL 反序列化整个对象的时间和空间开销将会非常大，特别是对于有 GC 的语言来说<sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup>。因此在这一点上 FlatBuffers 基本完美解决了这个问题。</p>

<p>第 4 个问题思考的角度需要从查询性能出发，既然是索引那必然追求的是查询时间复杂度最小，那就没有比 O(1) 更小的复杂度了。能够实现 O(1) 查找的数据结构最常见的就是 hash map<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup>，在不同语言中这都是非常基础的数据结构，基本不用操心是否需要自己从头开始实现。Hash map 的 key 就是倒排索引 key，value 就是索引的条目列表。而 value 应该用什么数据结构呢？倒排索引的 value 一定是有序的，且通常是倒序排列，最简单的场景用 array 其实就够了，如果需要动态增删那你可能会想到类似 <a href="https://en.wikipedia.org/wiki/Skip_list">skip list</a> 这样的数据结构。这里有一个细节点需要注意，同一个条目是有可能同时出现在不同的倒排索引中的，因此做好对象复用是节省内存非常关键的点。</p>

<p>回答第 5 个问题前可以先回到介绍 schema 时举的例子，倒排索引的字段是一个特殊的数据结构 <code>[KeyValueEntry]</code>，那么这个 <code>KeyValueEntry</code> 具体是什么呢？</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">table</span> <span class="n">KeyValueEntry</span> <span class="o">{</span>
</span><span class='line'>  <span class="nl">key:</span><span class="n">string</span> <span class="o">(</span><span class="n">key</span><span class="o">);</span>
</span><span class='line'>  <span class="nl">value:</span><span class="kt">double</span><span class="o">;</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>这是一个由用户自定义的数据结构，只有两个字段 <code>key</code> 和 <code>value</code>，前者即是倒排索引 key，而后者即是倒排索引条目的 score，同一个倒排索引 key 下的条目列表将会根据这个 score 从大到小逆序排序。这个特殊的数据结构是框架约定俗成的，只要符合一定条件就可以作为倒排索引的字段类型。</p>

<p>最后一个问题是在推荐系统的业务场景中相当常见的需求，通常查询时会限定查询 top N 的条目，但是对于不同用户这个 top N 可能是不一样的。例如需要过滤掉每个用户历史上曾经有过曝光（impression）的条目，需要根据某些用户画像属性过滤条目等。出于节省内存的原因我们不可能将一个完整定义中的所有字段都直接存放在内存中<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup>，因此限定了只有某些标记了特殊属性的字段才会存储在索引条目中，这也是前面示例中 <code>index_attribute</code> 这个标记的作用。因此一个完整的索引条目数据结构大概是这样（以 Java 语言为例）：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">IndexPayload</span><span class="o">&lt;</span><span class="n">T</span> <span class="kd">extends</span> <span class="n">Comparable</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;</span> <span class="kd">implements</span> <span class="n">Cloneable</span> <span class="o">{</span>
</span><span class='line'>    <span class="kd">private</span> <span class="kd">final</span> <span class="n">T</span> <span class="n">primaryKey</span><span class="o">;</span>
</span><span class='line'>    <span class="kd">private</span> <span class="kd">final</span> <span class="n">Object</span> <span class="n">indexKey</span><span class="o">;</span>
</span><span class='line'>    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">double</span> <span class="n">score</span><span class="o">;</span>
</span><span class='line'>    <span class="kd">private</span> <span class="kd">final</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Object</span><span class="o">&gt;</span> <span class="n">attributes</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="n">Object</span> <span class="nf">getAttribute</span><span class="o">(</span><span class="n">String</span> <span class="n">attrName</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">attributes</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">attrName</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>上面的 <code>attributes</code> 成员变量即是索引属性，key 是标记了索引属性的字段名，value 是对应的值，可以通过 <code>getAttribute()</code> 方法查询这个值。前面介绍的 <code>QueryApi.queryByIndexKey()</code> 接口中有一个 <code>filter</code> 参数，数据类型是 <code>Function&lt;IndexPayload&lt;?&gt;, Boolean&gt;</code>，也就是说这个参数是一个函数，输入参数的数据类型是 <code>IndexPayload</code>，返回值的数据类型是 <code>Boolean</code>。用户需要自己实现过滤器的逻辑，通过 <code>IndexPayload</code> 提供的接口来判断是否需要过滤当前条目。</p>

<p>以上就是本篇要介绍的全部内容，简单回顾一下：</p>

<ul>
<li>基于 FlatBuffers 的 schema 定义</li>
<li>根据不同索引类型提供不同的查询 API</li>
<li>如何在运行时创建倒排索引</li>
</ul>


<p>下一篇文章依然是围绕索引来介绍，不过重点将会是正排索引，看似一个 hash map 即可解决的问题其实有很多玄机。</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>为什么不直接用 SQL 呢？首先 SQL 的语法很复杂，很多原语是多余的，这对于使用者来说是不必要的负担。其次我们是实现一个推荐系统而不是一个完备的 DBMS，没必要硬套。最后这个 DDL 需要足够的扩展性来满足针对推荐系统的一些定制需求，关于这一点后面会提到。<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>需要查看原文和所有特点的朋友请转到 FlatBuffers 的官网<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>这里我刻意没有用「反序列化」这个词，理论上 FlatBuffers 是没有反序列化这个概念的，buffer is data（缓冲区即数据）。<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>框架使用者甚至不需要知道底层用的是 FlatBuffers<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>同样的设计思想在 <a href="https://github.com/FoundationDB/fdb-record-layer/blob/master/docs/Overview.md">FoundationDB Record Layer</a> 里也有所体现，只不过它使用的是 PB 作为 DDL，相比之下 FlatBuffers 的语法会更加简洁。<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
<li id="fn:6">
<p>实际在实现时是通过框架暴露的注册 schema 的 API 由用户来提供这些信息<a href="#fnref:6" rev="footnote">&#8617;</a></p></li>
<li id="fn:7">
<p>截止 2020 年 4 月 FlatBuffers 官方依然没有提供 Java 语言的反射 API，有需要的朋友可以参考 <a href="https://github.com/google/flatbuffers/pull/4019">#4019</a> 这个 PR，虽然这个 PR 也烂尾了。<a href="#fnref:7" rev="footnote">&#8617;</a></p></li>
<li id="fn:8">
<p>如果你使用的是 Java 语言，即使用对象池这个问题也是没法优化的，类似 PB 这样的协议对于对象池的支持可以说是相当不友好。<a href="#fnref:8" rev="footnote">&#8617;</a></p></li>
<li id="fn:9">
<p>这里暂时忽略掉哈希碰撞<a href="#fnref:9" rev="footnote">&#8617;</a></p></li>
<li id="fn:10">
<p>至于完整的数据存放在哪里后续的文章中会介绍<a href="#fnref:10" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何设计与实现一个分布式索引框架（一）：概览]]></title>
    <link href="https://blog.xiaogaozi.org/2020/04/21/how-to-design-a-distributed-index-framework-part-1/"/>
    <updated>2020-04-21T17:08:24+08:00</updated>
    <id>https://blog.xiaogaozi.org/2020/04/21/how-to-design-a-distributed-index-framework-part-1</id>
    <content type="html"><![CDATA[<blockquote><p>这是一个<a href="https://blog.xiaogaozi.org/categories/htdadif/">系列文章</a>，大部分内容都来自我过去在小红书发现 Feed 团队工作期间的实践和经验。在介绍的过程中我会尽量不掺杂过多的业务细节<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>，而专注于这背后我个人一些浅薄的设计思想，希望你在阅读完这些文章以后能够直接或者间接地拓展到不同的场景。</p></blockquote>

<p>在介绍什么是索引框架之前先了解一下我们当时面临的业务场景<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>，业界现在的 <a href="https://en.wikipedia.org/wiki/Activity_stream">feed 流</a>产品已经逐步从非个性化全面过渡到个性化，所谓的个性化 feed 其实就是<strong>基于机器学习的推荐系统</strong>。</p>

<!-- more -->


<p>先讲讲什么是推荐系统，用一个词概括就是「投其所好」。当你遇到一个跟你志趣相投的人时，那这个人感兴趣的东西很有可能也是你感兴趣的，这是「基于人」的维度进行推荐，微信的「朋友圈」就是这么一个简单的思路<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>。也有可能一个人他从来没见过你，你们也不互相认识，但是如果他能够知道你过去看过、喜欢过的东西，那他也很有可能可以推断出你未来感兴趣的东西，这是「基于历史行为」的维度进行推荐。我们可以通过制定一些人工的规则来实现推荐，但是用户的喜好是千奇百怪的<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>，有大量长尾的需求是人工规则无法覆盖的<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>。因此我们需要让计算机学习如何制定这些规则，这是对「机器学习」这个概念非常浅显的解释。一个完整的机器学习流程简单概括包含「离线」和「在线」两部分，离线部分是通过大量的用户数据来让计算机找寻其中的规律和共性，最终产出「模型」；在线部分是通过输入当前用户的数据给模型，让模型计算出一个预测值，这个预测值用来衡量我们想要推荐的内容是否符合这个用户的兴趣。这个系列的文章将会主要围绕在线部分，离线部分如果有机会会在以后的文章中介绍。</p>

<p>前面提到在线部分的核心逻辑是模型计算<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>，但在计算之前还有一个非常重要的工作是筛选候选集，通常叫做「召回（recall）」。所谓召回就是从一个很大的集合中通过一定的条件选取一个子集，为什么要有召回这一步呢？本质上是因为模型计算是一个非常耗费时间及资源的过程，如果每次用户请求都对整个集合中的条目进行计算，不仅浪费资源，所需的时间对于用户来说也是无法接受的<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup>。大部分情况<sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup>下我们对于推荐系统一次请求的时间要求是控制在 100~200ms 左右，如果超过这个时间对业务指标一定会有负面影响。因此有针对性地进行召回就非常关键了，召回需要尽量确保筛选出来的候选集是符合当前用户兴趣的，但同时耗时又是非常短的<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup>。总结一下一次推荐请求的流程如下图所示。</p>

<p><img src="https://blog.xiaogaozi.org/images/posts/recommendation_system_arch.png" alt="recommendation system architecture" /></p>

<p>实现快速召回的关键是「索引（index）」，正如大部分数据库系统一样，索引是为了实现快速查找的重要组件。在推荐系统中主要有两类索引：正排索引（forward index）和倒排索引（inverted index）<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup>。正排索引通常是用来通过一个主键（primary key）查询一个条目，是「一对一的映射」；倒排索引是用来通过跟条目关联的某些属性查询多个条目，是「一对多的映射」。举个实际的例子，小红书上用户发布的内容叫做「笔记」，每一篇笔记都会生成一个唯一的 ID，这个 ID 就是这篇笔记的主键，正排索引即是一个从笔记 ID 到笔记的映射。而每篇笔记都会有一些同笔记本身相关的属性，比如分类（category），一些常见的分类有：旅行、美妆、摄影、美食等。倒排索引即是一个从多个属性到多篇笔记的映射，如「旅行」分类可以映射到所有属于这个类别的笔记列表。对于召回来说主要依赖倒排索引，而正排索引将会在模型计算的前置步骤特征提取中用到<sup id="fnref:11"><a href="#fn:11" rel="footnote">11</a></sup>。</p>

<p><img src="https://blog.xiaogaozi.org/images/posts/rec_sys_index.png" alt="recommendation system index" /></p>

<p>讲到这里也基本上把索引框架需要实现的功能介绍得差不多了，其实需求很简单：给定一个集合然后在这个集合上创建正排和倒排索引，并暴露相应的查询接口。下一篇将会详细介绍如何定义索引、框架的 API 应该有哪些以及如何实现一个简单的倒排索引。</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>但其实能真正应用到业务中才是检验设计的唯一标准<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p><del>刚说完不聊业务就打脸</del><a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>当然前提是你的好友数得像<a href="https://baike.baidu.com/item/%E5%BD%AD%E7%A3%8A/6238051">彭磊</a>一样少<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>这几年有一个很恶心的词叫「千人千面」也是同样的意思<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>满足好长尾需求也是推荐系统面临的一大挑战<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
<li id="fn:6">
<p>你可能看到的表示模型计算的术语有：推理（inference）、预测（prediction）<a href="#fnref:6" rev="footnote">&#8617;</a></p></li>
<li id="fn:7">
<p>想象一下你打开某个 app 的首页需要等待数分钟才能显示出来<a href="#fnref:7" rev="footnote">&#8617;</a></p></li>
<li id="fn:8">
<p>大部分情况 = P95/P99<a href="#fnref:8" rev="footnote">&#8617;</a></p></li>
<li id="fn:9">
<p>召回的耗时通常比模型计算小一到两个数量级<a href="#fnref:9" rev="footnote">&#8617;</a></p></li>
<li id="fn:10">
<p>如果你接触过搜索引擎，对于这两类索引也不会感到陌生。<a href="#fnref:10" rev="footnote">&#8617;</a></p></li>
<li id="fn:11">
<p>特征提取（feature extraction）是一个非常重要的步骤，这里暂时不会过多介绍。<a href="#fnref:11" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Little Throught About Microservices]]></title>
    <link href="https://blog.xiaogaozi.org/2015/03/22/a-little-throught-about-microservices/"/>
    <updated>2015-03-22T23:25:05+08:00</updated>
    <id>https://blog.xiaogaozi.org/2015/03/22/a-little-throught-about-microservices</id>
    <content type="html"><![CDATA[<p>知乎在 4 年前已经开始尝试服务化，至今也经历了好几个架构的变迁演化。我大约是 2013 年开始在知乎负责服务化的工作，对服务化的理解也从最初的模糊逐渐变得清晰，前段时间看了一篇叫做 <a href="http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html">Microservices &ndash; Not A Free Lunch!</a> 的文章，也想趁着这个机会梳理总结目前为止我的一些感悟和想法。</p>

<!-- more -->


<h2>SOA 与 Microservices</h2>

<p>SOA（Service Oriented Architecture）是一个很「古老」的概念，而 microservices 似乎是这两年才开始流行起来的。很多人把 microservices 看作一个全新的概念（我们都是喜新厌旧的人），Martin Fowler 觉得它跟 SOA <a href="http://martinfowler.com/articles/microservices.html#MicroservicesAndSoa">差别非常大</a>，Netflix 也把他们目前的架构<a href="http://nginx.com/blog/microservices-at-netflix-architectural-best-practices">称作</a> microservices architecture。但是有人站出来<a href="http://service-architecture.blogspot.co.uk/2014/03/microservices-is-soa-for-those-who-know.html">说</a> microservices 根本就是 SOA 很多年前已经提出的概念嘛，甚至还有一份相当冗长的<a href="https://www.oasis-open.org/committees/download.php/19679/soa-rm-cs.pdf">标准文档</a>，SOA 在互联网界的流行很大程度上可能也要归功于 <a href="http://www.infoq.com/news/Amazon-CTO-Werner-Vogels-on-SOA">Amazon</a>。在 microservices（这个单词真的好长。。）这个名词流行之前，我对服务化的理解一直就是 SOA，不过我并不是想说 SOA 跟 microservices 是两个完全不同的东西，对于后者我的理解是它是 SOA 的一个 <a href="http://en.wikipedia.org/wiki/Dialect_(computing)">dialect</a>，很多核心的思想还是来源于 SOA，只不过随着时代的发展必然会产生差异（也可以说是标准制定得太慢）。至于 microservices 的标准定义，我想目前应该没有，就连 Wikipedia 的<a href="http://en.wikipedia.org/wiki/Microservices">条目</a>也讲得不清不楚（还不如看前面提到的 Netflix 的文章，里面与 SOA 比较的文字我也觉得有待商榷），每个人、每个团队、每个公司都应该有自己的理解，后文提到的知乎目前的服务化架构姑且用 microservices 指代。</p>

<h2>Microservices 的代价</h2>

<p>服务化的好处可能很多人都了解了，你可以在任何一篇相关文章中很轻易地找到关于服务化的各种优点，很多人选择服务化的时候也正是被这个「看起来」很美好的概念打动。一切模块都是天然解耦的，这简直就是软件工程的理想境界。但凡事有利必有弊，告诉你这个东西很好的人并不一定会告诉你背后隐含的一些注意事项（所以我特别欣赏那些可以把不管优点缺点都告诉你的开源项目）。文章开头提到的那篇文章就讲述了几个在实践过程中才会真正发现的「问题」，我也大概循着作者的思路，以及附上其它一些在工作中体会到的事情。</p>

<h3>显著增加运维（DevOps）成本</h3>

<p>这里的成本包括人力和物力成本。先说说物力，在服务化之前，一个项目的所有代码应该都在一个代码仓库里，在部署的时候很自然地我们把代码 clone 下来，可能还会编译打包，最后把整个项目放到生产环境。采用服务化意味着你的项目可能会从一个变成几十个（曾经有新同事来了之后惊讶于知乎内部居然有这么多项目，其实里面有很多都是一个个小的服务），想象一下此时你的部署流程会变成什么样子？当然我们并不会每次部署都要把这几十个项目挨个部署一遍，但最坏情况下你需要关心的项目的确变多了。比如所有项目依赖的一个特殊的服务有变化，需要依赖方重启，这将会是一场「浩大」的工程，不同项目大部分情况下拥有不同的维护者，通知到所有人并且完成这件事情本身就变得比较困难（难度取决于团队大小，当然这个例子并不会是经常发生的事情）。</p>

<p>在 microservices 的思想里不同的服务应该拥有完全「独立」的资源，包括代码、机器、存储等，理论上每台机器应该只运行一个服务，存储也应该只供这一个服务读写。如果再考虑不同服务的负载和高可用，那么需要为每个服务分配 2 至多台机器。此时从运维角度上来看已经增加了「数量庞大」的机器，不过考虑到成本问题，我们可能会把服务都部署在虚拟机里，而单个存储实例也可能是被多个服务共享。但这只是物理机器的数目变少了，实际上需要管理的机器还是很多。不过现在越来越流行的容器（container）的概念也许是一个不错的解决方案，有效利用了集群的资源，同时还能做到自动伸缩（auto scaling，前提是你的服务必须是无状态的）。</p>

<p>有了这么多服务，找到它们变成了一件困难的事情。这个时候我们需要一个 proxy，它的功能很简单，帮你找到你想使用的服务，再高级一点的，也许还会帮你完成负载均衡。但有网络必有开销，即使是内网，何况还是单点，有一天你会发现某个服务的调用量已经大到无法忽视 proxy 带来的网络开销。于是我们把一个 proxy 变成多个，来分担压力。但维护这些 proxy 的信息其实也是一件麻烦事，服务的机器可能会调整，可能会有很多新的服务出现，对于运维来说是不容忽视的成本。也许你在某个地方看到了另一种方案，我们其实可以不需要 proxy，直连服务岂不更好？直连减少了多余的网络开销，同时也意味着你需要自己做负载均衡和高可用，以及发现新的或者死掉的服务。其实很多人已经想到了一个解决的办法：服务发现（service discovery）。这是一个已经很成熟的方案，你甚至可以找到<a href="http://nerds.airbnb.com/smartstack-service-discovery-cloud">很</a><a href="https://github.com/Netflix/eureka">多</a><a href="https://www.consul.io">开</a><a href="https://coreos.com">源</a>实现，这里有一篇<a href="http://jasonwilder.com/blog/2014/02/04/service-discovery-in-the-cloud">文章</a>比较详细地介绍、对比了服务发现相关的技术。当然这些开源实现各有利弊，也许最终你会选择自己开发。但服务发现终归引入了一个新的概念，意味着你需要单独为它部署、配置、管理，也许还会与你的代码耦合。</p>

<p>另一个必须关心的事情就是监控，当然你说监控本来就是运维需要做的事情，但无形中增加了这么多机器监控肯定值得关注。并且监控不仅仅是指服务是否正常运行，还包括服务的请求量、负载、响应时间，这些都不是现成的，需要额外统计。</p>

<p>然后就是人力成本。前面提到的架构已经比服务化之前复杂了许多，这也许就不是一个人能完成的事情。还有很多组件并不一定是现成的，于是运维同学还需要具备一定的开发能力，DevOps 这个称谓其实是一个蛮高的要求。伴随而来的就是招人的标准也得提高，考虑到我们是家小公司，技术团队规模也不会太大，必须在招人上做出取舍。</p>

<h3>接口</h3>

<p>有了服务之后接口变成了一件很重要的事情。我们需要制定一些接口规范，讲究一点的可能还会要求命名风格；需要考虑接口的粒度，不能过细，尽量通用；不能让接口的使用者对服务内部产生太大影响，比如调用一个非常消耗服务资源的接口，这时服务的开发者就需要对接口参数进行必要的检验；最重要的，接口一旦发布，之后的任何改动都必须向后兼容。Protocol Buffers 就是一个很好的例子，因为是强类型，所以接口参数验证可以很方便地完成，Google 还给出了一套<a href="https://developers.google.com/protocol-buffers/docs/proto#updating">更新接口的准则</a>，例如新增的参数必须是 <code>optional</code> 或者 <code>repeated</code>，不能删除 <code>required</code> 参数。但有时候难免会做出不兼容的改动或者发布了新的接口，这时就需要告知所有服务的调用者。但你会发现找到服务是一个难题，找到服务的调用者其实也是一个难题。糙一点的可能就是发邮件给所有人或者通过经验来逐一排查，智能一点的就得在服务的框架里做些统计，自动生成服务的调用关系图。总之接口是一个你不可避免需要考虑的问题。</p>

<h3>重复逻辑</h3>

<p>软件工程一个比较重要的思想就是要避免重复代码，有这样一句耳熟能详的话：当你第二次写下同样的代码的时候就得思考是否可以抽象出一段新的代码。在一个项目里这件事很容易，可以是封装好一些函数、mixin 或者类。服务化之后有好几种方案可以选择：</p>

<ul>
<li>抽象出一个新的服务</li>
<li>把这段逻辑封装为一个库</li>
<li>管他的，我们就直接复制粘贴了吧</li>
</ul>


<p>每一个其实都有优缺点，挨个说一下。抽象新服务有滥用服务化的嫌疑，并且新的服务意味着更多的网络开销，多个服务也跟这个新服务显式地绑在了一起，稳定性有待商榷。封装库少了刚才提到的不稳定因素，但同时带来了维护成本，只要维护过库的同学应该都了解版本更新是一件很麻烦的事情，在迭代速度上肯定要逊于第一种方案。最后一种，嗯。。就像武侠小说中的锦囊一样，不到万不得已千万不要用。目前我们更倾向于第二种。</p>

<h3>分布式系统带来的复杂性</h3>

<p>服务化打破了长久以来的三层架构（3-tier architecture），有人称之为<a href="http://nginx.com/blog/time-to-move-to-a-four-tier-application-architecture">四层架构</a>。分层在软件工程里是一件好事，可以有效减少单层实现的复杂度，但同时也会给整个系统产生额外的代价。网络开销、网络的不稳定性、架构的容错性、消息的序列化和反序列化、不同服务之间负载的变化等等。四层架构里多了很重要的一层「服务层」，这一层内部的网络通信需要与上层隔离，客户端需要对服务的某些异常进行捕获，必要的时候重发请求，服务如何做到 graceful 部署，分布式事务（如果你真的需要事务），不要因为某个服务挂掉而导致整个系统宕机，序列化是采用二进制还是 JSON，序列化程序的性能如何，服务层内部又如何分层，如何避免循环调用。前面这些都必须考虑。</p>

<p>还有一个问题可能很多人刚开始并不一定会想到，那就是分布式系统的整体跟踪（tracing）。这是干嘛的？当一个问题出现时，你需要准确判断是哪一层出了问题，而不是靠猜或者逐一排查；当你需要优化整体性能时，你需要判断是哪次调用拖了后腿。早在 2010 年 Google 发表了 <a href="http://research.google.com/pubs/pub36356.html">Dapper 的论文</a>，之后 Twitter 开源了他们的实现 <a href="https://twitter.github.io/zipkin">Zipkin</a>，目前知乎也是在 Zipkin 的基础上针对我们自己的服务化框架定制了一套 tracing 系统。</p>

<p>系统架构的变化也会影响到开发者的某些设计，在以前这就是一些普通的函数调用，我们可以自由地控制调用的顺序、处理相关的异常，现在我们需要考虑到网络调用的因素，时序性也是一个问题，什么时候需要重试，什么时候又不行。某些问题是一个好的服务框架可以解决的，但某些不可以。</p>

<h3>异步</h3>

<p>由于<a href="http://en.wikipedia.org/wiki/Global_Interpreter_Lock">众所周知的原因</a>，Python 的多线程并不是一个效率很高的方案（事实上多线程本身也不是一个很好的方案），于是异步大行其道。但是 Python 的异步毕竟不是语言级别的，虽然有很多实现，但都不是特别好用（Python 3 这货也不知道要何年何月才能普及）。某些异步实现也会带来编程习惯上的改变，在使用的时候需要特别注意，否则可能会遇到一些看似「莫名其妙」的 bug。异步也不是银弹，当一个服务既有异步请求又有同步请求的时候，异步请求的性能反而会因为同步请求变差，因此一个服务最好是完完全全的异步。</p>

<h3>开发与测试</h3>

<p>这可能是比较容易忽视的一块，毕竟是给自己用的东西，不好用也许还可以忍忍，但我觉得这反而是最影响开发效率的环节。当一个项目的运行需要依赖十几个、几十个服务的时候，开发、测试就成了一个难题。我们也许可以分别在开发环境和测试环境将这些服务部署好，但是维护这些服务的可用性和稳定性会变成新的问题。比较理想的情况是项目的开发和测试不依赖任何第三方服务，从单元测试的角度上来讲你也只需要测试自己代码的逻辑就够了，这也许就得从服务框架的角度入手，不管开发还是测试都要保证接口正常调用，必要的时候把接口 mock 掉（但不能滥用 mock），不过集成测试还是不可避免大量服务的依赖。</p>

<h3>RPC 框架</h3>

<p>知乎从一开始就没有使用 Thrift 这样现成的 RPC 框架，而是基于 Protocol Buffers 自己搞了一个，后来又有了 JSON 序列化的框架，也逐渐从 Python 版扩展到 Node.js、Java 等语言。对于使用 HTTP 协议或者现成框架的团队来说可能这不是什么问题，但对于我们来说几乎是从零开始。凡事有利有弊，但知乎技术团队还是更倾向于简单的解决方案，服务化是一个生态，每个组件都需要完成自己的工作，框架可能是其中的胶水，把各个组件连接起来。2015 年我们会继续完善最新一版的 RPC 框架，同时还有整个服务化的生态。</p>

<h2>组织结构与 Microservices</h2>

<p>这是一个比较有趣的话题，我也是在看 Martin Fowler 的文章时才第一次了解到。引用一段著名的理论——Conway&rsquo;s Law（这个理论因《The Mythical Man-Month》而得名）：</p>

<blockquote><p>Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization&#8217;s communication structure.</p><footer><strong>Conway&#8217;s Law</strong> <cite><a href='http://www.melconway.com/Home/Conways_Law.html'>www.melconway.com/Home/&hellip;</a></cite></footer></blockquote>


<p>翻译过来就是：一个组织设计的系统（广义的指代，并不一定指软件系统）往往就是公司管理组织结构的翻版。在大公司通常是这样的，设计师、产品经理、工程师、测试、运维分别属于不同的团队，但是他们又共同负责一个产品，于是这个产品可能就变成产品经理想好需求，设计师负责界面交互，弄好之后交给工程师，工程师弄好之后交给测试，测试通过最后交给运维部署，软件架构上每个角色负责的东西都是独立的。而 microservices 更加强调小团队，每个团队的成员可以承担多种角色（感觉跟敏捷开发好像），microservices 往往又跟 <a href="http://en.wikipedia.org/wiki/Continuous_integration">CI</a> 和 <a href="http://en.wikipedia.org/wiki/Continuous_delivery">CD</a> 联系紧密，因此这样的组织结构能够更加契合新的软件架构。前段时间知乎内部也有关于这个话题的讨论，最后觉得软件架构和组织结构其实是相互影响的，任何一方不契合另外一方，都会造成这两个的融合。</p>

<h2>一点总结</h2>

<p>写了这么多，并不是想说服务化有多么可怕，相反，在我看来在如今移动互联网的时代，microservices 架构是一个趋势，但每个团队应该根据自己当前的需要合理选择服务化架构，这个架构可以很复杂也可以很简单，没有必要完全相同，适合的就是最好的，这绝对是软件工程第一准则。</p>

<h2>相关文章</h2>

<ul>
<li><a href="http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html">Microservices &ndash; Not A Free Lunch!</a></li>
<li><a href="http://martinfowler.com/articles/microservices.html">Microservices</a></li>
<li><a href="http://nginx.com/blog/time-to-move-to-a-four-tier-application-architecture">It’s Time to Move to a Four-Tier Application Architecture</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop Best Practices: Scheduling in YARN]]></title>
    <link href="https://blog.xiaogaozi.org/2014/12/27/hadoop-best-practices-scheduling-in-yarn/"/>
    <updated>2014-12-27T19:01:55+08:00</updated>
    <id>https://blog.xiaogaozi.org/2014/12/27/hadoop-best-practices-scheduling-in-yarn</id>
    <content type="html"><![CDATA[<blockquote><p>这篇文章基本上是对<a href="https://www.safaribooksonline.com/library/view/hadoop-the-definitive/9781491901687/ch04.html#YARNScheduling">《Hadoop: The Definitive Guide, 4th Edition》第 4 章</a>的转述，版权归作者所有。</p></blockquote>

<p>YARN 提供了三种任务调度策略：FIFO Scheduler，Capacity Scheduler 和 Fair Scheduler，下面会分别详细介绍。</p>

<!-- more -->


<h2>FIFO Scheduler</h2>

<p>顾名思义，FIFO Scheduler 就是将所有 application 按照提交顺序来执行，这些 application 都放在一个队列里，只有在执行完一个之后，才会继续执行下一个。</p>

<p>这种调度策略很容易理解，但缺点也很明显。耗时的长任务会导致后提交的任务一直处于等待状态，如果这个集群是多人共享的，显然不太合理。因此 YARN 提供了另外两种调度策略，更加适合共享集群。下图是 FIFO Scheduler 执行过程的示意图：</p>

<p><img src="https://farm8.staticflickr.com/7562/16118318715_13c5427d15_o.png" alt="FIFO Scheduler" /></p>

<h2>Capacity Scheduler</h2>

<p>既然需要多人共享，那 Capacity Scheduler 就为每个人分配一个队列，每个队列占用的集群资源是固定的，但是可以不同，队列内部还是采用 FIFO 调度的策略。下图是 Capacity Scheduler 执行过程的示意图：</p>

<p><img src="https://farm8.staticflickr.com/7559/15495992404_c03bc4d9a8_o.png" alt="Capacity Scheduler" /></p>

<p>可以看到，队列 A 和 B 享有独立的资源，但是 A 所占的资源比重更多。如果任务在被执行的时候，集群恰好有空闲资源，比如队列 B 为空，那么调度器就可能分配更多的资源给队列 A，以更好地利用空闲资源。这种处理方式被叫做「queue elasticity」（弹性队列）。</p>

<p>但是弹性队列也有一些副作用，如果此时队列 B 有了新任务，之前被队列 A 占用的资源并不会立即释放，只能等到队列 A 的任务执行完。为了防止某个队列过多占用集群资源，YARN 提供了一个设置可以控制某个队列能够占用的最大资源。但这其实又是跟弹性队列冲突的，因此这里有一个权衡的问题，这个最大值设为多少需要不断试验和尝试。</p>

<p>Capacity Scheduler 的队列是支持层级关系的，即有子队列的概念。下面是一个示例配置文件：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="cp">&lt;?xml version=&quot;1.0&quot;?&gt;</span>
</span><span class='line'><span class="nt">&lt;configuration&gt;</span>
</span><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>yarn.scheduler.capacity.root.queues<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>prod,dev<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>yarn.scheduler.capacity.root.dev.queues<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>eng,science<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>yarn.scheduler.capacity.root.prod.capacity<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>40<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>yarn.scheduler.capacity.root.dev.capacity<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>60<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>yarn.scheduler.capacity.root.dev.maximum-capacity<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>75<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>yarn.scheduler.capacity.root.dev.eng.capacity<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>50<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>yarn.scheduler.capacity.root.dev.science.capacity<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>50<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span><span class='line'><span class="nt">&lt;/configuration&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>所有队列的根队列叫做 <code>root</code>，这里一共有两个队列：<code>dev</code> 和 <code>prod</code>，<code>dev</code> 队列之下又有两个子队列：<code>eng</code> 和 <code>science</code>。<code>dev</code> 和 <code>prod</code> 分别占用了 60% 和 40% 的资源比重，同时限制了 <code>dev</code> 队列能够伸缩到的最大资源比重是 75%，换句话说，<code>prod</code> 队列至少能有 25% 的资源分配。<code>eng</code> 和 <code>science</code> 队列各占 50%，但因为没有设置最大值，所以有可能出现某个队列占用整个父队列资源的情况。</p>

<p>除了设置队列层级关系和资源分配比重之外，Capacity Scheduler 还提供了诸如控制每个用户或者任务最大占用资源、同时执行的最大任务数，以及队列的 ACL 等配置，详细请参考<a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html">官方文档</a>。</p>

<h3>队列放置</h3>

<p>分配好了队列，要怎么控制任务在指定队列执行呢？如果是 MapReduce 程序，那么可以通过 <code>mapreduce.job.queuename</code> 来设置执行队列，默认情况是在 <code>default</code> 队列执行。注意指定的队列名不需要包含父队列，即不能写成 <code>root.dev.eng</code>，而应该写 <code>eng</code>。</p>

<h2>Fair Scheduler</h2>

<p>Fair Scheduler 试图为每个任务均匀分配资源，比如当前只有任务 1 在执行，那么它拥有整个集群资源，此时任务 2 被提交，那任务 1 和任务 2 将平分集群资源，以此类推。</p>

<p>当然 Fair Scheduler 也支持队列的概念，下图是执行过程的示意图：</p>

<p><img src="https://www.safaribooksonline.com/library/view/hadoop-the-definitive/9781491901687/images/yarn_fair_scheduling.png" alt="Fair Scheduler" /></p>

<p>队列 A 首先执行任务，任务 1 拥有整个集群资源，随后队列 B 增加任务 2，这两个队列均分资源，接着任务 3 被提交到队列 B，但这并不会影响队列 A，任务 3 将会跟任务 2 一起均分资源。</p>

<h3>开启 Fair Scheduler</h3>

<p>设置 <code>yarn.resourcemanager.scheduler.class</code> 为 <code>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</code>（在 <code>yarn-site.xml</code>），如果你使用的是 CDH，那默认就是 Fair Scheduler（事实上，CDH 也<a href="http://www.cloudera.com/content/cloudera/en/documentation/cdh5/v5-1-x/CDH5-Installation-Guide/cdh5ig_mapreduce_to_yarn_migrate.html#concept_nqs_pmy_xl_unique_3">不支持 Capacity Scheduler</a>）。</p>

<h3>队列设置</h3>

<p>Fair Scheduler 通过 <code>fair-scheduler.xml</code> 文件来进行各种设置，这个文件的位置可以通过 <code>yarn.scheduler.fair.allocation.file</code> 属性来控制（在 <code>yarn-site.xml</code>）。如果没有这个文件，Fair Scheduler 采取的策略将是：每个任务都放在以当前用户命名的队列中，如果这个队列不存在，将会自动创建。</p>

<p>Fair Scheduler 也支持显式定义队列，就像 Capacity Scheduler 那样，下面是示例文件：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="cp">&lt;?xml version=&quot;1.0&quot;?&gt;</span>
</span><span class='line'><span class="nt">&lt;allocations&gt;</span>
</span><span class='line'>  <span class="nt">&lt;defaultQueueSchedulingPolicy&gt;</span>fair<span class="nt">&lt;/defaultQueueSchedulingPolicy&gt;</span>
</span><span class='line'>
</span><span class='line'>  <span class="nt">&lt;queue</span> <span class="na">name=</span><span class="s">&quot;prod&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;weight&gt;</span>40<span class="nt">&lt;/weight&gt;</span>
</span><span class='line'>    <span class="nt">&lt;schedulingPolicy&gt;</span>fifo<span class="nt">&lt;/schedulingPolicy&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/queue&gt;</span>
</span><span class='line'>
</span><span class='line'>  <span class="nt">&lt;queue</span> <span class="na">name=</span><span class="s">&quot;dev&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;weight&gt;</span>60<span class="nt">&lt;/weight&gt;</span>
</span><span class='line'>    <span class="nt">&lt;queue</span> <span class="na">name=</span><span class="s">&quot;eng&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;queue</span> <span class="na">name=</span><span class="s">&quot;science&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/queue&gt;</span>
</span><span class='line'>
</span><span class='line'>  <span class="nt">&lt;queuePlacementPolicy&gt;</span>
</span><span class='line'>    <span class="nt">&lt;rule</span> <span class="na">name=</span><span class="s">&quot;specified&quot;</span> <span class="na">create=</span><span class="s">&quot;false&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;rule</span> <span class="na">name=</span><span class="s">&quot;primaryGroup&quot;</span> <span class="na">create=</span><span class="s">&quot;false&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;rule</span> <span class="na">name=</span><span class="s">&quot;default&quot;</span> <span class="na">queue=</span><span class="s">&quot;dev.eng&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/queuePlacementPolicy&gt;</span>
</span><span class='line'><span class="nt">&lt;/allocations&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>这里自定义了两个队列：<code>prod</code> 和 <code>dev</code>，权重比是 40:60，也就是说不采用均分的策略。每个队列可以有不同的调度策略，默认都是 <code>fair</code>，此外还有 FIFO、Dominant Resource Fairness（<code>drf</code>，后面会讲到）。详细的配置信息可以查看<a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/FairScheduler.html">官方文档</a>。</p>

<h3>队列放置</h3>

<p>不同于 Capacity Scheduler，Fair Scheduler 是通过规则来决定放置的队列，即前面配置文件中的 <code>queuePlacementPolicy</code> 设置。第一个规则 <code>specified</code> 代表如果任务自己指定了队列，就放置到这个队列，如果没有指定，或者指定的队列不存在，就采用下一条规则。<code>primaryGroup</code> 规则的意思是试图将任务放置到当前用户的主要 Unix 组，如果这个队列不存在则继续下一条规则。<code>default</code> 规则会匹配所有任务，示例文件的意思是放置到 <code>dev.eng</code> 队列中。</p>

<p><code>queuePlacementPolicy</code> 可以省略，如果不设置，那么默认的规则如下：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;queuePlacementPolicy&gt;</span>
</span><span class='line'>  <span class="nt">&lt;rule</span> <span class="na">name=</span><span class="s">&quot;specified&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;rule</span> <span class="na">name=</span><span class="s">&quot;user&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'><span class="nt">&lt;/queuePlacementPolicy&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>也就是说除非显式指定队列，那么将会使用当前用户名作为队列，并且如果队列不存在将会自动创建。</p>

<h3>中断（Preempt）</h3>

<p>当一个任务被提交到一个空队列，但是集群不太空闲的时候，这个任务不会被立即执行，需要等待其它任务执行完毕让出资源。为了等待时间更加可控，Fair Scheduler 支持「中断」（preemption）。</p>

<p>中断的意思是调度器会通过强行结束 container 执行的方式来释放资源，在满足某些条件的情况下。注意中断是以牺牲集群性能为代价的一种做法，因为被强行结束的 container 需要重新执行。</p>

<p>通过设置 <code>yarn.scheduler.fair.preemption</code> 为 <code>true</code> 来开启中断（在 <code>yarn-site.xml</code>），同时还需要设置另外两个超时属性中的至少一个（在 <code>fair-scheduler.xml</code>），超时的单位都是秒。</p>

<ul>
<li><code>defaultMinSharePreemptionTimeout</code> 或 <code>minSharePreemptionTimeout</code>：如果一个队列等待当前设置的超时时间之后还是没有分配到应该分配的最小资源，那么调度器就会去中断其它 container。</li>
<li><code>defaultFairSharePreemptionTimeout</code> 或 <code>fairSharePreemptionTimeout</code>：如果一个队列等待当前设置的超时时间之后还是没有分配到应该分配的资源的一半以上，那么调度器就会去中断其它 container。<code>defaultFairSharePreemptionThreshold</code> 或 <code>fairSharePreemptionThreshold</code> 可以用来调节阈值，默认是 0.5。</li>
</ul>


<h2>延迟调度</h2>

<p>以上三种调度都遵从 locality 原则。在一个繁忙的集群里，当一个任务请求一个节点的时候有很大概率这个节点正被其它 container 占用，比较显而易见的做法可能是立即寻找同一机柜里的其它节点。但是经过实际观察，如果稍微等待一段时间（秒级），分配到当前请求节点的概率将显著增加。这种策略叫做「延迟调度」（delay scheduling），Capacity Scheduler 和 Fair Scheduler 都支持这种策略。</p>

<p>每一个 node manager 会定期发送心跳给 resource manager，这其中就包含了该 node manager 正在运行的 container 数量以及可以分配给新 container 的资源。当采用延迟调度策略时，调度器并不会立即使用收集到的信息，而会等待一段时间，以达到遵从 locality 的目的。</p>

<p>Capacity Scheduler 的延迟调度通过 <code>yarn.scheduler.capacity.node-locality-delay</code> 来配置，这是一个正整数，假设是 n，表示调度器将会放弃前 n 条心跳信息。</p>

<p>Fair Scheduler 的延迟调度通过 <code>yarn.scheduler.fair.locality.threshold.node</code> 来设置，这是一个 0~1 之间的浮点数，例如是 0.5，表示调度器将会等待超过一半的节点发送心跳信息之后再决定。</p>

<h2>Dominant Resource Fairness (DRF)</h2>

<p>如果只有一种资源类型需要调度，例如内存，那资源容量的概念将会很简单，比如均分资源，就代表均分内存。但是如果有多种资源类型，例如再加上 CPU，事情就变得复杂了。如果一个任务需要很多的 CPU，但是很少的内存，而另一个任务需要很少的 CPU，很多的内存，这两个任务要如何比较呢？</p>

<p>Dominant Resource Fairness（DRF）就是用来干这种事情的，下面举例说明是什么意思。</p>

<p>假设一个集群总共有 100 个 CPU，10 TB 内存。任务 A 需要 2 个 CPU，300 GB 内存。任务 B 需要 6 个 CPU，100 GB 内存。那么 A 所需资源占集群的比重是 2% 和 3%，因为内存的比重更大，那么就可以以 3% 这个比重来整体衡量 A。同理，比较之后 B 的最终比重是 6%。因此任务 B 需要两倍于任务 A 的资源（6% 比 3%），如果是均分（fair）策略，那么 B 的 container 数量将会是 A 的一半。</p>

<p>DRF 没有默认使用，因此在计算资源的时候只考虑了内存，而忽略了 CPU。Capacity Scheduler 需要设置 <code>yarn.scheduler.capacity.resource-calculator</code> 为 <code>org.apache.hadoop.yarn.util.resource.DominantResourceCalculator</code>（在 <code>capacity-scheduler.xml</code>）；Fair Scheduler 需要设置 <code>defaultQueueSchedulingPolicy</code> 为 <code>drf</code>。</p>

<h2>总结</h2>

<p>FIFO Scheduler 显然不适用于生产环境；Capacity Scheduler 概念简单，但缺乏灵活性；Fair Scheduler 最复杂，但具有足够的灵活性以及更好的资源利用率。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[香港帆船培训记录]]></title>
    <link href="https://blog.xiaogaozi.org/2014/12/15/saling-in-hk/"/>
    <updated>2014-12-15T05:28:58+08:00</updated>
    <id>https://blog.xiaogaozi.org/2014/12/15/saling-in-hk</id>
    <content type="html"><![CDATA[<p><img class="center" src="https://farm4.staticflickr.com/3947/14961313994_9fea8b7503_z.jpg"></p>

<p>曾经对香港的印象就是便宜的苹果电脑和遍地的茶餐厅，竟忘记了这是一个靠海的岛屿。作为一个在西部长大的孩子，对于海总是有很多憧憬。从小到大见过很多地方的海，有浑浊的，有碧蓝的，有挤满游客的，也有波涛汹涌的。其实海不一定就是蓝色的，只是人们习惯性地把自己的愿望加诸在别的东西身上，所以如果某一天你见到了不是蓝色的海，请不要抱怨它。</p>

<!-- more -->


<p>听说厂里要组织去香港培训帆船的时候很兴奋，想象在海上漂泊一周，应该会遇到很多有趣的事吧，虽然对于帆船其实毫无概念。照例准备好各种东西，通行证、睡袋、手套、薄外套这些，翻箱倒柜居然找出了以前用过的八达通。同事帮忙买了香港的上网卡，想到以前去只能蹭酒店 Wi-Fi 的窘境。</p>

<p>恍然来到香港，跟同事会合，一路在港铁上打趣，穿越拥挤的街道，坐在街边的茶餐厅看店员交谈，排着长队上太平山，俯瞰星光点点的维港，再来一份糖水，第一天的香港，还是老样子。</p>

<p>为了准时到达跟教练约好的地点，第二天起了个大早，幸好还有时间品尝热粥。见面的地点是香港帆船俱乐部的会客厅，墙上一张很大的地图绘制着香港岛屿周围的海域，以及各种不了解含义的符号，后来教练有介绍上面大部分的标识。教练是个苏格兰人，我们习惯称他 Cameron，接下来的五天我们一点一点了解着这个中年男人，互相交谈，互相倾听。</p>

<p>帆船在英文里叫做 yacht，如果你查字典的话会发现还有一个含义是游艇，可能在大多数人的印象中只有游艇，一个象征有钱人的东西。但真正的帆船运动远不是点燃发动机，操控船舵那么简单。也许这五天对我来说最大的意义就是了解到世界上还有这样一种运动，需要丰富的知识和经验，需要团队协作，需要良好的体力，还需要极大的热情。</p>

<p>上船的第一天对我来说应该是不太好的，在讲完必要的安全须知之后，我们正式从铜锣湾起航，一点一点远离维港。在驶到相对宁静的海湾之后，开始学习船员落水后的救援措施。首先发现落水的人需要大喊一声，扔下救生器具，同时死死盯住落水者。这是很关键的一步，Cameron 讲到在海上其实很难发现那里有一个人，尤其是人浮在水面上的部分很有限，而救生器具除了帮助落水者以外，其实还有标记的作用。这时船长需要选择一个逆风的路线逐渐靠近落水者，之所以要逆风是为了尽量控制船的行进，千万不能顺风，对于帆船来说顺风就是噩梦。最后其他的船员要负责捞起落水者，而船长始终由第一个发现的人指挥方向，因为只有他知道落水者的实际位置，以及跟船之间的距离，这需要对指挥者的充分信任。如此练习几次之后，我们向着更广阔的海域驶去。</p>

<p>「天气不错，让我们起帆吧。」 Cameron 说道。虽然这艘船有发动机，但是只要天气合适 Cameron 都更愿意使用帆来航行，「这会让你不断思考需要怎样控制船，注意风的变化，而且也更环保。」我们的帆船一共有两个帆，分别叫做 mainsail 和 genoa。首先需要升起 mainsail，也就是主帆，是个体力活，但也需要技巧和配合。帆船上的很多工作都需要很好的体力，但看似简单的步骤如果掌握了技巧会让你轻松很多。接下来是 genoa，这是一个在主帆前面的帆，比主帆大很多，根据不同的风向，我们需要控制它的大小。此时的我已经开始晕船，这真是一种不太好的感觉，于是接下来的练习我也基本上没有参与，静静躺在船上随着波浪起伏。在太阳下山前我们赶到了浅水湾，今晚将会在这里过夜，但不会靠岸。趁着夕阳我拍下了文章开头的那张照片，浅水湾真是一个适合停靠的地方，夜晚看着对面灯火辉煌的楼宇，安静的海面，时而波动。</p>

<p>第二天 Cameron 告诉了我们一个不幸的消息，今天似乎没风，这意味着原计划的航行只能作罢。「但是没关系，即使没风我们也可以做很多其它的练习。」Cameron 不放过任何练习的机会，他告诉我们虽然我们报名的课程里没有，但是他很愿意教授我们更多帆船的知识。既然没风，那就练习怎么使用发动机吧。如何原地转弯，如何快速调头，如何掌舵，如何观察水的流向，如何将船固定在港口的浮标上，这些都要一遍一遍地练习。午餐之后，幸运的我们又迎来了风。「让我们起帆出海吧！」这可能是 Cameron 最喜欢说的一句话，这个男人对于大海总是有着极大的热情。依旧是类似昨天的练习，但要更熟练，更迅速。</p>

<p>帆船依靠风来航行，因此对于不同风向，帆船的方向以及帆的角度和大小都至关重要。通常情况下正对风左右各 45 度角的区域是无法航行的，称为「no-go zone」，这是一个绝对不能进入的区域，否则就会失去动力。有时我们需要转向，此时风向也会从船的一边变到另外一边，因此帆的角度也要同时变化，这个过程叫做 tacking 或者 jibing。你需要不断观察风向，以及船与风的夹角，因为风向随时可能会变化。而对于帆船来说最好的位置是航向与风向呈 90 度角。「要怎么判断风向呢？」「用你的脸去感觉」虽然我们有风向仪，但 Cameron 更喜欢原始的方法，他总是说你得学会在仪器坏了的情况继续航行。</p>

<p>第三天我们迎来了距离最远的一次航行，从深水湾到西贡，意味着我们将有夜航的课程。夜航是一种完全不同的体验，你无法看清海面，也没有明显的参照物，因此船上的灯光显得尤为重要。到了晚上任何船只都会分别在左舷和右舷亮起红色和绿色的灯，这样就能够很方便地判断某一艘船与你的方位。远处的灯塔指引着你的方向，也提醒你这里可能会有礁石，不同的灯塔会有不同颜色、不同形式的灯光，便于区分。夜航带来了更多挑战，也更加危险，不过 Cameron 说道虽然帆船跟飞机有很多相似的地方，但最大的好处是如果遇到紧急情况帆船可以立即停下来。</p>

<p>之后的两天是对于前几天的复习，很快五天就这样过去了，想到周一我们还对帆船一无所知，如今已是可以控制它航行的船员了。我想我以后也许不会继续参与这项运动，但帆船运动的精神会一直伴随着我，至于 Cameron 的传奇经历，只能等以后再写了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Auto Open Browser After Copy URL]]></title>
    <link href="https://blog.xiaogaozi.org/2014/01/31/auto-open-browser-after-copy-url/"/>
    <updated>2014-01-31T05:07:36+08:00</updated>
    <id>https://blog.xiaogaozi.org/2014/01/31/auto-open-browser-after-copy-url</id>
    <content type="html"><![CDATA[<p>前段时间看过一篇叫 <a href="http://sc5.io/blog/2014/01/automate-everyday-tasks">Automate Everyday Tasks</a> 的博客，其中的一些见解很有意思，我们日常工作中有很多细小但是重复的事情，如果能够将某些工作自动完成，会让生活更加舒适。我很喜欢 Mac 上一个叫 <a href="http://pilotmoon.com/popclip">PopClip</a> 的小 app，可以大大减少很多重复的操作。这篇博客就是介绍如何制作一个 app，当复制 URL 时自动在浏览器中打开。</p>

<!-- more -->


<p>有了这个想法之后我先去<a href="https://www.google.com/search?q=os+x+clipboard+manager">找找看</a>是否有类似的软件，但已有的剪贴板管理工具都没有这样的功能。于是决定自己动手做，因为没有开发 Mac app 的经验，首先想到的就是利用 Automator 来实现，可惜 Automator 不支持后台运行。经过搜索 StackExchange 上的一个<a href="http://apple.stackexchange.com/questions/96214/creating-a-resident-workflow-with-automator">问题</a>给了我思路：用 AppleScript 来做。</p>

<h2>AppleScript 程序</h2>

<p>打开 AppleScript Editor，输入以下代码，代码大意是每隔 1 秒判断剪贴板内容是否为 URL，如果是就在浏览器中打开。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='applescript'><span class='line'><span class="k">property</span> <span class="nv">oldValue</span> <span class="p">:</span> <span class="no">missing value</span>
</span><span class='line'>
</span><span class='line'><span class="k">on </span><span class="nf">idle</span>
</span><span class='line'>    <span class="k">local</span> <span class="nv">newValue</span>
</span><span class='line'>    <span class="k">set</span> <span class="nv">newValue</span> <span class="k">to</span> <span class="nb">the clipboard</span>
</span><span class='line'>    <span class="k">if</span> <span class="nv">oldValue</span> <span class="ow">is not</span> <span class="ow">equal to</span> <span class="nv">newValue</span> <span class="k">then</span>
</span><span class='line'>        <span class="k">try</span>
</span><span class='line'>            <span class="k">if</span> <span class="nv">newValue</span> <span class="ow">starts with</span> <span class="s2">&quot;http://&quot;</span> <span class="ow">or</span> <span class="nv">newValue</span> <span class="ow">starts with</span> <span class="s2">&quot;https://&quot;</span> <span class="k">then</span>
</span><span class='line'>                <span class="nb">do shell script</span> <span class="s2">&quot;open &quot;</span> <span class="o">&amp;</span> <span class="nv">newValue</span>
</span><span class='line'>            <span class="k">end</span> <span class="k">if</span>
</span><span class='line'>        <span class="k">end</span> <span class="k">try</span>
</span><span class='line'>        <span class="k">set</span> <span class="nv">oldValue</span> <span class="k">to</span> <span class="nv">newValue</span>
</span><span class='line'>    <span class="k">end</span> <span class="k">if</span>
</span><span class='line'>    <span class="no">return</span> <span class="mi">1</span>
</span><span class='line'><span class="k">end </span><span class="nf">idle</span>
</span></code></pre></td></tr></table></div></figure>


<p>保存，「File Format」选「Application」，勾选「Stay open after run handler」。</p>

<p><img class="center" src="http://f.cl.ly/items/3s0D1g2D2h2U1R273i1b/Screen%20Shot%202014-01-30%20at%2017.31.56.png"></p>

<h2>设置后台运行</h2>

<p>AppleScript 程序运行时会在 Dock 上显示一个图标，我们需要隐藏这个图标。</p>

<p><img class="center" src="http://f.cl.ly/items/343f2V1S2D3E1O102h0t/Screen%20Shot%202014-01-31%20at%200.57.07.png"></p>

<p><img class="center" src="http://cl.ly/image/2O0v2O23341w/Screen%20Shot%202014-01-31%20at%204.49.28.png"></p>

<p>增加一个新的 key「Application is background only」，value 为「YES」。</p>

<p><img class="center" src="http://f.cl.ly/items/0L3c0u1R47213D2b2F3N/Screen%20Shot%202014-01-30%20at%2017.58.09.png"></p>

<h2>设置登录自动启动</h2>

<p>在 System Preferences → Users &amp; Groups → Login Items 中添加刚才创建的 app，并设置为 hide 模式。</p>

<p><img class="center" src="http://f.cl.ly/items/1t461t21143M1s1J1L1o/Screen%20Shot%202014-01-30%20at%2018.02.57.png"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[流浪汉，木偶和厨子]]></title>
    <link href="https://blog.xiaogaozi.org/2013/03/21/vagrant-puppet-and-chef/"/>
    <updated>2013-03-21T20:25:00+08:00</updated>
    <id>https://blog.xiaogaozi.org/2013/03/21/vagrant-puppet-and-chef</id>
    <content type="html"><![CDATA[<p>最近要为 Phabricator 搭建虚拟测试环境，<a href="http://www.vagrantup.com">Vagrant</a> 是一个不错的选择（话说官网现在更新以后，变得颇为华丽）。Vagrant 官方只<a href="https://github.com/mitchellh/vagrant/wiki/Available-Vagrant-Boxes">提供</a> Ubuntu 的 base box，不过 <a href="http://www.vagrantbox.es">Vagrantbox.es</a> 有提供很多其它的系统，甚至还有 Window$。也可以自己根据<a href="http://docs-v1.vagrantup.com/v1/docs/base_boxes.html">官方文档</a>重新搭建一个 base box。</p>

<p><a href="http://docs.vagrantup.com/v2/provisioning/index.html">Provisioning</a> 是 Vagrant 一个很棒的特性，可以通过工具来自动配置和管理虚拟机。目前支持的有 Puppet 和 Chef，这两个都是著名的配置管理工具，其中 Google、Twitter、GitHub 在用 Puppet，Facebook 在用 Chef，知乎目前用的是 Puppet。正好这次两个都了解了一点，可以简单比较一下。</p>

<p>从安装方式来说，因为都是基于 Ruby 的工具，所以都可以通过 <code>gem</code> 来安装，从这一点上来说还是很方便的（话说对于 Mac 用户，千万别用官方提供的烂方法）。Puppet 的命令行工具就叫 <code>puppet</code>，而 Chef 的叫做 <code>knife</code>，这倒是跟 Chef 本身名字很搭。初学工具，肯定要看官方文档，在这一点上我觉得 Puppet 做得更好，至少还有一个像模像样的 <a href="http://docs.puppetlabs.com/learning/">Learning Puppet</a> 系列，由浅入深，循序渐进，基本上看完就可以对 Puppet 有个大概的了解和使用。而 Chef 就只扔给你一个<a href="http://docs.opscode.com">不知道该从哪看起的页面</a>，作为初学者表示很难入门。</p>

<p>Puppet 可以将一系列的配置文件打包成一个 module 供人下载，Chef 对应的则叫做 cookbook，这两者都提供了网站用于集中放置社区贡献的包，分别是 <a href="http://forge.puppetlabs.com">Puppet Forge</a> 和 <a href="http://community.opscode.com/cookbooks">Opscode Community</a>（不得不吐槽，这两个网站都很糙）。对于 module、cookbook 的安装及管理 Chef 略胜一筹，Puppet 的命令行工具可以很方便地安装 module，但是如果需要安装的包比较多，就只能通过自己写脚本来自动处理。而 Chef 有一个很好用的工具 <a href="https://github.com/applicationsonline/librarian">Librarian-Chef</a>，只需要定义好所有依赖包，并放到 Cheffile 中，就可以通过 <code>librarian-chef</code> 命令来安装和管理。</p>

<p>Puppet 在易用性，社区质量和包的扩展性上来说要比 Chef 略优，能查到的文档资料也更多一点，最终我选择了 Puppet，<a href="https://github.com/xiaogaozi/vagrant-phabricator">这里</a>是我的适用于 Phabricator 的配置文件，对 Chef 有兴趣的同学也可以看<a href="https://github.com/grigio/vagrant-chef-solo-bootstrap">这个</a>示例配置。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Little Tips: Redis MONITOR Command]]></title>
    <link href="https://blog.xiaogaozi.org/2013/03/12/little-tips-redis-monitor-command/"/>
    <updated>2013-03-12T23:47:00+08:00</updated>
    <id>https://blog.xiaogaozi.org/2013/03/12/little-tips-redis-monitor-command</id>
    <content type="html"><![CDATA[<p>前段时间知乎的 cache 服务器中的某个数据总是错乱，想到了几个可能修改缓存的源头，同时在代码中搜索相关代码，把这些服务都重启了。但是问题依旧，只是没有之前那么严重。好吧，这下肯定是某个不知名的地方仍然在访问缓存。那就从根源查起，猛然发现 Redis 的 <a href="http://redis.io/commands/monitor">MONITOR</a> 命令，可以实时打印出此时正在执行的命令，正合我意，修改缓存的命令我是知道的，只需要监测这个命令，然后就可以查到来源了。</p>

<pre><code>$ redis-cli monitor | grep '"set" "alist"'
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[给未来的你]]></title>
    <link href="https://blog.xiaogaozi.org/2012/10/28/big-fish/"/>
    <updated>2012-10-28T17:27:00+08:00</updated>
    <id>https://blog.xiaogaozi.org/2012/10/28/big-fish</id>
    <content type="html"><![CDATA[<p>孩子，你的一生会遇见很多不一样的人，在陌生的城市和环境里结交着朋友，找寻着恋人。你每天都会很忙，忙到没有时间喝水，没有时间吃饭，没有时间思考。你会羡慕那些生活得悠闲自在的人，仿佛他们生来如此。看到街上的情侣你也会想她是否也在想着你，因为你们仰望着同一片星空。你向往着有一天和她一起生活，你们想要的生活。</p>

<p>孩子，还记得我讲过的怎样遇见你母亲的故事吗？那是一个明媚的午后，记忆中的阳光总是很灿烂。当那个女生出现时，时间仿佛凝固，她没有注意到你，你知道这是一个需要你用一生去爱的女人。是的，一生。年轻人总是有无尽的诺言，但是诺言是沉重的，兑现诺言的过程是洗礼，也是炼狱，你们虽然彼此伤害，却靠得更近。</p>

<p>我对你的爷爷奶奶知之甚少，大部分是从旁人那里听说。他们小学是一个学校的，奶奶上学会经过爷爷的屋前。后来奶奶高中毕业后就开始教书，而爷爷则继续深造师范学校，传说他们从这时便已经在谈恋爱，分隔两地免不了很多的思念与痛苦，爷爷常常笑着说当年可是拒绝了很多女生的诱惑。爷爷毕业后回到了奶奶教书的学校，多年的长跑也终于有了结果。其实你还有一个姑姑，不过连我也没有见过。她是爷爷奶奶的第一个小孩，听人说长得很乖巧，但在十几岁时便由于生病去世了。爷爷奶奶教了一辈子学生，却不怎么跟我说起他们的故事，也许是不知如何表达。</p>

<p>我们都会老去，我们也曾年轻，你的困惑就是我们曾经的困惑，你的烦恼就是我们曾经的烦恼。如果你想倾诉，别忘了在远方还有你的母亲，还有我，不管发生什么，我们永远都是你最亲的人。我知道你曾经也恨过我们，但那不是真正的恨，我相信有那么一天我们能彼此释然。</p>

<p>到那时，你会了解，我们是如此深深地爱着你。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用 Bootstrap 的几个问题]]></title>
    <link href="https://blog.xiaogaozi.org/2012/10/13/some-issues-about-using-bootstrap/"/>
    <updated>2012-10-13T21:24:00+08:00</updated>
    <id>https://blog.xiaogaozi.org/2012/10/13/some-issues-about-using-bootstrap</id>
    <content type="html"><![CDATA[<h2>Responsive 与 Modal</h2>

<p>在开启 responsive 后，小屏幕设备上显示 modal 时会变成一闪而过，然后浮动窗口就不见了。具体效果可以缩小浏览器尺寸，在<a href="http://twitter.github.com/bootstrap/javascript.html#modals">这个页面</a>的 Live demo 点击「Launch demo modal」看到。<a href="https://github.com/twitter/bootstrap/issues/2130">Issue #2130</a> 专门讨论了这个问题，目前比较好的解决办法是使用<a href="http://niftylettuce.github.com/twitter-bootstrap-jquery-plugins">这个插件</a>，根据页面大小来动态调整 modal 的位置，不过貌似用了之后 modal 那个由上至下显示的动画就没有了。这个 issue 现在还处于开启状态，看来官方短期内是不会解决这个问题的。</p>

<h2>Responsive 与 Navbar</h2>

<p><del>responsive 模式下的 navbar 显示效果很赞，但是有一个很令人费解的事情，默认情况下所有 dropdown menu 都是展开的，对于使用多个菜单项，且子菜单条目很多的场景这是不能接受的。于是 <a href="https://github.com/twitter/bootstrap/issues/3184">Issue #3184</a> 出现了，这次的方案比较 hack，需要修改 bootstrap-responsive.css，将 <code>.nav-collapse .dropdown-menu</code> 里的 <code>display: block;</code> 注释掉。这时你会惊喜地发现 dropdown menu 默认折叠了，点击也能展开子菜单。</del> 最新版 Bootstrap 已经修复了 dropdown menu 默认展开的问题，但是（总是有很多但是），在触屏设备上子菜单是选不中的。托 <a href="http://www.filod.net">filod</a> 同学的福，修改 bootstrap-dropdown.js 中的一段代码：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="cm">/* APPLY TO STANDARD DROPDOWN ELEMENTS</span>
</span><span class='line'><span class="cm"> * =================================== */</span>
</span><span class='line'>
</span><span class='line'><span class="nx">$</span><span class="p">(</span><span class="nb">document</span><span class="p">)</span>
</span><span class='line'>  <span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;click.dropdown.data-api touchstart.dropdown.data-api&#39;</span><span class="p">,</span> <span class="nx">clearMenus</span><span class="p">)</span>
</span><span class='line'>  <span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;click.dropdown touchstart.dropdown.data-api&#39;</span><span class="p">,</span> <span class="s1">&#39;.dropdown form&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">e</span><span class="p">)</span> <span class="p">{</span> <span class="nx">e</span><span class="p">.</span><span class="nx">stopPropagation</span><span class="p">()</span> <span class="p">})</span>
</span><span class='line'>  <span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;click.dropdown.data-api touchstart.dropdown.data-api&#39;</span>  <span class="p">,</span> <span class="nx">toggle</span><span class="p">,</span> <span class="nx">Dropdown</span><span class="p">.</span><span class="nx">prototype</span><span class="p">.</span><span class="nx">toggle</span><span class="p">)</span>
</span><span class='line'>  <span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;keydown.dropdown.data-api touchstart.dropdown.data-api&#39;</span><span class="p">,</span> <span class="nx">toggle</span> <span class="o">+</span> <span class="s1">&#39;, [role=menu]&#39;</span> <span class="p">,</span> <span class="nx">Dropdown</span><span class="p">.</span><span class="nx">prototype</span><span class="p">.</span><span class="nx">keydown</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>这里同时监听了 click 和 touchstart 事件，于是在触屏设备上先有 touchstart 将子菜单隐藏，再有 click 点击到隐藏后该位置的菜单项，因此你永远都不可能点到想点的子菜单。<del>根本原因也是因为我们之前注释了 <code>display: block;</code> 引起，改变了 Bootstrap 的使用场景，于是 JS 出现如此纰漏。解决方法便是不监听 touchstart 事件，虽然会造成些小问题，不过也算基本满足要求。这个 issue 官方明确<a href="https://github.com/twitter/bootstrap/issues/3184#issuecomment-8072507">表示</a>不会采纳，不过还是希望以后有机会增加一个开关选项给用户。</del> 关于这个问题的讨论可以看 <a href="https://github.com/twitter/bootstrap/issues/4550">Issue #4550</a>，不明白为什么官方一直不解决，我的修改可以见<a href="https://github.com/xiaogaozi/bootstrap/commit/7bd46eadbcb8730d588676c538712f4f57ffebab">这个</a>和<a href="https://github.com/xiaogaozi/bootstrap/commit/2c4eb4b678490973f92d574b397758aadbc7bf8f">这个</a> commit。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[理解 tornado.gen]]></title>
    <link href="https://blog.xiaogaozi.org/2012/09/21/understanding-tornado-dot-gen/"/>
    <updated>2012-09-21T01:56:00+08:00</updated>
    <id>https://blog.xiaogaozi.org/2012/09/21/understanding-tornado-dot-gen</id>
    <content type="html"><![CDATA[<p>Tornado 通过 <code>@asynchronous</code> decorator 来实现异步请求，但使用的时候必须将 request handler 和 callback 分离开，<code>tornado.gen</code> 模块可以帮助我们在一个函数里完成这两个工作。下面是官方的一个例子：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">class</span> <span class="nc">GenAsyncHandler</span><span class="p">(</span><span class="n">RequestHandler</span><span class="p">):</span>
</span><span class='line'>    <span class="nd">@asynchronous</span>
</span><span class='line'>    <span class="nd">@gen.engine</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>        <span class="n">http_client</span> <span class="o">=</span> <span class="n">AsyncHTTPClient</span><span class="p">()</span>
</span><span class='line'>        <span class="n">response</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">gen</span><span class="o">.</span><span class="n">Task</span><span class="p">(</span><span class="n">http_client</span><span class="o">.</span><span class="n">fetch</span><span class="p">,</span> <span class="s">&quot;http://example.com&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="n">do_something_with_response</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s">&quot;template.html&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>这里用到了两个 decorator 稍显复杂，第一个 <code>@asynchronous</code> 会首先被执行，它的主要工作就是将 <code>RequestHandler</code> 的 <code>_auto_finish</code> 属性置为 <code>false</code>，如下：</p>

<figure class='code'><figcaption><span>web.py</span><a href='https://github.com/facebook/tornado/blob/master/tornado/web.py#L1116'>download </a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='py'><span class='line'><span class="k">def</span> <span class="nf">asynchronous</span><span class="p">(</span><span class="n">method</span><span class="p">):</span>
</span><span class='line'>    <span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">method</span><span class="p">)</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span class='line'>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">application</span><span class="o">.</span><span class="n">_wsgi</span><span class="p">:</span>
</span><span class='line'>            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;@asynchronous is not supported for WSGI apps&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">_auto_finish</span> <span class="o">=</span> <span class="bp">False</span>
</span><span class='line'>        <span class="k">with</span> <span class="n">stack_context</span><span class="o">.</span><span class="n">ExceptionStackContext</span><span class="p">(</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">_stack_context_handle_exception</span><span class="p">):</span>
</span><span class='line'>            <span class="k">return</span> <span class="n">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">wrapper</span>
</span></code></pre></td></tr></table></div></figure>


<p>接着就是最重要的 <code>@gen.engine</code>，这里充分利用了 generator 的各种特性，首先来看 <code>@gen.engine</code> 的实现（我删减了部分代码以简化理解）：</p>

<figure class='code'><figcaption><span>gen.py</span><a href='https://github.com/facebook/tornado/blob/master/tornado/gen.py#L91'>download </a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='py'><span class='line'><span class="k">def</span> <span class="nf">engine</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
</span><span class='line'>    <span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span class='line'>        <span class="n">gen</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span class='line'>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">types</span><span class="o">.</span><span class="n">GeneratorType</span><span class="p">):</span>
</span><span class='line'>            <span class="n">runner</span> <span class="o">=</span> <span class="n">Runner</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span>
</span><span class='line'>            <span class="n">runner</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</span><span class='line'>            <span class="k">return</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">wrapper</span>
</span></code></pre></td></tr></table></div></figure>


<p>局部变量 <code>gen</code> 代表第一段代码里的 <code>get</code> 函数，因为 <code>get</code> 包含了 <code>yield</code> 语句，因此成为了一个 generator。注意这里 <code>get</code> 并没有被执行，只是赋给了 <code>gen</code>。接下来是运行 <code>Runner</code> 对象的 <code>run</code> 函数。在理解 <code>run</code> 之前需要知道 generator 是通过调用 <code>next()</code> 或者 <code>send()</code> 来启动，启动之后会在遇到 <code>yield</code> 的地方 hold 住，然后将 <code>yield</code> 后面的语句的返回值返回给调用者，generator 此时即处于暂停运行状态，所有上下文都会保存。再次调用 <code>next()</code> 或 <code>send()</code> 便会恢复 generator 的运行，如果不再遇到 <code>yield</code> 语句就会抛出 <code>StopIteration</code> 异常。在恢复运行的同时 <code>yield</code> 语句本身会有返回值，如果是通过调用 <code>next()</code> 来恢复的，那么返回值永远是 <code>None</code>，而如果是通过 <code>send()</code> 则返回值取决于传给 <code>send()</code> 的参数。更多关于 generator 的说明请参考<a href="http://docs.python.org/reference/expressions.html#yield-expressions">官方文档</a>。</p>

<p>结合第一段的示例代码，可以想到 <code>run</code> 干的工作可能就是启动 generator，然后获得 <code>gen.Task</code> 对象并调用 <code>http_client.fetch</code> 函数，等回调回来之后恢复 generator 的运行，最后将回调的返回值通过 <code>send()</code> 赋给 <code>response</code>。下面是我简化后的代码。</p>

<figure class='code'><figcaption><span>gen.py</span><a href='https://github.com/facebook/tornado/blob/master/tornado/gen.py#L322'>download </a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='py'><span class='line'><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class='line'>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">yield_point</span><span class="o">.</span><span class="n">is_ready</span><span class="p">():</span>
</span><span class='line'>            <span class="k">return</span>
</span><span class='line'>        <span class="nb">next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">yield_point</span><span class="o">.</span><span class="n">get_result</span><span class="p">()</span>
</span><span class='line'>        <span class="k">try</span><span class="p">:</span>
</span><span class='line'>            <span class="n">yielded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gen</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="nb">next</span><span class="p">)</span>
</span><span class='line'>        <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
</span><span class='line'>            <span class="k">return</span>
</span><span class='line'>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">yielded</span><span class="p">,</span> <span class="n">YieldPoint</span><span class="p">):</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">yield_point</span> <span class="o">=</span> <span class="n">yielded</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">yield_point</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>第 3 行检查回调是否完成，第一次运行 <code>run</code> 总是会返回 <code>True</code>。第 5 行获取回调的返回值，同样的第一次运行返回的是 <code>None</code>。将 <code>None</code> 传给 <code>send()</code> 启动 generator，<code>yielded</code> 即是 <code>gen.Task</code> 对象，第 12 行调用 <code>start</code> 开始运行我们真正需要运行的函数，对应到示例代码就是 <code>http_client.fetch</code> 函数，同时将 <code>Runner</code> 的 <code>result_callback</code> 作为回调函数。如下：</p>

<figure class='code'><figcaption><span>gen.py</span><a href='https://github.com/facebook/tornado/blob/master/tornado/gen.py#L374'>download </a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='py'><span class='line'><span class="k">def</span> <span class="nf">result_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">inner</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">kwargs</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span class='line'>            <span class="n">result</span> <span class="o">=</span> <span class="n">Arguments</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
</span><span class='line'>        <span class="k">elif</span> <span class="n">args</span><span class="p">:</span>
</span><span class='line'>            <span class="n">result</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'>        <span class="k">else</span><span class="p">:</span>
</span><span class='line'>            <span class="n">result</span> <span class="o">=</span> <span class="bp">None</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">inner</span>
</span></code></pre></td></tr></table></div></figure>


<p>在得到回调返回值之后再次调用 <code>run</code>，通过 <code>get_result</code> 获取返回值，最后将返回值返回赋给 <code>response</code>，继续 request handler 的代码流程。</p>
]]></content>
  </entry>
  
</feed>
